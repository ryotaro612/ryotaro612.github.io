<!DOCTYPE html>
<html>

<head>
    
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-W5TDG76');</script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
        integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
        crossorigin="anonymous" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="/css/base.css">
    
    <link rel="stylesheet" href="/css/articles.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://kit.fontawesome.com/4e0e0c0a41.js" crossorigin="anonymous"></script>
    <title>Tags</title>
</head>

<body>
    
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header class="navigation">
        <h2><a href="/">Blanket</a></h2>
        <nav>
            <ul>
                <li><a href="/about">About me</a></li>
                <li><a href="/posts">Posts</a></li>
                <li><a href="/gallery">Gallery</a></li>
            </ul>
        </nav>
    </header>
    
<main>
    <h1>Posts</h1>

    
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/lightgbm/">LightGBM: A Highly Efficient Gradient Boosting Decision Tree</a></h3>
        <div class="summary"><p>LightGBMは、GBDTを高速化したアルゴリズムであり、XGBoostよりも必要な計算時間と消費メモリが少ない。
GBDTの処理時間のボトルネックは決定木の分岐を決めるところである。
その前処理で特徴の値をソートする場合は、ソートがボトルネックになる。
勾配の小さいサンプルを除外することでデータを減らし、また、同時に0でない値にならない排他的な特徴をマージすることで特徴の種類を減らし、ソートを高速化した。</p></div>
        <div class="article-footer">
            <span class="date">April 16, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/adam/">Adam: A Method for Stochastic Optimization</a></h3>
        <div class="summary"><p>ADAMはAdaptive moment estimationに由来し、名前のとおり、推定した1, 2次のモーメントによる学習率最適化のアルゴリズムである。
勾配が疎なときに有効なAdaGradの利点と、目的関数が時間とともに変化してもよいRMSPropの利点をそなえる。
一次や二次のモーメントを、指数関数的に加重を減少させる移動平均で推定する。
ただし、モーメントの初期値を0にすると最初のうちはモーメントの推定値が0に偏ってしまう。
そこで、反復回数がすくないほど推定値を大きくなるよう補正する。</p></div>
        <div class="article-footer">
            <span class="date">April 9, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/xgboost/">XGBoost: A Scalable Tree Boosting System</a></h3>
        <div class="summary"><p>XGBoostは、キャッシュやシャーディングによる高速な勾配ブースティングのライブラリであり、スパースなデータでも高速に学習できる。
情報利得が大きくなるにノードから枝をのばすときは、ノードにあるサンプルで分岐の条件を決定する。
このとき、分岐条件の特徴が欠損するサンプルを左右どちらかに無条件にふり分けると利得が大きくなるかを計算する。
これにより、欠損のないサンプル数の線形オーダまで計算量を削減する。</p></div>
        <div class="article-footer">
            <span class="date">March 26, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/classifier_chains_for_multi-label_classification/">Classifier Chains for Multi-label Classification</a></h3>
        <div class="summary"><p>scikit-learnの<a href="https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html?highlight=chain#sklearn-multioutput-classifierchain">Classifier Chain</a>で実装されたClassifier Chainsは、ラベルの相関関係を特徴につかうマルチラベル分類のモデルで、相関関係をもちいる既存手法よりも計算量がすくない。
より細かくみれば、Classifier Chainsは、Classifier Chain Model(CC)とCCのアンサンブル学習であるEnsembles of Classifier Chains(ECC)の2つにわかれる。</p></div>
        <div class="article-footer">
            <span class="date">March 22, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/effective_multi-label_active_learning_for_text_classification/">Effective Multi-Label Active Learning for Text Classification</a></h3>
        <div class="summary"><p>SVMをつかったマルチラベル文書分類のための能動学習である。
ラベルをつければモデルの損失を最も小さくできるデータをさがす。
ラベルつきデータでSVMを学習し、さらに、その識別関数の値を特徴としてラベルの数を予測するロジスティック回帰を学習する。
ラベルのないデータを両モデルに入力し、ロジスティック回帰が予測するラベルの数だけ、識別関数の値の高い順にラベルを選び、そのデータのマルチラベルとみなす。
このとき、その推定したマルチラベルと識別関数の値がほど、損失関数を最も小さくできるデータとみなす。</p></div>
        <div class="article-footer">
            <span class="date">March 12, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/pegasos/">Pegasos: Primal Estimated sub-GrAdient SOlver for SVM</a></h3>
        <div class="summary"><p>Pegasosは、SVMの学習のための反復的なアルゴリズムであり、2022年3月現在、scikit-learnの<a href="https://scikit-learn.org/stable/modules/sgd.html#implementation-details">SGDClassifier</a>で学習率を更新に採用されている。
Pegasosは、目的関数の最小値の近似値をもとめる。
求める最小値との誤差を\(\epsilon\), SVMの正則化パラメタを\(\lambda\), 各サンプルの説明変数の0でない要素数の上限を\(d\)とすると、線形カーネルをつかうSVMの時間計算量は、\(\tilde{O}(d/\lambda \epsilon)\)になる。
訓練データの数が計算量に影響しないので、教師データの数に対してスケールする。</p></div>
        <div class="article-footer">
            <span class="date">March 12, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/an_interior_point_method_for_large_scale_l1_regularized_least_squares/">An Interior-Point Method for Large-Scale L1-Regularized Least Squares</a></h3>
        <div class="summary"><p>前処理付共役勾配法により、スパースな説明変数をもつリッジ回帰の学習を高速化する。
リッジ回帰の目的関数は、凸関数だが微分可能ではない。
また、リッジ回帰の係数はスパースになりやすい。
そこで、目的関数を最小化する係数の探索を、線形不等式制約つきの凸二次計画問題とらえ、前処理付共役勾配法をつかった内点法で係数の更新方向を探索する。</p></div>
        <div class="article-footer">
            <span class="date">March 5, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/regularization_paths_for_generalized_liner_models_via_coordinate_descent/">Regularization Paths for Generalized Linear Models via Coordinate Descent</a></h3>
        <div class="summary"><p>ラッソ、リッジ、またはその両方をくみあわせるelastictnetを正則化項とする一般化線形モデルの学習を高速化した座標降下法である。
座標降下法を単純に実装すると、スパースで次元数の多い特徴だと学習に時間がかかる。
表題の手法は、その単純なパラメタの更新式の一部を、説明変数の内積におきかえ、学習データの数や次元数に対して学習時間を短縮する。</p></div>
        <div class="article-footer">
            <span class="date">February 19, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/using_tfidf_to_determine_word_relevance_in_document_queries/">Using TF-IDF to Determine Word Relevance in Document Queries(2003)</a></h3>
        <div class="summary"><p>自然言語による文書検索で、TF-IDFをベースラインにつかう利点と欠点を調べた。
クエリにある各単語のTF-IDF値の総和が最大の文書を最も関連する文書とみなす。
実験では、TFのみで検索する手法よりも予測性能がよかったが、類義語同士の同一判定をできない問題があった。</p></div>
        <div class="article-footer">
            <span class="date">February 19, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/an_algorithm_for_suffix_stripping/">An algorithm for suffix stripping (1980)</a></h3>
        <div class="summary"><p>Poterのステミングで知られる。
アルゴリズムが単純で、辞書を必要としないところに特徴がある。
規則にしたがって単語の接尾辞を段階的に変換し、変換後の文字列を語幹とみなす。</p></div>
        <div class="article-footer">
            <span class="date">February 11, 2022</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">
    
    <li>
        <a href="/tags/"><span class="material-icons">first_page</span></a>
    </li>
    <li>
        <a href="/tags/page/3/"><span class="material-icons">chevron_left</span></a>
    </li>
    
    
    <li>
        <a href="/tags/page/5/"><span class="material-icons">chevron_right</span></a>
    </li>
    <li>
        <a href="/tags/page/25/"><span class="material-icons">last_page</span></a>
    </li>
    
</ul>

    <footer>
        <ul>
            
            <li>
                <a href="https://github.com/nryotaro">
                    <i class="fab fa-github"></i>
                </a>
            </li>
            
            
            <li>
                <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
                    <i class="fab fa-linkedin-in"></i>
                </a>
            </li>
            
            <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
            
        </ul>
        <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
</body>

</html>
