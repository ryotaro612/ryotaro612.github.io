<!DOCTYPE html>
<html>

<head>
    
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-W5TDG76');</script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
        integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
        crossorigin="anonymous" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="/css/base.css">
    
    <link rel="stylesheet" href="/css/articles.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://kit.fontawesome.com/4e0e0c0a41.js" crossorigin="anonymous"></script>
    <title>Tags</title>
</head>

<body>
    
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header class="navigation">
        <h2><a href="/">Blanket</a></h2>
        <nav>
            <ul>
                <li><a href="/about">About me</a></li>
                <li><a href="/posts">Posts</a></li>
                <li><a href="/gallery">Gallery</a></li>
            </ul>
        </nav>
    </header>
    
<main>
    <h1>Posts</h1>

    
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/semi_supervised_classification_with_graph_convolutional_networks/">SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a></h3>
        <div class="summary"><p>文書の特徴を点、引用などの関係を辺でしめしたグラフ構造に畳込みニューラルネットワークを適用する半教師あり学習で、ラベルのない文書は近くにある文書とおなじラベルになると仮定する。
<a href="https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf">Zhu et al.</a>にみられる先行研究は、辺の情報をニューラルネットワークにあたず、文書の特徴のみを入力していた。
表題の手法では、文書の特徴にくわえて隣接行列で表現した辺の情報もニューラルネットワークにあたえる。
グラフの辺の数に対して線形にスケールし、隠れ層でグラフの分散表現を獲得できる。</p></div>
        <div class="article-footer">
            <span class="date">January 21, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/dynamic_routing_between_capsules/">Dynamic Routing Between Capsules (2017)</a></h3>
        <div class="summary"><p>カプセルはおなじ層にあるニューロン(ユニット)をグループであり、カプセルの出力するベクトルは入力にある特定のエンティティの分散表現になる。
表題のdynamic routingは、カプセルの出力ベクトルを1つ上の層のどのカプセルに渡すべきかを学習する手法である。
これにより、プーリング層で失われるエンティティの空間上の位置情報をカプセルの出力するベクトルで表現できる。
実験では、2層の畳み込み層と1層の全結合層からなる浅いニューラルネットワークをMNISTに適用し、長さでエンティティが存在する確率を、向きでエンティティの特徴を表現できるベクトルを学習できることを示した。</p></div>
        <div class="article-footer">
            <span class="date">December 26, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/hierarchical_attention_networks_for_document_classification/">Hierarchical Attention Networks for Document Classification (2016)</a></h3>
        <div class="summary"><p>Hierarchical Attention Network(HAN)は、単語は文から文書は文からなりたつ文書の構造をアーキテクチャに反映し、単語の注意から文の注意を、文の注意から文書の注意を計算する。
順方向と逆方向の2つのGRUでエンコードした単語の分散表現から注意を計算し、文ごとに、単語の注意の重みつき和を計算し文の分散表現とする。
さらに、文の分散表現を別の順、逆方向GRUにあたえ、単語とおなじように各文の注意を計算し、その重みつき和を文書の分散表現としてあつかう。
最後に、文書の分散表現を全結合層に入力し、ソフトマックス関数で文書のクラスを推定する。
単語の文の注意を推定できるため、単語と文の2つの粒度で文書の重要な箇所を可視化することができる。</p></div>
        <div class="article-footer">
            <span class="date">December 26, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/effective_approaches_to_attention_based_neural_machine_translation/">Effective Approaches to Attention-based Neural Machine Translation (2015)</a></h3>
        <div class="summary"><p>注意機構をつかった翻訳用のニューラルネットワークを2つ例示し、翻訳における効果的な注意機構の使い方を提案した。
どちらもスタッキングしたLSTMを使うが、注意の計算で参照するLSTMの隠れ状態が違う。
ひとつは、1単語を出力するときに、すべての単語のLSTMの隠れ状態から注意を算出するグローバルなアプローチで、もうひとつは一部の単語の状態だけから注意を算出するローカルなアプローチである。
英語とドイツ語の双方への翻訳タスクに適用したところ、ローカルなアプローチで注意機構をつかわない手法と比べてBLEUスコアを5.0ポイントできた。</p></div>
        <div class="article-footer">
            <span class="date">December 26, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/deep_learning_based_text_classification/">Deep Learning Based Text Classification: A Comprehensive Review (2020)</a></h3>
        <div class="summary"><p>深層学習によるテキスト分類のサーベイで、調査したモデル数の多さで論文の貢献を主張している。
文章の構成は、150個のモデル、40件のデータセット、定量的な評価指標の解説がつづく。
文書分類を広くとらえ、典型的なテキスト分類だけでなくQAやテキスト含意への言及もある。</p></div>
        <div class="article-footer">
            <span class="date">December 25, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/monitoring_streams/">Monitoring Streams - A New Class of Data Management Applications (2002)</a></h3>
        <div class="summary"><p>常時発生するセンサー情報などのストリームデータの監視にむいたDBMS, Auroraの設計の解説。
既存のDBMSは人の行動で起きるトランザクションを想定している。
一方、ストリームデータは、人の能動的な活動によらず絶えず発生し、異常値があればアラートを出す必要がある。
また、時系列に長期的なデータをとり、リアルタイムに応答するために不要なデータを切り捨て負荷を下げる必要もある。
Auroraは、以上のストリーミング、トリガー、不正確なデータ、リアルタイム性の4特性を扱えるモデルとして、ストリームデータの出力元をソース、ノードをストリームデータの計算、シンクをアプリケーションとするDAGで抽象化されたアーキテクチャをもつ。
ノードが計算には、ストリームをウィンドウに区切る、フィルタ、リサンプリングなどの8つがある。
DAGで表せる計算をAurora内部で実行し、その結果が接続するアプリケーションにわたる。</p></div>
        <div class="article-footer">
            <span class="date">December 11, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/a_bridging_model_for_parallel_computation/">A Bridging Model for parallel Computation (1990)</a></h3>
        <div class="summary"><p>バッチ処理グラフの最適化を目的として演算処理のバルク同期並列（bulk synchronous parallel、 BSP）を提唱した。
BPSは、Apache Giraph, Spark の GraphX API, Gelly APIで採用され、なかでもGoogleのPregelで知られるようになった<a href="https://www.oreilly.co.jp/books/9784873118703/">*1</a>。
BPSの目的は、ハードウェアと並列計算の高水準なプログラミングモデルがどちらもBPSに準ずることで、高水準なプログラミングモデルで実装された並列計算を多様なハードウェア上で動かすことにある。
フォン・ノイマンモデル型のコンピュータであれば、ハードウェアの種類を意識することなく、その上で逐次計算をおこなう多様なソフトウェアを動かせる。
フォン・ノイマンモデルは、多様なハードウェアと多様なソフトウェアをつなぐ。
BPSは、並列計算用のハードウェアと高水準な並列計算のプログラミングモデルをつなぐためにある。</p></div>
        <div class="article-footer">
            <span class="date">December 11, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/wait_free_synchronization/">Wait-Free Synchronization</a></h3>
        <div class="summary"><p>あるデータ構造がwait-freeであり、データ構造への操作が有限回のステップで完了するのであれば、ほかの並行プロセスの処理速度によらず、任意のプロセスによるその操作は必ず完了する。
表題のsynchronizationは、wait-freeであるデータ構造で別のwait-freeなデータ構造を実装することを意味する。
実装可能かを定義するためにコンセンサス数を導入する。
あるデータ構造のコンセンサス数は、単純な含意形成問題を解くときに参加できるプロセス数の最大値である。
たとえば、read / writeレジスタのコンセンサス数は1, test &amp; swapは2, compare &amp; swapは無限である。
プロセス数を定義した上で、あるコンセンサス数のデータ構造を、それより小さいコンセンサス数のデータ構造では実装できないことを示した。</p></div>
        <div class="article-footer">
            <span class="date">November 27, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/live_migration_of_virtual_machines/">Live Migration of Virtual Machines</a></h3>
        <div class="summary"><p>XenのハイパーバイザーにOSのライブマグレーションを統合し、約60msのダウンタイムでのOSのライブマイグレーションを実現した。
手法の焦点は、どれだけ短いダウンタイムや移行時間で、移行元と移行先のメモリの状態を同等にできるかにある。
ネットワークアドレスや物理デバイスの移行はあつかわない。
移行元と移行先は同じローカルネットワークにあり、マイグレーションによるIPアドレスのホストの移動を主にARP replyで通知でき、NASにデータを保存することを前提にし、ネットワークや物理デバイスの移行を考えなくてよいものとしている。</p></div>
        <div class="article-footer">
            <span class="date">November 20, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/a_critique_of_ansi_sql_isolation_levels/">A Critique of ANSI SQL Isolation Levels</a></h3>
        <div class="summary"><p>ANSI SQL-92規格は、トランザクション分離レベルを、Dirty Read, Non-Repeatable Reads, Phantomが発生する可能性で定義する。
著者は、トランザクション分離レベルを禁止する現象で定義する理由を、ロックなどの実装手段で定義すると規格が実装依存になるからだと考えている。
表題の論文は、規格の現象による定義があいまいであり、3つの異常が起きなくても望まない結果になる実行があることを例示した。
また、規格のトランザクション分離レベルが、商用データベースで採用されているトランザクション分離レベルにあてはまらない問題もある。
禁止する現象にDirty Writeを規格に加え、厳しく実行列を制限するように現象の定義を解釈し、現象の説明を自然言語から形式的な記述に変えることを提唱した。
さらに、規格がデータの版が単一であることを前提としていることを指摘した上で、多版型のトランザクションであるSnaphot Isolationを提案した。</p></div>
        <div class="article-footer">
            <span class="date">November 13, 2021</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">
    
    <li>
        <a href="/tags/"><span class="material-icons">first_page</span></a>
    </li>
    <li>
        <a href="/tags/"><span class="material-icons">chevron_left</span></a>
    </li>
    
    
    <li>
        <a href="/tags/page/3/"><span class="material-icons">chevron_right</span></a>
    </li>
    <li>
        <a href="/tags/page/21/"><span class="material-icons">last_page</span></a>
    </li>
    
</ul>

    <footer>
        <ul>
            
            <li>
                <a href="https://github.com/nryotaro">
                    <i class="fab fa-github"></i>
                </a>
            </li>
            
            
            <li>
                <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
                    <i class="fab fa-linkedin-in"></i>
                </a>
            </li>
            
            <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
            
        </ul>
        <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
</body>

</html>
