<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coda</title>
    <link>https://nryotaro.github.io/</link>
    <description>Recent content on Coda</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 17 Aug 2019 14:49:48 +0900</lastBuildDate>
    
	<atom:link href="https://nryotaro.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>メモ Advantages and Disadvantages of a Monolithic Repository</title>
      <link>https://nryotaro.github.io/post/advantages_and_disadvantages_of_a_monolithic_repository/</link>
      <pubDate>Sat, 17 Aug 2019 14:49:48 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/advantages_and_disadvantages_of_a_monolithic_repository/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、マルチリポジトリと比べたときのモノリシックリポジトリの長所と短所の調べた論文のタイトルである。
論文は2018年のICSEでGoogleから発表された。
調査方法はGoogle社のエンジニアへのアンケートとエンジニアの行動ログの分析が採用されている。
Googleではモノリシックリポジトリが採用されており、エンジニアがこれまで経験したマルチリポジトリが比較対象となっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ CatBoost: unbaiased boosting with categorical features</title>
      <link>https://nryotaro.github.io/post/cat_boost/</link>
      <pubDate>Sat, 10 Aug 2019 23:27:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/cat_boost/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題はNeurIPS 2018で発表されたCatBoostという勾配ブースティングの手法を論文にちなむ。
Target Statisticsというカテゴリカル特徴量の前処理と勾配ブースティングの学習時に生じる一種のleakageが起きることを示し、leakageをさけて前処理と学習をする手法を示した。
CatBoostは二進木の決定木を弱識別器に用いる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Are We Really Making Much Progress? A Worring Analysis of Recent Neural Recomendation Approaches</title>
      <link>https://nryotaro.github.io/post/are_we_really_making_much_progress/</link>
      <pubDate>Sat, 10 Aug 2019 14:39:11 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/are_we_really_making_much_progress/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、ニューラルネットワークを用いた推薦システムを提案、評価した論文における実験の再現性と予測性能の再評価した論文のタイトルにあたる。
発表学会は、2019年のRecSys。著者らは、以下の2つのRQに回答するためにトップ会議で発表された18の論文を調査した。その結果、実験を再現できた論文は7稿であり、その中でも単純な手法を上回る性能が認められたのは1稿だけだった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RQ1: ニューラルネットワークを用いた推薦システムの研究の再現性はどの程度か&lt;/li&gt;
&lt;li&gt;RQ2: 最近発表されたアルゴリズムは、ハイパーパラメタチューニングされた単純な手法と比べてどの程度性能がいいか&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>メモ Gaussian Processes for Regression</title>
      <link>https://nryotaro.github.io/post/gaussian_processes_for_regression/</link>
      <pubDate>Sat, 03 Aug 2019 21:54:03 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/gaussian_processes_for_regression/</guid>
      <description>&lt;p&gt;表題はガウス過程の回帰問題への応用を提案した論文。著者らは、scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process&#34;&gt;ガウス過程回帰&lt;/a&gt;の
元になっている&lt;a href=&#34;http://www.gaussianprocess.org/gpml/chapters/RW.pdf&#34;&gt;Gaussian Processes for Machine Learning&lt;/a&gt;の著者と同じ。
論文の構成は、ガウス過程回帰の予測分布の式、ハイパーパラメタ推定方法、実験による評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Google Vizier: A Service for Black-Box Optimization</title>
      <link>https://nryotaro.github.io/post/google_vizier/</link>
      <pubDate>Sat, 03 Aug 2019 17:18:36 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/google_vizier/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にあるVizierはGoogleにおいてデファクトになっているブラックボックス最適化のためのサービスであり、
論文は、Vizierのシステムアーキテクチャの構成とアルゴリズムの説明とその評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Learning Active Learning from Data</title>
      <link>https://nryotaro.github.io/post/learning_active_learning_from_data/</link>
      <pubDate>Sat, 27 Jul 2019 16:40:43 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/learning_active_learning_from_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、次にラベルを与えるべきデータが何かという能動学習における問題を、
あるサンプルを教師データに追加したときの損失関数の減少値を予測する回帰の問題としてとらえる。
能動学習の目的は最小限データで最大の予測性能をもつモデルを構築することであり、次にアノテーションすべきデータが何かを正しく予測することが課題になる。
論文は、アノテーションすべきサンプルを予測する回帰モデルを学習するアルゴリズムを提案、評価する。アルゴリズムは2値分類の分類器を対象としている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 TextRank: Bringing Order into Texts</title>
      <link>https://nryotaro.github.io/post/textrank/</link>
      <pubDate>Sat, 20 Jul 2019 17:49:36 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/textrank/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、ドキュメントからキーワードとキーセンテンスを抽出するためのグラフベースのアルゴリズムTextRankを提案、評価した。
TextRankは、名前から推測できるようにPageRankを応用した手法であり、頂点の重要度を、頂点の内容のような局所的な情報ではなく、他の頂点との辺の接続関係を含むグラフ全体の大域的な情報から決定する。PageRankとTextRankのアルゴリズムの違いは、TextRankの場合は辺ごとに重みが設定できるところにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates</title>
      <link>https://nryotaro.github.io/post/subword_regularization/</link>
      <pubDate>Wed, 17 Jul 2019 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/subword_regularization/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、過去に&lt;a href=&#34;../neural_machine_translation_of_rate_words/&#34;&gt;紹介&lt;/a&gt;した&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162&#34;&gt;論文&lt;/a&gt;と同様、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）の元になった論文にあたる。
ノイズに対する頑強さのために、単語のサブワード（部分文字列）を生成するユニグラム言語モデルの学習方法と、モデルから生成されたサブワード列を入力とする機械翻訳モデルの学習方法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Neural Machine Trasnslation of Rare Words with Subword Units</title>
      <link>https://nryotaro.github.io/post/neural_machine_translation_of_rate_words/</link>
      <pubDate>Sat, 13 Jul 2019 17:19:10 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/neural_machine_translation_of_rate_words/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;内容は、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）のトークナイズで使われるアルゴリズムになっている。単語をサブワード（単語の部分文字列）に分割し、サブワードを組み合わせて珍しい単語や未知語を表現することで、これらの出現頻度の低い単語の翻訳上げるというもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Embedding Logical Queries on Knowledge Graphs</title>
      <link>https://nryotaro.github.io/post/embedding_logical_queries_on_knowledge_graphs/</link>
      <pubDate>Sun, 17 Feb 2019 17:03:49 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/embedding_logical_queries_on_knowledge_graphs/</guid>
      <description>概要 一階述語論理式で表現されたクエリを満たすノードを、分散表現に変換し、ナレッジグラフの中から計算時間上効率よく見つけるアルゴリズムを提案した。 クエリに現れるエッジの数に対して計算時間が線形であることが特徴。 ただし、クエリには、存在量化と連接を使えるが、全称量化、選択、否定を使うことができない制約がある。
感想 全称量化を使えないなら、これをベースにする検索では検索結果を2つ以上は出せないのでしょうか？
論文はこちら。</description>
    </item>
    
    <item>
      <title>メモ Enriching Word Vectors with Subword Information</title>
      <link>https://nryotaro.github.io/post/enriching_word_vectors_with_subword_information/</link>
      <pubDate>Fri, 10 Aug 2018 17:29:44 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/enriching_word_vectors_with_subword_information/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;Fasttextを提案、評価した論文。
Character n-gramsを入力としてskip-gramのモデルを作る方法を提案、評価している。
単語の部分文字列（subword）を使わない手法や形態素解析に頼る手法よりも提案手法が優れていることを実験で示した。
部分文字列のベクトルの和が単語のベクトルとなる。
実験の考察では、そのために、未知語の部分文字列が学習データにあれば、未知語に対しても妥当な分散表現を与えることができるとあった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 When Do Chagnes Induce Fixes?</title>
      <link>https://nryotaro.github.io/post/when_do_changes_induce_fixes/</link>
      <pubDate>Fri, 03 Aug 2018 21:47:03 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/when_do_changes_induce_fixes/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ざっくり言うと、バージョン管理ツールとバグチケット管理ツールを導入しているプロジェクトにおいて、
バージョン管理ツールで追跡されている変更とバグチケット管理ツールで追跡されているバグを紐付ける手法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 A Simple Semi-supervised Algorithm For Named Entity Recognition</title>
      <link>https://nryotaro.github.io/post/a_simple_semi_supervised_for_ner/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/a_simple_semi_supervised_for_ner/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;CRFに入力する学習データを集めるための半教師学習の手法を提案と評価した論文。
本手法はCRFに与える学習データを集めるための手法であり、CRFのアルゴリズム自体に変更を加えることはない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 Applying Conditional Random Fields to Japanese Morphological Analysis</title>
      <link>https://nryotaro.github.io/post/applying_crf_to_japanese_morph_analysis/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/applying_crf_to_japanese_morph_analysis/</guid>
      <description>&lt;p&gt;Mecabの中の人の&lt;a href=&#34;http://chasen.naist.jp/chaki/t/2009-09-30/doc/mecab-cabocha-nlp-seminar-2009.pdf&#34;&gt;資料&lt;/a&gt;で紹介でされている、Mecabのアルゴリズムを提案・評価した論文。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Text Classification from Labeled and Unlabeled Documents using EM</title>
      <link>https://nryotaro.github.io/post/text_cls_from_lbl_and_unlbl_doc_em/</link>
      <pubDate>Sun, 08 Jul 2018 01:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.github.io/post/text_cls_from_lbl_and_unlbl_doc_em/</guid>
      <description>&lt;h3 id=&#34;アルゴリズム&#34;&gt;アルゴリズム&lt;/h3&gt;

&lt;p&gt;提案手法は、Naive BayesとEMアルゴリズムを組み合わせたもの。
ラベル付きデータが\(D^l\)でラベルなしデータが\(D^u\)で表されるとき、対数尤度\(\log P(D^l)P(D^u)\)を最大化する問題を解く。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>