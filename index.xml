<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blanket</title>
    <link>https://nryotaro.dev/</link>
    <description>Recent content on Blanket</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sat, 16 Apr 2022 14:32:01 +0900</lastBuildDate>
    
	<atom:link href="https://nryotaro.dev/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>LightGBM: A Highly Efficient Gradient Boosting Decision Tree</title>
      <link>https://nryotaro.dev/posts/lightgbm/</link>
      <pubDate>Sat, 16 Apr 2022 14:32:01 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/lightgbm/</guid>
      <description>&lt;p&gt;LightGBMは、GBDTを高速化したアルゴリズムであり、実験ではXGBoostよりも計算時間と消費メモリが少ない。
GBDTは決定木の分岐を決めるのに最も時間がかかる。
その前処理で特徴の値をソートする場合は、ソートがボトルネックになる。
勾配の小さいサンプルを除外することでデータを減らし、また、同時に0でない値にならない排他的な特徴をマージすることで特徴の種類を減らし、ソートを高速化した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ADAM: A METHOD FOR STOCASTIC OPTIMIZATION</title>
      <link>https://nryotaro.dev/posts/adam/</link>
      <pubDate>Sat, 09 Apr 2022 13:43:35 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/adam/</guid>
      <description>&lt;p&gt;ADAMはAdaptive moment estimationに由来し、名前のとおり、推定した1, 2次のモーメントによる学習率最適化のアルゴリズムである。
勾配が疎なときに有効なAdaGradの利点と、目的関数が時間とともに変化してもよいRMSPropの利点をそなえる。
一次や二次のモーメントを、指数関数的に加重を減少させる移動平均で推定する。
ただし、モーメントの初期値を0にすると最初のうちはモーメントの推定値が0に偏ってしまう。
そこで、反復回数がすくないほど推定値を大きくなるよう補正する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>XGBoost: A Scalable Tree Boosting System</title>
      <link>https://nryotaro.dev/posts/xgboost/</link>
      <pubDate>Sat, 26 Mar 2022 17:38:58 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/xgboost/</guid>
      <description>&lt;p&gt;XGBoostは、キャッシュやシャーディングによる高速な勾配ブースティングのライブラリであり、スパースなデータもあつかえる。
情報利得を最大化する分岐をもとめてノードからのばすときは、ノードにあるサンプルで分岐の条件を決定する。
このとき、欠損のない特徴の値のみをつかい、欠損のないサンプル数の線形オーダまで計算量を削減する。
情報利得の最大値をもとめるときは、分岐条件になる特徴が欠損しているときに左右どちらに分岐させるべきかを計算する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Classifier Chains for Multi-label Classification</title>
      <link>https://nryotaro.dev/posts/classifier_chains_for_multi-label_classification/</link>
      <pubDate>Tue, 22 Mar 2022 16:30:13 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/classifier_chains_for_multi-label_classification/</guid>
      <description>&lt;p&gt;scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.ClassifierChain.html?highlight=chain#sklearn-multioutput-classifierchain&#34;&gt;Classifier Chain&lt;/a&gt;で実装されたClassifier Chainsは、ラベルの相関関係を特徴につかうマルチラベル分類のモデルで、既存の相関関係をもちいる手法よりも計算量がすくない。
より細かくみれば、Classifier Chainsは、Classifier Chain Model(CC)とCCのアンサンブル学習であるEnsembles of Classifier Chains(ECC)の2つにわかれる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Effective Multi-Label Active Learning for Text Classification</title>
      <link>https://nryotaro.dev/posts/effective_multi-label_active_learning_for_text_classification/</link>
      <pubDate>Sat, 12 Mar 2022 15:25:23 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/effective_multi-label_active_learning_for_text_classification/</guid>
      <description>&lt;p&gt;SVMをつかったマルチラベル文書分類のための能動学習である。
ラベルをつければモデルの損失を最も小さくできるデータをさがす。
ラベルつきデータでSVMを学習し、さらに、その識別関数の値を特徴としてラベルの数を予測するロジスティック回帰を学習する。
ラベルのないデータを両モデルに入力し、ロジスティック回帰が予測するラベルの数だけ、識別関数の値の高い順にラベルを選び、そのデータのマルチラベルとみなす。
このとき、その推定したマルチラベルと識別関数の値がほど、損失関数を最も小さくできるデータとみなす。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Pegasos: Primal Estimated sub-GrAdient SOlver for SVM</title>
      <link>https://nryotaro.dev/posts/pegasos/</link>
      <pubDate>Sat, 12 Mar 2022 11:50:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/pegasos/</guid>
      <description>&lt;p&gt;Pegasosは、SVMの学習のための反復的なアルゴリズムであり、2022年3月現在、scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/sgd.html#implementation-details&#34;&gt;SGDClassifier&lt;/a&gt;で学習率を更新に採用されている。
Pegasosは、目的関数の最小値の近似値をもとめる。
求める最小値との誤差を\(\epsilon\), SVMの正則化パラメタを\(\lambda\), 各サンプルの説明変数の0でない要素数の上限を\(d\)とすると、線形カーネルをつかうSVMの時間計算量は、\(\tilde{O}(d/\lambda \epsilon)\)になる。
訓練データの数が計算量に影響しないので、教師データの数に対してスケールする。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Interior-Point Method for Large-Scale L1-Regularized Least Squares</title>
      <link>https://nryotaro.dev/posts/an_interior_point_method_for_large_scale_l1_regularized_least_squares/</link>
      <pubDate>Sat, 05 Mar 2022 13:11:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/an_interior_point_method_for_large_scale_l1_regularized_least_squares/</guid>
      <description>&lt;p&gt;前処理付共役勾配法により、スパースな説明変数をもつリッジ回帰の学習を高速化する。
リッジ回帰の目的関数は、凸関数だが微分可能ではない。
また、リッジ回帰の係数はスパースになりやすい。
そこで、目的関数を最小化する係数の探索を、線形不等式制約つきの凸二次計画問題とらえ、前処理付共役勾配法をつかった内点法で係数の更新方向を探索する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regularization Paths for Generalized Linear Models via Coordinate Descent</title>
      <link>https://nryotaro.dev/posts/regularization_paths_for_generalized_liner_models_via_coordinate_descent/</link>
      <pubDate>Sat, 19 Feb 2022 15:02:19 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/regularization_paths_for_generalized_liner_models_via_coordinate_descent/</guid>
      <description>&lt;p&gt;ラッソ、リッジ、またはその両方をくみあわせたelastictnetを正則化項にもつ一般化線形モデルの学習を高速化する座標降下法である。
座標降下法を単純に実装すると、スパースで次元数の多い特徴だと学習に時間がかかる。
表題の手法は、その単純なパラメタの更新式の一部を、説明変数の内積におきかえ、学習データの数や次元数に対して学習時間を短縮する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Using TF-IDF to Determine Word Relevance in Document Queries(2003)</title>
      <link>https://nryotaro.dev/posts/using_tfidf_to_determine_word_relevance_in_document_queries/</link>
      <pubDate>Sat, 19 Feb 2022 13:31:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/using_tfidf_to_determine_word_relevance_in_document_queries/</guid>
      <description>&lt;p&gt;自然言語のクエリで文書を検索する問題に、TF-IDFをベースラインにつかう利点と欠点を調べた。
クエリにある各単語のTF-IDF値の総和が最大化の文書を最も関連する文書とみなす。
実験では、TFのみで検索する手法よりも予測性能がよかったが、類義語同士の同一判定をできない問題があった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An algorithm for suffix stripping (1980)</title>
      <link>https://nryotaro.dev/posts/an_algorithm_for_suffix_stripping/</link>
      <pubDate>Fri, 11 Feb 2022 13:23:45 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/an_algorithm_for_suffix_stripping/</guid>
      <description>&lt;p&gt;Poterのステミングで知られる。
アルゴリズムが単純で、辞書を必要としないところに特徴がある。
単語の接尾辞を規則にしたがい段階的に変換し、変換後の文字列を語幹とみなす。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Bringing GNU Emacs to Native Code</title>
      <link>https://nryotaro.dev/posts/bringing_gnu_emacs_to_native_code/</link>
      <pubDate>Sun, 30 Jan 2022 14:19:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bringing_gnu_emacs_to_native_code/</guid>
      <description>&lt;p&gt;Emacs 28から利用できる&lt;a href=&#34;https://gcc.gnu.org/onlinedocs/jit/&#34;&gt;libgccjit&lt;/a&gt;によるネイティブコンパイルの解説である。
パッケージアーカイブELPAにあるelisp-benchmarksによる比較ではバイトコンパイルよりも2.3倍から42倍の高速化を実現した。
ネイティブコンパイル時は、はじめに、Emacs Lispのコードをバイトコンパイラで、Emacs VM(Lisp Assembly Program, LAP)の中間表現に変換する。
つぎに、LAPをS式で静的単一代入形式の中間表現LIMPLEに変換する。
LIMPLEは、GCCの中間表現GIMPLEに由来し、ネイティブコンパイルの中核技術にあたる。
さいごに、LIMPLEをlibgccjitの中間表現に変換し、GCCでネイティブに実行可能なプログラムにコンパイルする。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Data Structure for Text Sequences</title>
      <link>https://nryotaro.dev/posts/data_structure_for_text_sequence/</link>
      <pubDate>Sat, 29 Jan 2022 18:15:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/data_structure_for_text_sequence/</guid>
      <description>&lt;p&gt;テキストエディタのためのデータ構造として、array, gap, list, line pointers, fixed size buffers, piece tablesを評価する。
とくに、Piece tablesを評価し詳しく解説する。
Piece tableはテキストを2つのバッファに記録する。
2つのバッファはfile buffer, add bufferで、file bufferは初期状態のテキストを保存し、add bufferはあらたに挿入された文字列を保存する追記のみのバッファである。
なまえのpieceはバッファの連続する部分文字列を意味する。
そして、pieceへのポインタのシーケンスがpiece tableである。
ポインタは、どちらのバッファか、参照する部分文字列の開始位置、長さの3つの情報からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</title>
      <link>https://nryotaro.dev/posts/semi_supervised_classification_with_graph_convolutional_networks/</link>
      <pubDate>Fri, 21 Jan 2022 21:01:24 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/semi_supervised_classification_with_graph_convolutional_networks/</guid>
      <description>&lt;p&gt;文書の特徴を点、引用などの関係を辺でしめしたグラフ構造に畳込みニューラルネットワークを適用する半教師あり学習で、ラベルのない文書は近くにある文書とおなじラベルになると仮定する。
&lt;a href=&#34;https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf&#34;&gt;Zhu et al.&lt;/a&gt;にみられる先行研究は、辺の情報をニューラルネットワークにあたず、文書の特徴のみを入力していた。
表題の手法では、文書の特徴にくわえて隣接行列で表現した辺の情報もニューラルネットワークにあたえる。
グラフの辺の数に対して線形にスケールし、隠れ層でグラフの分散表現を獲得できる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dynamic Routing Between Capsules (2017)</title>
      <link>https://nryotaro.dev/posts/dynamic_routing_between_capsules/</link>
      <pubDate>Sun, 26 Dec 2021 22:26:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dynamic_routing_between_capsules/</guid>
      <description>&lt;p&gt;カプセルはおなじ層にあるニューロン(ユニット)のグループであり、カプセルの出力するベクトルは入力にある特定のエンティティの分散表現になる。
表題のdynamic routingは、カプセルの出力ベクトルを1つ上の層のどのカプセルに渡すべきかを学習する手法である。
これにより、プーリング層で失われるエンティティの空間上の位置情報をカプセルの出力するベクトルで表現する。
実験では、2層の畳み込み層と1層の全結合層からなる浅いニューラルネットワークをMNISTに適用し、長さでエンティティが存在する確率を、向きでエンティティの特徴を表現できるベクトルを学習できることを示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Hierarchical Attention Networks for Document Classification (2016)</title>
      <link>https://nryotaro.dev/posts/hierarchical_attention_networks_for_document_classification/</link>
      <pubDate>Sun, 26 Dec 2021 13:24:12 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/hierarchical_attention_networks_for_document_classification/</guid>
      <description>&lt;p&gt;Hierarchical Attention Network(HAN)は、単語は文から文書は文からなる文書の構造をアーキテクチャに反映し、単語の注意から文の注意を、文の注意から文書の注意を計算する。
順方向と逆方向の2つのGRUでエンコードした単語の分散表現から注意を計算し、文ごとに、単語の注意の重みつき和を計算し文の分散表現とする。
さらに、文の分散表現を別の順、逆方向GRUにあたえ、単語とおなじように各文の注意を計算し、その重みつき和を文書の分散表現としてあつかう。
最後に、文書の分散表現を全結合層に入力し、ソフトマックス関数で文書のクラスを推定する。
単語の文の注意を推定できるため、単語と文の2つの粒度で文書の重要な箇所を可視化することができる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Effective Approaches to Attention-based Neural Machine Translation (2015)</title>
      <link>https://nryotaro.dev/posts/effective_approaches_to_attention_based_neural_machine_translation/</link>
      <pubDate>Sun, 26 Dec 2021 01:54:42 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/effective_approaches_to_attention_based_neural_machine_translation/</guid>
      <description>&lt;p&gt;注意機構をつかった翻訳用のニューラルネットワークを2つ例示し、翻訳における効果的な注意機構の使い方を提案した。
どちらもスタッキングしたLSTMを使うが、注意の計算で参照するLSTMの隠れ状態が違う。
ひとつは、1単語を出力するときに、すべての単語のLSTMの隠れ状態から注意を算出するグローバルなアプローチで、もうひとつは一部の単語の状態だけから注意を算出するローカルなアプローチである。
英語とドイツ語の双方への翻訳タスクに適用したところ、ローカルなアプローチで注意機構をつかわない手法と比べてBLEUスコアを5.0ポイントできた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Deep Learning Based Text Classification: A Comprehensive Review (2020)</title>
      <link>https://nryotaro.dev/posts/deep_learning_based_text_classification/</link>
      <pubDate>Sat, 25 Dec 2021 11:44:17 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_learning_based_text_classification/</guid>
      <description>&lt;p&gt;深層学習によるテキスト分類のサーベイで、調査したモデル数の多さで論文の貢献を主張している。
文章の構成は、150個のモデル、40件のデータセット、定量的な評価指標の解説がつづく。
文書分類を広くとらえ、典型的なテキスト分類だけでなくQAやテキスト含意への言及もある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Monitoring Streams - A New Class of Data Management Applications (2002)</title>
      <link>https://nryotaro.dev/posts/monitoring_streams/</link>
      <pubDate>Sat, 11 Dec 2021 18:27:24 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/monitoring_streams/</guid>
      <description>&lt;p&gt;常時発生するセンサー情報などのストリームデータの監視にむいたDBMS, Auroraの設計の解説。
既存のDBMSは人の行動で起きるトランザクションを想定している。
一方、ストリームデータは、人の能動的な活動によらず絶えず発生し、異常値があればアラートを出す必要がある。
また、時系列に長期的なデータをとり、リアルタイムに応答するために不要なデータを切り捨て負荷を下げる必要もある。
Auroraは、以上のストリーミング、トリガー、不正確なデータ、リアルタイム性の4特性を扱えるモデルとして、ストリームデータの出力元をソース、ノードをストリームデータの計算、シンクをアプリケーションとするDAGで抽象化されたアーキテクチャをもつ。
ノードが計算には、ストリームをウィンドウに区切る、フィルタ、リサンプリングなどの8つがある。
DAGで表せる計算をAurora内部で実行し、その結果が接続するアプリケーションにわたる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Bridging Model for parallel Computation (1990)</title>
      <link>https://nryotaro.dev/posts/a_bridging_model_for_parallel_computation/</link>
      <pubDate>Sat, 11 Dec 2021 14:29:16 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_bridging_model_for_parallel_computation/</guid>
      <description>&lt;p&gt;バッチ処理グラフの最適化を目的として演算処理のバルク同期並列（bulk synchronous parallel、 BSP）を提唱した。
BPSは、Apache Giraph, Spark の GraphX API, Gelly APIで採用され、なかでもGoogleのPregelで知られるようになった&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873118703/&#34;&gt;*1&lt;/a&gt;。
BPSの目的は、ハードウェアと並列計算の高水準なプログラミングモデルがどちらもBPSに準ずることで、高水準なプログラミングモデルで実装された並列計算を多様なハードウェア上で動かすことにある。
フォン・ノイマンモデル型のコンピュータであれば、ハードウェアの種類を意識することなく、その上で逐次計算をおこなう多様なソフトウェアを動かせる。
フォン・ノイマンモデルは、多様なハードウェアと多様なソフトウェアをつなぐ。
BPSは、並列計算用のハードウェアと高水準な並列計算のプログラミングモデルをつなぐためにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wait-Free Synchronization</title>
      <link>https://nryotaro.dev/posts/wait_free_synchronization/</link>
      <pubDate>Sat, 27 Nov 2021 12:41:19 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/wait_free_synchronization/</guid>
      <description>&lt;p&gt;あるデータ構造がwait-freeであり、データ構造への操作が有限回のステップで完了するのであれば、ほかの並行プロセスの処理速度によらず、任意のプロセスによるその操作は必ず完了する。
表題のsynchronizationは、wait-freeであるデータ構造で別のwait-freeなデータ構造を実装することを意味する。
実装可能かを定義するためにコンセンサス数を導入する。
あるデータ構造のコンセンサス数は、単純な含意形成問題を解くときに参加できるプロセス数の最大値である。
たとえば、read / writeレジスタのコンセンサス数は1, test &amp;amp; swapは2, compare &amp;amp; swapは無限である。
プロセス数を定義した上で、あるコンセンサス数のデータ構造を、それより小さいコンセンサス数のデータ構造では実装できないことを示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Live Migration of Virtual Machines</title>
      <link>https://nryotaro.dev/posts/live_migration_of_virtual_machines/</link>
      <pubDate>Sat, 20 Nov 2021 19:53:45 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/live_migration_of_virtual_machines/</guid>
      <description>&lt;p&gt;XenのハイパーバイザーにOSのライブマグレーションを統合し、約60msのダウンタイムでのOSのライブマイグレーションを実現した。
手法の焦点は、どれだけ短いダウンタイムや移行時間で、移行元と移行先のメモリの状態を同等にできるかにある。
ネットワークアドレスや物理デバイスの移行はあつかわない。
移行元と移行先は同じローカルネットワークにあり、マイグレーションによるIPアドレスのホストの移動を主にARP replyで通知でき、NASにデータを保存することを前提にし、ネットワークや物理デバイスの移行を考えなくてよいものとしている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Critique of ANSI SQL Isolation Levels</title>
      <link>https://nryotaro.dev/posts/a_critique_of_ansi_sql_isolation_levels/</link>
      <pubDate>Sat, 13 Nov 2021 19:34:24 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_critique_of_ansi_sql_isolation_levels/</guid>
      <description>&lt;p&gt;ANSI SQL-92規格は、トランザクション分離レベルを、Dirty Read, Non-Repeatable Reads, Phantomが発生する可能性で定義する。
著者は、トランザクション分離レベルを禁止する現象で定義する理由を、ロックなどの実装手段で定義すると規格が実装依存になるからだと考えている。
表題の論文は、規格の現象による定義があいまいであり、3つの異常が起きなくても望まない結果になる実行があることを例示した。
また、規格のトランザクション分離レベルが、商用データベースで採用されているトランザクション分離レベルにあてはまらない問題もある。
禁止する現象にDirty Writeを規格に加え、厳しく実行列を制限するように現象の定義を解釈し、現象の説明を自然言語から形式的な記述に変えることを提唱した。
さらに、規格がデータの版が単一であることを前提としていることを指摘した上で、多版型のトランザクションであるSnaphot Isolationを提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Overview of Data Warehousing and OLAP Technology</title>
      <link>https://nryotaro.dev/posts/an_overview_of_data_warehousing_and_olap_technology/</link>
      <pubDate>Sat, 06 Nov 2021 21:10:04 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/an_overview_of_data_warehousing_and_olap_technology/</guid>
      <description>&lt;p&gt;データウェアハウスの概要と発表時期の97年の関連技術を解説した論文で、データウェアハウスの理論を提唱したInmonにならい、データウェアハウスを、目的指向(subject-oriented)で、統合され、組織の意思決定に資する永続的なデータとらえている。
関連技術を、ETL処理、データ保存方法、保存したデータによる分析の3つに分けて整理する。
データベースの設計手法では、Kimballの提唱したスタースキーマ、その応用のスノーフレークスキーマ, 事実の星座(fact constellations)、インデックスについてビットマップインデックスを解説する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Managing Update Conflicts in Bayou, a Weakly Connected Replicated Storage System</title>
      <link>https://nryotaro.dev/posts/bayou/</link>
      <pubDate>Sat, 06 Nov 2021 18:41:01 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bayou/</guid>
      <description>&lt;p&gt;Bayouは、モバイルコンピューティングむけに95年に発表されたストレージで、弱い一貫性とレプリケーションがある。
発表当時の不安定なモバイルネットワーク環境でもクライアントがストレージにアクセスできるように、一貫性を犠牲にしてクライアントにどんなレプリケーションへの読み書きも認める。
Bayouは、アプリケーションの知識を借りてデータの整合性を復元するアプローチを開拓したストレージとして知られ、書き込み時に開発者が実装した不整合を検知する処理を実行する。
不整合を検知したら、同じく開発者によって実装された不整合を解消する処理を実行する。
ただし、書き込みのログをほかのレプリケーションに伝搬することでデータを同期するため、どんなレプリケーションでも不整合の検知と解消の処理が同一の結果になるように、これらの処理は決定的でなければならない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Many Faces of Publish/Subscribe (2003)</title>
      <link>https://nryotaro.dev/posts/the_many_faces_of_publish_subscribe/</link>
      <pubDate>Sat, 30 Oct 2021 16:13:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_many_faces_of_publish_subscribe/</guid>
      <description>&lt;p&gt;分散システムの通信をpublish/subscribeモデルにするとシステム間の結合を疎にできる。
表題の論文は、publish/subscribeのサーベイであり、publish/subscribeモデルを空間、時間、同期の3種の結合度を下げる技術ととらえ、ほかの通信技術と比較する。
また、先行研究のpublish/subscribeモデルを、購読するイベントの宣言手段によって、topic-based, content-based, type-basedに分類する。
最後に、メッセージブローカーを使うかどうかなどpublish/subscribeモデルの設計や実装の利点や欠点を整理する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dryad: Distributed Data-Parallel Programs from Sequential Building Blocks</title>
      <link>https://nryotaro.dev/posts/dryad/</link>
      <pubDate>Sat, 23 Oct 2021 19:03:45 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dryad/</guid>
      <description>&lt;p&gt;DryadはMicrosoftで開発された分散コンピューティングエンジンであり、MapReduceに近い。
処理を点、処理結果を受け渡す通信経路を辺とするDAGで、分散処理を定義する。
通信経路にはファイル、TCP, FIFOを使え、実行環境は1台のマルチコアのコンピュータから数千台のコンピュータまでスケールできる。
MapReduceは入力と出力が一つでなければならないが、DryadはDAGであれば入力と出力が複数あってもかまわない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Chubby lock service for loosely-coupled distributed systems</title>
      <link>https://nryotaro.dev/posts/the_chubby_lock_service_for_loosely_coupled_distributed_systems/</link>
      <pubDate>Sat, 16 Oct 2021 15:16:55 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_chubby_lock_service_for_loosely_coupled_distributed_systems/</guid>
      <description>&lt;p&gt;Chubbyは、ファイルに助言ロックをかけられる低容量のストレージで、開発元のGoogleは分散システム向けのロックサービスとして使っている。
処理性能よりも高可用性と信頼性を重視し、ロックを保持する期間は数時間から数日にわたる長いものを想定する。
ロックされたファイルで情報を共有でき、例えばリーダーの選出に使える。
Chubbyは既存のアルゴリズムを集積であり、表題の論文は、新しいアルゴリズムよりも、Chubbyの設計や想定していた使用方法や想定外の使われ方に重点をおく。
Chubbyはロックサービスとして作られたが、ネームサーバとして最もよく使われる。
数千規模の互いに依存するプロセスがあり、プロセスが落ちたら新しいプロセスに置き換えるとする。
このとき、ネームサーバにDNSをつかうと、DNSは時間で失効するキャッシュ方式なので、TTLを短くし、落ちたプロセスにリクエストが届かないようにすると、DNSへの負荷が増える。
一方、Chubbyのキャッシュは時間ではなくファイルに変更されたときに無効になるので、Chubbyをネームサーバに使うことで、名前解決の負荷を減らすことができる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Congestion Avoidance and Control</title>
      <link>https://nryotaro.dev/posts/congestion_avoidance_and_control/</link>
      <pubDate>Sat, 09 Oct 2021 12:44:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/congestion_avoidance_and_control/</guid>
      <description>&lt;p&gt;86年の10月におきたインターネットの世界規模の輻輳の反省から、4BSDに7つのTCPの輻輳制御のアルゴリズムが導入された。
うち5つは、送信したパケットが到達や消失でネットワークに流れなくなるまで、ウィンドウサイズ以上の新しいパケットを送らない原則を守るためにある。
この原則をconservation of packets principleという。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Notion of Consistency and Predicate Locks in a Database System</title>
      <link>https://nryotaro.dev/posts/the_notion_of_consistency_and_predicate_locks_in_a_database_system/</link>
      <pubDate>Sat, 02 Oct 2021 16:24:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_notion_of_consistency_and_predicate_locks_in_a_database_system/</guid>
      <description>&lt;p&gt;トランザクションを並行実行するときに、直列実行した場合と同じ実行結果をえるには、各トランザクションがロックを解放後に新しいロックを獲得してはならないことを示した。
その場合もデッドロックがおきうるが、それは並列実行を終了するためにはいつロックをかければよいかという議論である。
ここでは、並列実行が終了した場合に直列実行と同じ結果になる一貫性を保証できるロックの順序を問う。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Parallel Database Systems: The Future of High Performance Database Systems (1992)</title>
      <link>https://nryotaro.dev/posts/parallel_database_systems/</link>
      <pubDate>Sat, 25 Sep 2021 13:09:34 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/parallel_database_systems/</guid>
      <description>&lt;p&gt;データベースの処理性能を上げる方法として、汎用的なコンピュータによる水平パーティションのシェアードナッシング構成を主張した。
特殊なハードウェアを使ったり、メモリ、ディスクを共有する複数のコンピュータを使ったりするよりも、単純で安く実装できる。
論文が発表された1992年の時点でTeradataやTandem NonStopなどのパーティンション化されたデータベースがある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chain Replication for Supporting High Throughput and Availability</title>
      <link>https://nryotaro.dev/posts/chain_replication_for_supporting_high_throughput_and_availability/</link>
      <pubDate>Sat, 18 Sep 2021 15:34:12 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/chain_replication_for_supporting_high_throughput_and_availability/</guid>
      <description>&lt;p&gt;ストレージサーバーに順番をつけ、順にオブジェクトを複製することで、ストレージサービスの一貫性を維持しつつスループットと可用性の向上をはかる。
ここでのストレージサービスは、オブジェクトを保存し、クエリに対して一つのオブジェクトを返し、アトミックに一つのオブジェクトを更新できるものをさす。
また、一貫性は、オブジェクトごとにクエリと更新を直列的に適用し、更新につづくクエリが更新内容になることを意味する。
末尾のサーバーがクエリを受信し、該当するオブジェクトをクライアントに返す。
先頭のサーバーが更新リクエストを受信し、順にサーバーのオブジェクトを更新し、末尾のサーバーが更新の結果をクライアントに返す。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Implementing Remote Procedure Calls</title>
      <link>https://nryotaro.dev/posts/implementing_remote_procedure_calls/</link>
      <pubDate>Sat, 11 Sep 2021 12:34:19 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/implementing_remote_procedure_calls/</guid>
      <description>&lt;p&gt;Xeroxのプログラミング環境&lt;a href=&#34;http://www.bitsavers.org/pdf/xerox/parc/techReports/CSL-80-10_Requirements_for_an_Experimental_Programming_Environment.pdf&#34;&gt;Cedar&lt;/a&gt;のために開発されたRPCを解説した84年の論文。
RPCの開発目的は、分散コンピューティングを簡単に実装できるようにする、通信時間を短くする、通信をセキュアにすることの3点にある。
RPCは大部分で&lt;a href=&#34;http://www.bitsavers.org/pdf/xerox/parc/techReports/CSL-79-3_Mesa_Language_Manual_Version_5.0.pdf&#34;&gt;Mesa&lt;/a&gt;が使われた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dremel: Interactive Analysis of Web-Scale Datasets</title>
      <link>https://nryotaro.dev/posts/dremel/</link>
      <pubDate>Sat, 04 Sep 2021 15:55:14 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dremel/</guid>
      <description>&lt;p&gt;Dremelは2006年からGoogle社内で利用されているDWHで、社外にはBigQueryとして提供されている。
列指向の形式でデータを保存し、SQLに似た言語のクエリでデータを検索できる。
Dremelは、サーバーのクラスタを木構造に組織し、ルートで受理したクエリの処理を下層のサーバに分配し、その結果を集約することで処理を分散し高速化をはかる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Is Rust Used Safely by Software Developers?</title>
      <link>https://nryotaro.dev/posts/is_rust_used_safely_by_software_developers/</link>
      <pubDate>Fri, 27 Aug 2021 17:51:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/is_rust_used_safely_by_software_developers/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://crates.io/&#34;&gt;crates.io&lt;/a&gt;に登録された15,097個のクレートにおける&lt;code&gt;unsafe&lt;/code&gt;キーワードの使用状況を調べた。
調査したクレートは、調査を開始した2018年9月時点で&lt;a href=&#34;https://crates.io/&#34;&gt;crates.io&lt;/a&gt;に登録された全クレートの81%にあたる。
&lt;code&gt;unsafe&lt;/code&gt;を含むクレートは、そのうちの29%だったが、依存するクレートにある&lt;code&gt;unsafe&lt;/code&gt;も対象にすると、50%におよぶ。
&lt;a href=&#34;https://crates.io/&#34;&gt;crates.io&lt;/a&gt;の総ダウンロード数のうち90%を占める473個の有名なクレートに限定すると、60%のクレート&lt;code&gt;unsafe&lt;/code&gt;が含まれる。
2018年9月から2019年6月までの10ヶ月間で&lt;code&gt;unsafe&lt;/code&gt;の使用傾向に変化はなく、&lt;code&gt;unsafe&lt;/code&gt;の数が少し増えただけであった。
&lt;code&gt;unsafe&lt;/code&gt;の用途の大半は&lt;code&gt;unsafe&lt;/code&gt;で修飾されたRustの関数を呼び出すためだった。
なお、コンパイラで生成された&lt;code&gt;unsafe&lt;/code&gt;キーワードは集計に含まれていない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Design Tradeoffs for SSD Performance</title>
      <link>https://nryotaro.dev/posts/design_tradeoffs_for_ssd_performance/</link>
      <pubDate>Mon, 23 Aug 2021 12:03:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/design_tradeoffs_for_ssd_performance/</guid>
      <description>&lt;p&gt;HDDの処理性能を測定するシミュレーションソフト&lt;a href=&#34;https://www.pdl.cmu.edu/DiskSim/index.shtml&#34;&gt;DiskSim&lt;/a&gt;をSSD向けに改造し、SSDの設計における選択肢の分類と選択にともなうトレードオフを報告した。
主要な選択肢は、論理アドレスと物理アドレスのマッピング、ページサイズ、オーバープロビジョニング、複数のpackageでcontrollerに接続するピンを共有するgangingがある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Program Comprehension and Code Complexity Metrics: An fMRI Study</title>
      <link>https://nryotaro.dev/posts/program_comprehension_and_code_complexity_metrics/</link>
      <pubDate>Sat, 21 Aug 2021 16:13:15 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/program_comprehension_and_code_complexity_metrics/</guid>
      <description>&lt;p&gt;コードの複雑さのメトリクスがコードを理解する難しさの指標になるかは疑問視されてきた。
19人の被験者に16個のソースコードを読ませ、関数の返り値を回答してもらい、作業中の脳の状態をfMRIで観察することで、メトリクスと回答時間、正答率、脳の活性状態の相関関係を調べた。
メトリクスと主観的な評価を比較するために、回答後に被験者にコードの複雑さを評価してもらった。
調べたメトリクスは、41種類あり、コードの行数(LOC), 語彙の多さ(Halstead), とりえる実行パスの数(McCabe), 依存するデータの数(DepDegree)の4種類に大別できる。
相関関係をケンドールの順位相関係数\(\tau\)で評価し、相関なし(\(\tau &amp;lt;0.1\)), 弱い(\(0.1 &amp;lt; \tau &amp;lt; 0.3\)), 中(\(0.3 &amp;lt; \tau &amp;lt;0.5\)), 強い(\(0.5&amp;lt;\tau\))とみなす。&lt;/p&gt;
&lt;p&gt;回答と脳の活性状態と相関関係にあったメトリクスはDepDegreeだったが、被験者の主観的な評価のほうが強い相関がみられた。
LOC, Halstead, DepDeegreeは回答時間や正答率と弱い〜中程度の相関があった。
この3つのメトリクスは脳の活性度合いと弱から中の相関があり、活性度合いと正答率には強い相関、回答時間には弱から中の相関があった。
一方、主観的な評価は、メトリクスと弱い相関があり、問題の正答率や脳の活性状態と強い相関関係があった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The UNIX Time-Sharing System</title>
      <link>https://nryotaro.dev/posts/the_unix_time_sharing_system/</link>
      <pubDate>Sat, 21 Aug 2021 13:11:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_unix_time_sharing_system/</guid>
      <description>&lt;p&gt;デニス・リッチーとケン・トンプソンによるPDP-11/40, /45, /70で採用されたUnixのファイルシステムとコマンドラインインターフェースの解説である。
PDP-11は1971年2月から運用がはじまり、当初はアセンブリ言語で実装されていたが、1973年の夏にCで再実装された。
ファイルシステムは、UNIXの最も重要な役割に位置づけられ、特殊ファイルによるI/Oデバイスの抽象化、外部ディスクのマウント、ファイルの権限、i-nodeをふくむ多くの特徴が今日まで引き継がれている。
2人は、UNIXの設計に影響したものとして、プログラマとして対話的なインターフェースを望んでいたこと、ハードウェアの低い性能ゆえにソフトウェアの設計を洗練させる必要があったこと、ソースコードをUNIX上で編集し簡単にプログラムを変更できたことをあげている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>What helped, and what did not? An Evaluation of the Strategies to Improve Continuous Integration</title>
      <link>https://nryotaro.dev/posts/what_helped_and_what_did_not/</link>
      <pubDate>Fri, 20 Aug 2021 17:58:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/what_helped_and_what_did_not/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://travistorrent.testroots.org/&#34;&gt;TravisTorrent&lt;/a&gt;にある100件のプロジェクトで10種類のCIのテクニックを定量評価した。
テクニックは、不要なビルドやテストをスキップするか、実行順序を優先づけるものかに分かれる。
前者は計算資源の消費を減らすこと、後者は失敗するケースを早めに実行することを目的にする。
もっとも成功するテストやビルドをスキップできたテクニックは、コードに変更のないケースをスキップするものだったが、同時に失敗するテストを多く見落とした。
実行順序を優先付ける手法で最も性能のよかったテクニックは、&lt;a href=&#34;https://www.semanticscholar.org/paper/Static-test-case-prioritization-using-topic-models-Thomas-Hemmati/ad77a2776733c7fdc10c0b043f7504a14fce3b6e&#34;&gt;Thomasら&lt;/a&gt;のもので、シグネチャやコメントで学習したトピックモデルを使い直前に実行したテストと違うトピックのテストを実行する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rumors Roble Bodegas Rumors</title>
      <link>https://nryotaro.dev/gallery/rumors/</link>
      <pubDate>Sun, 15 Aug 2021 23:00:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/rumors/</guid>
      <description>渋い。</description>
    </item>
    
    <item>
      <title>Don&#39;t Do That! Hunting Down Visual Design Smells in Complex UIs against Design Guidelines</title>
      <link>https://nryotaro.dev/posts/dont_do_that/</link>
      <pubDate>Sat, 14 Aug 2021 16:40:58 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dont_do_that/</guid>
      <description>&lt;p&gt;2020年5月時点のマテリアルデザインの公式ドキュメントから93種類の不吉な匂いを洗い出し、71種類の匂いを検出するツールUIS-Hunterを開発した。
文中に&amp;quot;don&amp;rsquo;t&amp;quot;や&amp;quot;caution&amp;quot;があることとUIの画像があることを条件に不吉な匂いを選び、9,286個のアンドロイドアプリにある7,497のUIを調べたところ、2,587個のアプリから1つ以上の不吉な匂いのあるUIが見つかった。
UIS-Hunterは、FigmaやAndroid Studio Layout EditorなどのモックアップやAndroid UI AutomatorやSeleniumのスクリーンショットから不吉な匂いを解析し、UIのソースコードを必要としない。
9,286個のアプリの60,756のUIで検出性能を評価したところ、precisionが0.81, recallが0.90だった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>An Empirical Analysis of UI-based Flaky Tests</title>
      <link>https://nryotaro.dev/posts/an_empirical_analysis_of_ui-based_flaky_tests/</link>
      <pubDate>Sat, 14 Aug 2021 16:33:14 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/an_empirical_analysis_of_ui-based_flaky_tests/</guid>
      <description>GitHub上の5つのWebアプリケーションと37のAndroidアプリケーションから集めた235件のUIのflaky tests（何度か実行すると成功する不安定なテスト）を調査し、原因と修正を分類した。
大きく原因を、非同期処理の待機、環境依存の動作、DOMのセレクタやテストライブラリの誤用、テスト対象の事前条件を満たしていないテストスクリプトの4つに大別した。 具体例をあげると、環境依存の動作には、IE固有のバグや予期していないレイアウトで画面が表示される場合、テストの事前条件については、テストの実行順序次第で誤ったテストデータが作られる場合がある。 最も多くのテストが分類され、全体の45%を占めたのは、非同期処理の不適切な待機方法だった。
修正のパターンには、待機時間の追加、テスト用APIの誤用の修正やAPIのアップグレード、テストスクリプトのリファクタリング、アニメーションの削除、不要なテストの削除がある。
論文をこちらからダウンロードできます。</description>
    </item>
    
    <item>
      <title>A Case Study of Onboarding in Software Teams: Tasks and Strategies</title>
      <link>https://nryotaro.dev/posts/a_case_study_of_onboarding_in_software_teams/</link>
      <pubDate>Sat, 14 Aug 2021 16:31:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_case_study_of_onboarding_in_software_teams/</guid>
      <description>&lt;p&gt;オンボーディングのためのタスクの選び方とタスクの効果を調査するために、マイクロソフトのエンジニアとマネージャーにインタビューした。
まず、新しいチームに入った32人のエンジニアとエンジニアを迎えた15人のマネージャーにインタビューし、特に、チームのことを知る、担当する役割を果たせる自信の醸成、メンバーとの交流の3つを重視し、これらに対するタスクの影響を調査した。
タスクの選び方は、大きく、割り当てるタスクを少しずつ複雑にする、優先度の高いものを選ぶ、曖昧なタスクを選ぶ、の3つがあった。
オンボーディングするエンジニアがジュニアであれば最初の選び方、シニアであれば最後の選び方、アジャイルを採用するチーム、新しいチーム、納期の厳しいチームは優先度でタスクが選ばれやすく、効果的であった。
以上の考察を189名のエンジニアと37名のマネージャに評価してもらい、妥当性を確認した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>A Differential Testing Approach for Evaluating Abstract Syntax Tree Mapping Algorithms</title>
      <link>https://nryotaro.dev/posts/a_differential_testing_approach_for_evaluating_ast_mapping_algorithms/</link>
      <pubDate>Sat, 14 Aug 2021 16:29:33 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_differential_testing_approach_for_evaluating_ast_mapping_algorithms/</guid>
      <description>&lt;p&gt;AST mappingは、コードの変更前後のASTを比べてノードの対応関係を見つける手法であり、変更差分検出に使われる。 現状、対応関係の精度を自動で評価する有効な方法はなく、評価には人手による手間がかかる。 多くのノードに1対1の対応関係があることに着目し、異なる2つのAST mappingを同じ変更に適用した結果を比べ、個別の文やトークンごとに、より正確な方を推定するアルゴリズムを提案した。 これを応用し、複数のAST mappingアルゴリズムに同じファイルの変更差分を入力し、アルゴリズムごとの不正確に検出した箇所を自動で推定できることを示した。 特定性能は、Precisionが0.98-1.00, Recallは0.65-0.75だった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>“Ignorance and Prejudice” in Software Fairness</title>
      <link>https://nryotaro.dev/posts/ignorance_and_prejudice_in_software_fairness/</link>
      <pubDate>Sat, 14 Aug 2021 16:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/ignorance_and_prejudice_in_software_fairness/</guid>
      <description>&lt;p&gt;特徴の種類を増やすと、機械学習の予測の公平性と精度を改善できることを5つのデータセットで例示した。 データセットのタスク内容は、性別、人種、年齢を特徴に含み、経済的な裕福さや再犯率を予測するもの。 他方、教師データの数を増やしても公平性は改善されなかった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Time, Clocks, and the Ordering of Events in a Distributed System</title>
      <link>https://nryotaro.dev/posts/time_clocks_and_the_ordering_of_events_in_a_distributed_system/</link>
      <pubDate>Sat, 14 Aug 2021 14:18:01 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/time_clocks_and_the_ordering_of_events_in_a_distributed_system/</guid>
      <description>&lt;p&gt;分散システムの各プロセスにおける送受信の半順序関係をすべてのプロセスで起きた送受信の全順序関係に拡張するアルゴリズムを提案し、アルゴリズムを同期処理に応用できることを例示した。
分散システムではプロセスの時刻が同期しているとはかぎらない。
各プロセスで起きたメッセージの送受信をプロセスでの時刻順に並べられても、その計測時刻を信じて全プロセスで起きたイベントを正しく発生順に並べることはできない。&lt;/p&gt;
&lt;p&gt;アルゴリズムは、プロセスごとに論理的なクロックをもたせる。
クロックは、メッセージを送信するときに時を進める。
メッセージを送信するプロセスは、送信時刻をメッセージにふくめる。
受信したプロセスは現在の時刻とメッセージにある送信元の時刻より先の時刻に時を進める。
以上の手続きで、異なるプロセス間の送受信であっても送信時刻が受信時刻より必ず前になり、全プロセスの送受信イベントに全順序関係を定義できる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, unbounded, Out-of-Order Data Processing</title>
      <link>https://nryotaro.dev/posts/dataflow/</link>
      <pubDate>Sat, 07 Aug 2021 15:11:48 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dataflow/</guid>
      <description>&lt;p&gt;データ処理サービスは、処理の正確さ、遅延、システムの複雑さの間にトレードオフを抱える。
ストリーミング処理サービスのStorm, Samza, Pulsarは、(論文が発表された2015年時点では)メッセージ配信がexactly-onceではなく欠損や重複する。
MapReduceやSparkなどのバッチ処理サービスは、バッチ処理の単位までデータが集まらなければバッチ実行できない。
Lambda architectureは、システムの複雑化を許容し、2つのアーキテクチャを使い分けることで、処理の正確さと遅延のバランスをとる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Playing Planning Poker in Crowds: Human Computation of Software Effort Estimates</title>
      <link>https://nryotaro.dev/posts/playing_planning_poker_in_crowds/</link>
      <pubDate>Fri, 06 Aug 2021 13:44:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/playing_planning_poker_in_crowds/</guid>
      <description>&lt;p&gt;プランニングポーカーのように、ソフトウェア開発の工数を見積もる手法の前提には、プロジェクトに一定期間在籍する専門家がいることがある。
しかし、OSS開発はその限りではなく、見積りの対象になるイシューの数は多い。
各イシューの見積りに5分から10分時間をかけるなら、Linux Kernelのバックログを見積りきるのに半年がかかる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Villa Yambol Cabernet Sauvignon</title>
      <link>https://nryotaro.dev/gallery/villa_yambol/</link>
      <pubDate>Wed, 04 Aug 2021 13:09:11 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/villa_yambol/</guid>
      <description>渋みがなく、飲みやすい。飲みやすくて、記憶に残りにくいけどおいしい。</description>
    </item>
    
    <item>
      <title>The Byzantine Generals Problem</title>
      <link>https://nryotaro.dev/posts/the_byzantine_generals_problem/</link>
      <pubDate>Sat, 31 Jul 2021 11:07:42 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_byzantine_generals_problem/</guid>
      <description>&lt;p&gt;ビザンチン将軍問題は、故障したコンポーネントがほかのコンポーネントに誤ったメッセージを送りうるとき、コンポーネント間でメッセージを交換した結果、すべてのコンポーネントが一つの正しいメッセージを合意する問題をあつかう。
アルゴリズムは、署名付きメッセージを使うものと使わないものの2つがある。
署名付きメッセージを使うと、受信したメッセージが改ざんされたかをコンポーネントが判断できる。
署名を使わない場合、3分の2より多くのコンポーネントが正常でなければシステム全体が正しい1つのメッセージについて合意にできないことを示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chateau La Croix Blanche</title>
      <link>https://nryotaro.dev/gallery/chateau_la_croix_blanche2/</link>
      <pubDate>Mon, 26 Jul 2021 10:04:27 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/chateau_la_croix_blanche2/</guid>
      <description>酸味はあまりない。少し渋い。</description>
    </item>
    
    <item>
      <title>The Browsemaps: Collaborative Filtering at LinkedIn</title>
      <link>https://nryotaro.dev/posts/browsemaps/</link>
      <pubDate>Thu, 22 Jul 2021 13:01:15 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/browsemaps/</guid>
      <description>&lt;p&gt;Browsemapsは、LinkedInのアイテムベースで水平型の協調フィルタリングである。
Browsemapは、LinkedInの画面上にある推薦するコンテンツを並べたコンポーネントを意味する。
ここでの水平型は特徴の種類の違いによらず異なるエンティティを統一的に扱えることであり、実際に、人、仕事、会社など複数のエンティティをBrowsemapsでユーザに推薦している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Casal di Serra</title>
      <link>https://nryotaro.dev/gallery/casal_di_serra2/</link>
      <pubDate>Mon, 19 Jul 2021 23:19:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/casal_di_serra2/</guid>
      <description>やっぱり記憶に残らない。</description>
    </item>
    
    <item>
      <title>Linearizability: A Correctness Condition for Concurrent Objects</title>
      <link>https://nryotaro.dev/posts/linearizability/</link>
      <pubDate>Sat, 17 Jul 2021 13:31:07 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/linearizability/</guid>
      <description>&lt;p&gt;オブジェクトを読み書きする並行プロセスの実行系列があるとき、読み書き操作がアトミックであるように観測でき、かつ、プロセスの実行を仮に直列化したときと同じ実行結果をえられる条件を示し、これを線形化可能性とよんだ。
線形化可能性は、直列化可能性と同様に安全性の条件だが、直列化可能性にはないローカル性がある。
いいかえると、各オブジェクトが線形化可能かつそのとき限り、システム全体が線形化可能になる。
また、ローカル性だけでなく、ノンブロッキング性もあり、操作がオブジェクトの任意の状態において定義されていれば、受信したリクエストの操作を保留しているオブジェクトは別オブジェクトの保留した操作の完了を待たずに自分の操作を進行できる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>END-TO-END ARGUMENTS IN SYSTEM DESIGN</title>
      <link>https://nryotaro.dev/posts/end_to_end_arguments_in_system_design/</link>
      <pubDate>Sat, 10 Jul 2021 15:15:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_arguments_in_system_design/</guid>
      <description>&lt;p&gt;分散システムのあるシステムから発せられた通信は、システムより低いレイヤーのネットワークを通り、ほかのシステムに到達する。
論文の発表当時から、分散システムの信頼性にかかわる機能には、途中の低レイヤーではなく高レイヤーの終端におくべきものがあると知られていた。
表題の論文は、それらを列挙し、END-TO-END ARGUMENTSと名付け、原則として提示する。
例えば、データの完全性の保証、メッセージの重複対応、メッセージが到達したことの保証が原則にあてはまる。
これらの機能を途中の低レイヤーにおくと、検証後の経路でメッセージが壊れた場合、送信元が重複メッセージをおくる場合、対向システムが受信したメッセージを処理できない場合に対処できない。
分散システム全体の信頼性をあげるのであれば、信頼性を上げる機能を低レイヤーではなく終端の高レイヤーにおくほうが効率がよい。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Goose Bump</title>
      <link>https://nryotaro.dev/gallery/goose_bump/</link>
      <pubDate>Sat, 10 Jul 2021 15:02:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/goose_bump/</guid>
      <description>甘い。この一言につきる。こんなに甘い赤ワインがあるんだって驚き。</description>
    </item>
    
    <item>
      <title>Casal di Serra</title>
      <link>https://nryotaro.dev/gallery/casal_di_serra/</link>
      <pubDate>Sat, 03 Jul 2021 23:51:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/casal_di_serra/</guid>
      <description>辛くもなく、樽香もないワイン。抑揚のないワインで、嫌いではないが、記憶に残らないのでまた買いたいという気にはならない。</description>
    </item>
    
    <item>
      <title>Chateau La Croix Blanche</title>
      <link>https://nryotaro.dev/gallery/chateau_la_croix_blanche/</link>
      <pubDate>Sat, 03 Jul 2021 23:43:55 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/chateau_la_croix_blanche/</guid>
      <description>なぜかまとめて２つ買ってしまったやつ。酸味と渋みのどちらにも偏りがなくて飲みやすい。 飲みやすくておいしいのは分かるけど、あまりに個性がなくて「これを飲みたい」みたいな気にならないのが残念。 ただ、美味しいのは確か。</description>
    </item>
    
    <item>
      <title>A History and Evaluation of System R</title>
      <link>https://nryotaro.dev/posts/a_history_and_evaluation_of_systemr/</link>
      <pubDate>Sat, 03 Jul 2021 15:02:21 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_history_and_evaluation_of_systemr/</guid>
      <description>&lt;p&gt;System Rは、1970年に発表されたリレーショナルモデルを実装した初めてのリレーショナルデータベースである。
1981年に発表された表題の論文は、System Rの開発プロジェクトを3つのフェーズに分け各フェーズごとにえられた知見をまとめている。
Phase 0は、74年から75年にかけて、シングルユーザ向けにSQLサブセットと対話的なインターフェースを開発した期間にあたる。
Phase 1は、76年から77年の、Phase 0のコードを破棄し、マルチユーザに対応しSystem Rの機能を完全に実装するまでの期間である。
Phase 2は、78年から79年にSan Jose Research Laboratoryなどでの実用にもとづく評価期間にあたる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>beamerのスタイルファイル rei.sty</title>
      <link>https://nryotaro.dev/posts/rei/</link>
      <pubDate>Sat, 26 Jun 2021 17:15:24 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/rei/</guid>
      <description>&lt;p&gt;日本語用のbeamerスライドのデザインを作った。
飽きないように単純なデザインにした。
デモは&lt;a href=&#34;https://nryotaro.dev/rei.pdf&#34;&gt;こっち&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AtCoder Beginner Contest 206 D KAIBUNsyo</title>
      <link>https://nryotaro.dev/posts/atcoder_abc206d/</link>
      <pubDate>Sun, 20 Jun 2021 12:59:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/atcoder_abc206d/</guid>
      <description>&lt;p&gt;Union Findを使うと通せる。すべての\(A_i\)と\(A_{N+1-i}\)が同じグループに所属するために必要なunionの回数を答えればいい。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web</title>
      <link>https://nryotaro.dev/posts/consistent_hashing_and_random_trees/</link>
      <pubDate>Sat, 19 Jun 2021 14:41:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/consistent_hashing_and_random_trees/</guid>
      <description>&lt;p&gt;各サーバーがネットワーク全体の情報を保持しない分散キャッシュネットワークにホットスポットを生まないためのキャッシュプロトコルを開発した。
表題のconsistent hashingは、プロトコルの基礎になるハッシュ関数で、関数の写像が値域の違いに影響されにくい。
この影響しにくさは、クライアントから見えるアクティブなサーバが入れ替わる可能性に対して機能する。
また、クライアントは一部のキャッシュサーバーにアクセスできればよく、クライアントごとにアクセス可能なキャッシュサーバーの集合は違ってよい。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Navaelus Bodega Inurrieta</title>
      <link>https://nryotaro.dev/gallery/navaelus_bodega_inurrieta/</link>
      <pubDate>Sat, 19 Jun 2021 14:39:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/navaelus_bodega_inurrieta/</guid>
      <description>すごい飲みやすい。また買いたい。</description>
    </item>
    
    <item>
      <title>Vine In Flames Chardonnay Ville</title>
      <link>https://nryotaro.dev/gallery/vine_in_flames_chardonnay_ville/</link>
      <pubDate>Sat, 19 Jun 2021 14:32:27 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/vine_in_flames_chardonnay_ville/</guid>
      <description>辛口でもなく、樽香をつけてもないシャルドネそのままの感じがする。辛口ではないシャルドネの中では一番好きかもしれない。</description>
    </item>
    
    <item>
      <title>AtCoder Begineer Contest 051 D - Candidates of No Shortest Paths</title>
      <link>https://nryotaro.dev/posts/abc051d/</link>
      <pubDate>Mon, 14 Jun 2021 11:04:07 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/abc051d/</guid>
      <description>&lt;p&gt;ワーシャルフロイト法で全ての2頂点間の最短距離を求めた後、隣接する2頂点の辺のうち、2頂点の最短距離が辺の重みと異なる辺を数えれば通る。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AtCoder Beginner Contest 205 D - Kth Excluded</title>
      <link>https://nryotaro.dev/posts/abc205d/</link>
      <pubDate>Mon, 14 Jun 2021 10:56:35 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/abc205d/</guid>
      <description>&lt;p&gt;\(K_q\)ごとに二部探索で答えを直接検索しても通すことができる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Windows Azure Storage: A Highly Available Cloud Storage Service with Strong Consistency</title>
      <link>https://nryotaro.dev/posts/windows_azure_storage/</link>
      <pubDate>Sat, 12 Jun 2021 17:21:52 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/windows_azure_storage/</guid>
      <description>&lt;p&gt;AzureのクラウドストレージサービスWindows Azure Storage(WAS) は、2008年の11月から本番運用されている。
保存できるデータの形式には、単なるファイル(Blob)だけでなく、テーブルのレコードとキューのメッセージがある。
ハードウェアの故障に備えたローカルでのレプリケーションだけでなく、地理的に離れたデータセンタにもレプリケーションを分散し、災害復旧にも備える。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Aves Del Sur</title>
      <link>https://nryotaro.dev/gallery/aves_del_sur/</link>
      <pubDate>Sat, 12 Jun 2021 17:11:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/aves_del_sur/</guid>
      <description>樽香が効いたチリワイン。開けたときの香りですぐにオークドシャルドネと分かるくらい香りがある。 美味しかった。</description>
    </item>
    
    <item>
      <title>Ilpasso</title>
      <link>https://nryotaro.dev/gallery/ilpasso/</link>
      <pubDate>Sat, 05 Jun 2021 17:03:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/ilpasso/</guid>
      <description>こういうモノクロの単純なラベルの赤に惹かれる。少し渋い感じがちょうどよくて好き。 寝る前の夜中の3時にあけて味わわずに飲んでしまったのが惜しい。</description>
    </item>
    
    <item>
      <title>Thrift: Scalable Cross-Language Services Implementation</title>
      <link>https://nryotaro.dev/posts/thrift/</link>
      <pubDate>Sun, 30 May 2021 19:59:48 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/thrift/</guid>
      <description>&lt;p&gt;ThriftはFacebookで開発されたRPCライブラリで、IDLからクライアントとサーバのコードを生成する。
Thrift自体は、大きくType, Transport, Protocol, Versioning, Processorの5つのコンポーネントからなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>The End of an Architectural Era (It&#39;s Time for a Complete Rewrite)</title>
      <link>https://nryotaro.dev/posts/the_end_of_an_architectural_era/</link>
      <pubDate>Sat, 29 May 2021 20:54:27 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_end_of_an_architectural_era/</guid>
      <description>&lt;p&gt;発表時期は2007年で、RDBMSの源流であるSystem Rが開発された70年代からハードウェアの性能や価格が変わったことを背景に、RDMSのアーキテクチャを既存技術の延長ではなく抜本から刷新し、いわゆるNoSQLを開発する必要性を主張している。
第一著者のMichael Stonebrakerは、後の2011年に今日全てのデータベースの要件をRDMSだけでは満たすことができないと主張する論文&lt;a href=&#34;https://cs.brown.edu/~ugur/fits_all.pdf&#34;&gt;&amp;ldquo;One Size Fits All&amp;rdquo;&lt;/a&gt;を出している。
表題の論文では、OLTPに特化したデータベースH-Storeを実装し、TPC-Cをベンチマークとして商用データベースと比較したところ、H-Storeの方が82倍高速だった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>C tes Du Roussillon Mas Las Cabes Domaine Gardi s</title>
      <link>https://nryotaro.dev/gallery/c_tes_du_roussillon_mas_las_cabes_domaine_gardi_s/</link>
      <pubDate>Sat, 29 May 2021 20:51:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/c_tes_du_roussillon_mas_las_cabes_domaine_gardi_s/</guid>
      <description>シラー。今までのんだシラーの中で一番好きかも。普段飲んでいるものより少し高いのが残念。</description>
    </item>
    
    <item>
      <title>Barista Chardonnay Bertus Fourie</title>
      <link>https://nryotaro.dev/gallery/barista_chardonnay_bertus_fourie/</link>
      <pubDate>Sat, 22 May 2021 19:05:11 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/barista_chardonnay_bertus_fourie/</guid>
      <description>樽香のあるシャルドネ。でもそこまで香りがきつくない。ちょうどいい。このくらいの香りがだめな人なら香りのついたシャルドネはダメかも。</description>
    </item>
    
    <item>
      <title>Burst Tries: A Fast, Efficient Data Structure for String Keys</title>
      <link>https://nryotaro.dev/posts/burst_tries/</link>
      <pubDate>Sat, 22 May 2021 02:32:18 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/burst_tries/</guid>
      <description>&lt;p&gt;trie木の一種のburst trieは、2分木よりもメモリ効率がよく、trie木と同じくらい速い。
内部は2種類のデータ構造からなり、trie木のほかに別のデータ構造もつかう。
どのデータ構造を使うかは要件次第で、実験では、連結リスト、二分探索木、スプレー木をつかった。
Burst trie内の別のデータ構造はcontainerとよばれる。
初期状態のburst trieは、1つのcontainerからなり、別のデータ構造そのものに等しい。
その後、containerの要素のアクセス頻度やヒット率にもとづくヒューリスティックな基準が満たされると、containerの要素をtrie木のノードにおきかえ、ノードの下に新しいcontainerをつくる。
新しくできたcontainerにも基準を適用し、適宜containerをtrieのノードにおきかえる。
以上の手続きより、与えられる文字列の頻度に合わせてtrie木と別のデータ構造を使い分けることができる。
性能はデータ分布の歪度に依存する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Suffix Arrays: A New Method for On-Line String Searches</title>
      <link>https://nryotaro.dev/posts/suffix_arrays/</link>
      <pubDate>Sun, 16 May 2021 01:45:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/suffix_arrays/</guid>
      <description>&lt;p&gt;接尾辞配列 Suffix Arrayは、長さ\(P\)の文字列が長さ\(W\)の文字列のどこに出現するかを時間計算量\(\mathcal{O}(P + \log N)\)で判定できるデータ構造で、接尾辞木 suffix treeよりもメモリ効率が3-5倍よい。
一方、検索の準備にかかる最悪時間計算量はsuffix treeよりも大きい。
suffix arrayの構築にかかる最悪時間計算量が\(\mathcal{O}(N\log N)\)に対して、suffix treeは\(\mathcal{O}(N)\)しかかからない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Reserva Dos Amigos Touriga Nacional Vidigal Wines</title>
      <link>https://nryotaro.dev/gallery/reserva_dos_amigos_touriga_nacional_vidigal_wines/</link>
      <pubDate>Sun, 16 May 2021 01:39:11 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/reserva_dos_amigos_touriga_nacional_vidigal_wines/</guid>
      <description>ラベルは渋そうな感じだけど、少しスパイシーで果実味がある。おいしい。また買いたい。でもラベルがそんなに好みじゃない。</description>
    </item>
    
    <item>
      <title>リトル　ジェームズ　バスケット　プレス　ホワイト</title>
      <link>https://nryotaro.dev/gallery/little_james_basket_press_white/</link>
      <pubDate>Sun, 09 May 2021 11:09:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/little_james_basket_press_white/</guid>
      <description>辛口の白。変な樽香のない感じでおいしい。 ただ辛口の白で香りのないものはみんな同じ味に感じる。 そうなると値段で選んだほうがいいのかな。</description>
    </item>
    
    <item>
      <title>論文メモ HyperDex: A Distribute, searchable Key-Value Store</title>
      <link>https://nryotaro.dev/posts/hyperdex/</link>
      <pubDate>Fri, 07 May 2021 18:10:27 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/hyperdex/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://dbdb.io/db/hyperdex&#34;&gt;HyperDex&lt;/a&gt;はキー以外の要素で値を検索できるキーバリューストアで、このキー以外の要素による検索速度がCassandraやMongoDBと比べて12-13倍速い。
キーバリューストアは、RDBMSとくらべて、処理速度は速く、検索条件の機能に乏しい。
HyperDexは、要素数と同数の次元からなるユークリッド空間を構成し、要素のハッシュ値で決まる座標に値をおくことで、キー以外でも高速に検索することを可能にする。
もとのドメインの順序関係を保持するハッシュ関数を使うため、範囲検索もあつかえる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Honoro Vera Organically Bodegas Juan Gil</title>
      <link>https://nryotaro.dev/gallery/honoro_vera_organically_bodegas_juan_gil/</link>
      <pubDate>Wed, 05 May 2021 13:03:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/honoro_vera_organically_bodegas_juan_gil/</guid>
      <description>オーガニックななんちゃらかんちゃら。少し渋い。</description>
    </item>
    
    <item>
      <title>50° Riesling trocken</title>
      <link>https://nryotaro.dev/gallery/50_riesling_trocken/</link>
      <pubDate>Mon, 03 May 2021 15:59:35 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/50_riesling_trocken/</guid>
      <description>リースリングだけど辛すぎない。辛いのが好きな人には物足りないかも。見かけによらず炭酸はない。</description>
    </item>
    
    <item>
      <title>論文メモ Integrating the UB-Tree into a Database System Kernel</title>
      <link>https://nryotaro.dev/posts/integrating_the_ub_tree_into_a_database_system_kernel/</link>
      <pubDate>Thu, 29 Apr 2021 16:30:04 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/integrating_the_ub_tree_into_a_database_system_kernel/</guid>
      <description>&lt;p&gt;商用DBMS TransBaseのインデックスをB木から&lt;a href=&#34;https://link.springer.com/chapter/10.1007/3-540-63343-X_48&#34;&gt;UB木&lt;/a&gt;に変え、 多次元アクセス（複数の列の範囲を指定するクエリ）を高速化した。
一見、商用DBMSのインデックスの拡張は複雑かつ高コストのように思える。
UB木は、B木をベースにしたインデックスで、B木のキーの生成とページ分割方法を細工し、範囲クエリを高速化できる。
範囲クエリに向きB木に似たUB木を使うことで、既存のDBMSの範囲クエリを人々の想定よりも簡単に高速化できることを例示した。
また、既存のインデックスの拡張用に提供されたインターフェースを使わず、インデックスを置き換えカーネルにUB木を密結合することで、クエリのオプティマイザを継続して利用できた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Designing Access Methods: The RUM Conjecture</title>
      <link>https://nryotaro.dev/posts/designing_access_methods/</link>
      <pubDate>Mon, 26 Apr 2021 10:29:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/designing_access_methods/</guid>
      <description>&lt;p&gt;データ構造は読み込み(Read, R), 更新(Update, U), 所要メモリ容量(Memory, M)にトリレンマを抱え、いかなるデータ構造でも、2つを最適化すると残る1つのオーバヘッドが悪化すると予想した。
Read, Update, Memoryの頭文字から、これをRUM Conjectureと名付けた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ドメーヌ・ダンデゾン　コート・デュ・ローヌ・ルージュ　ヴィエイユ・ヴィーニュ　2018</title>
      <link>https://nryotaro.dev/gallery/cotes_du_rhone_rouge/</link>
      <pubDate>Mon, 19 Apr 2021 15:04:04 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/cotes_du_rhone_rouge/</guid>
      <description>コルクが割れたけど、割れた位置が浅かったから深く刺しなおして、まっすぐ上にひっぱったらきれいに抜けた。 渋みも酸味もなく、果実の味がそのままする。</description>
    </item>
    
    <item>
      <title>論文メモ A comparison of Fractal Trees to Log-Structured Merge (LSM) Trees</title>
      <link>https://nryotaro.dev/posts/a_comparision_of_fractal_trees_to_lsm_trees/</link>
      <pubDate>Mon, 19 Apr 2021 14:59:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_comparision_of_fractal_trees_to_lsm_trees/</guid>
      <description>&lt;p&gt;Fractal Treeは、B+木のルートと節にバッファをもたせるデータ構造にあたる。
そのFractal TreeのamplificationをB+木やLSM Treeのそれと比較した。
議論になるamplificationは、write, read, spaceの3つで、write amplificationはアプリケーションが書き込むデータ量に対して実際にストレージに書き込まれたデータ量を表す。
read amplificationはクエリの実行に必要なI/Oの回数、space amplificationは仕組み上避けられない断片化や一時的なデータのコピーに該当する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Fast Intersection Algorithms for Sorted Sequences</title>
      <link>https://nryotaro.dev/posts/fast_intersection_algorithms_for_sorted_sequences/</link>
      <pubDate>Mon, 12 Apr 2021 13:27:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/fast_intersection_algorithms_for_sorted_sequences/</guid>
      <description>&lt;p&gt;ソートされたシーケンスの直積を高速に求めるアルゴリズム Double Binary Searchを示した。
2つのシーケンス\(D\), \(Q\)があり、\(\mid D\mid=n\), \(\mid Q\mid=m\), \(n &amp;gt;= m\)であれば、平均と最悪時間計算量が、それぞれ、\(\mathcal{O}(m\log(n/m))\), \(m\)になる。
本アルゴリズムは、Web検索エンジンで大きなシーケンスの直積を高速に求めるために開発された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ドメーヌ・ポール・マス・シェ・マス・赤[2019]</title>
      <link>https://nryotaro.dev/gallery/domaine_paul_mas_chai_mas_rouge2019/</link>
      <pubDate>Sat, 10 Apr 2021 16:41:50 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/domaine_paul_mas_chai_mas_rouge2019/</guid>
      <description>派手なラベルを裏切るような感じ。最近飲んだものの中で一番酸味と渋みがバランスがとれてピーキーな感じがしなかった。</description>
    </item>
    
    <item>
      <title>La Vie Pinot Noir Domeniile Sahateni</title>
      <link>https://nryotaro.dev/gallery/lavie20210403/</link>
      <pubDate>Sat, 03 Apr 2021 23:12:57 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/lavie20210403/</guid>
      <description>4回目。でもいつも買っているリアルワインガイドの通販で売り切れていたからしばらく飲めない。あと1本だけ家にある。</description>
    </item>
    
    <item>
      <title>論文メモ The Log-Structured Merge-Tree (LSM-Tree)</title>
      <link>https://nryotaro.dev/posts/lsmtree/</link>
      <pubDate>Sat, 03 Apr 2021 22:26:27 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/lsmtree/</guid>
      <description>&lt;p&gt;LSM-Treeは、検索より挿入や削除が多い用途に向いたインデックス構造であり、例えば履歴テーブルやログの保存につかえる。
メモリにある1つ木とディスク上の1つ以上の木からなり、直近の挿入や削除をメモリの木で管理する。
メモリの木の大きさがしきい値を超えたとき、メモリの木の葉をディスクの木に移す。
移動時は、ディスク上の木の葉とメモリの葉をマージソートの要領でソートし、ソートした葉をディスクの新しい連続領域に書き込む。
連続領域に書き込み、アームの移動やディスクの回転を減らすことで、高速に挿入や削除ができる。
一方、検索速度は、複数の木を探索しなければならないために、1つの木でインデックスを構成するB木に劣る。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ The Design and Implementation of a Log-Structured File System</title>
      <link>https://nryotaro.dev/posts/the_design_and_implementation_of_a_log_structured_file_system/</link>
      <pubDate>Mon, 29 Mar 2021 16:18:21 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_design_and_implementation_of_a_log_structured_file_system/</guid>
      <description>&lt;p&gt;Log-structured file system(LFS)は、91年に提唱されたHDD向けのファイルシステムであり、バッファリングした変更をディスクの連続領域に一度に書き込むことで、小さなファイルを大量に高速で書き込める。
また、クラッシュからのリカバリも、ディスク全体ではなくチェックポイント以降に追記された箇所だけを検査すればよいので、高速になる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>シャトー・プティ・フレロン・キュヴェ・サラ[2016]</title>
      <link>https://nryotaro.dev/gallery/chateau_petit_freylon/</link>
      <pubDate>Sun, 28 Mar 2021 21:48:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/chateau_petit_freylon/</guid>
      <description>ラベルの高級感のとおり、ちょっと渋い。また飲んでもいい。</description>
    </item>
    
    <item>
      <title>ピノ・グリ（白） [&#39;20] ボートシェッド・ベイ</title>
      <link>https://nryotaro.dev/gallery/2020_boatshed_bay_marlborugh_pinot_gris/</link>
      <pubDate>Sun, 28 Mar 2021 21:43:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/2020_boatshed_bay_marlborugh_pinot_gris/</guid>
      <description>炭酸入り。味をあまり覚えていない。嫌いじゃないけどまた飲みたいという感じじゃない。 多分、炭酸そんなに好きじゃないのかも。</description>
    </item>
    
    <item>
      <title>論文メモ ARIES/IM: An Efficient and High Concurrency Index Management Method Using Write-Ahead Logging</title>
      <link>https://nryotaro.dev/posts/ariesim/</link>
      <pubDate>Sun, 21 Mar 2021 12:08:11 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/ariesim/</guid>
      <description>&lt;p&gt;ARIES/IMは、B+木への直列化可能性のある並行処理とログ先行書き込み(Write-Ahead Logging, WAL)による復元を実現する。
ARIES/IMのベースには、先行研究の&lt;a href=&#34;https://web.stanford.edu/class/cs345d-01/rl/aries.pdf&#34;&gt;ARIES&lt;/a&gt;がある。
復元手順はARIESとほとんど変わらない。
キーの参照先にあるデータのレコードとキーを同じロックで保護したり、ロックの代わりにラッチを使ったりすることで、ロックの頻度を下げ、B+木の高速化を実現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ベルフォンテーヌ Bellefontaine Pays d&#39;Oc Rouge</title>
      <link>https://nryotaro.dev/gallery/bellefontaine_rouge/</link>
      <pubDate>Fri, 19 Mar 2021 19:22:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/bellefontaine_rouge/</guid>
      <description>かなり好き。果実味が強く、渋みのない味でLa Vieと似た感じ。La Vieが1300円くらいで、こっちは800円くらい。すごい。また飲みたい。</description>
    </item>
    
    <item>
      <title>論文メモ The Ubiquitous B-Tree</title>
      <link>https://nryotaro.dev/posts/the_ubiquitous_b_tree/</link>
      <pubDate>Fri, 19 Mar 2021 19:17:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_ubiquitous_b_tree/</guid>
      <description>&lt;p&gt;B木とその派生データ構造のサーベイ論文で、とくにB+木に重点がおかれている。
B+木は、全てのキーを葉におき、葉を隣接リストでつなぐことで、B木が不得手なシーケンシャルなアクセスを改善する。
これにより、定数オーダーの時間と空間計算量で逐次的にキーにアクセスにできる。
ランダムな検索、挿入、削除にかかる時間、空間計算量はB木と変わらない。
以降はB木のデータ構造を前提としてB+木の概要を説明する。B木について知りたい場合は、&lt;a href=&#34;https://nryotaro.dev/posts/organization_and_maintenance_of_large_orderred_indexes/&#34;&gt;B木のオリジナル論文の解説記事&lt;/a&gt;を見てほしい。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>エリソン マラン 2019</title>
      <link>https://nryotaro.dev/gallery/herisson_malin/</link>
      <pubDate>Sat, 13 Mar 2021 02:40:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/herisson_malin/</guid>
      <description>シャルドネの辛口。樽香で変な香りをつけておらず、少し炭酸があって、辛口。のみやすくて好き。</description>
    </item>
    
    <item>
      <title>論文メモ Robust Random Cut Forest Based Anomaly Detection On Streams</title>
      <link>https://nryotaro.dev/posts/robust_random_cut_forest_based_anomaly_detection_on_streams/</link>
      <pubDate>Fri, 12 Mar 2021 20:30:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/robust_random_cut_forest_based_anomaly_detection_on_streams/</guid>
      <description>&lt;p&gt;Robust Random Cut Forest(RRCT)はストリームデータ向きの異常検知の手法で、&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162/&#34;&gt;Amazon SageMaker&lt;/a&gt;から提供されている。
バッチデータと違い、ストリームデータは新たなデータが随時追加、修正される。
RRCTは、特徴の値でデータを2分するノードからなる木の集合であり、データを追加したときに木の集合であるモデルを大きく複雑するものを異常と判定する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Coteaux du Pont du Gard Cuvee des Galets</title>
      <link>https://nryotaro.dev/gallery/coteaux_du_pont_du_gard_cuvee_des_galets/</link>
      <pubDate>Sun, 07 Mar 2021 13:04:28 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/coteaux_du_pont_du_gard_cuvee_des_galets/</guid>
      <description>ラベルがかわいい。味はLa Vieに似てた。好き。</description>
    </item>
    
    <item>
      <title>La Vie その3</title>
      <link>https://nryotaro.dev/gallery/lavie3/</link>
      <pubDate>Sun, 07 Mar 2021 13:03:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/lavie3/</guid>
      <description>おいしかったので、3回目。</description>
    </item>
    
    <item>
      <title>Feudo Arancio Inzolia</title>
      <link>https://nryotaro.dev/gallery/feudo_arancio_inzolia/</link>
      <pubDate>Sun, 28 Feb 2021 12:16:50 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/feudo_arancio_inzolia/</guid>
      <description>辛口で変な香りのない素直な感じ。ラベルがいいよね。好き。</description>
    </item>
    
    <item>
      <title>論文メモ Organization and Maintenance of Large Ordered indexes</title>
      <link>https://nryotaro.dev/posts/organization_and_maintenance_of_large_orderred_indexes/</link>
      <pubDate>Sat, 27 Feb 2021 19:54:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/organization_and_maintenance_of_large_orderred_indexes/</guid>
      <description>&lt;p&gt;1972年に発表されたB木のオリジナルの論文。
\(I\)をインデックスの大きさ、\(k\)をハードウェア依存の値とすると、検索、挿入、削除の時間計算量は\(\log_kI\)になる。
ここでのインデックスは、固定長の\((x, \alpha)\)を要素とする連想配列で、最大\(2k\)個のキーを格納できる連続したページ上にある。
\(\alpha\)には、データを保存した1つ以上のレコードへのポインタが格納される。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Space/Time Trade-offs in Hash Coding with Allowable Errors</title>
      <link>https://nryotaro.dev/posts/space_time_trade-offs_in_hash_coding_with_allowable_errors/</link>
      <pubDate>Sat, 20 Feb 2021 16:46:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/space_time_trade-offs_in_hash_coding_with_allowable_errors/</guid>
      <description>&lt;p&gt;要素がハッシュ空間にあるかを高速に調べる手法で、ブルームフィルタの名で知られる。
偽陽性を許容し、ハッシュ値の保持に必要な空間を小さすることで、管理できるデータ件数を増やす。
例えば、&lt;a href=&#34;https://www.oreilly.com/library/view/designing-data-intensive-applications/9781491903063/&#34;&gt;データベースのストレージで使われており&lt;/a&gt;、検索するキーがデータベースに存在するか事前に確かめ、存在しないキーのための不要なディスクの読み取りを省いている。
偽陰性の誤りはない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>La Vie その2</title>
      <link>https://nryotaro.dev/gallery/la_vie2/</link>
      <pubDate>Sat, 20 Feb 2021 13:33:48 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/la_vie2/</guid>
      <description>おいしかったので、2回目。</description>
    </item>
    
    <item>
      <title>ヴィニウス・ヴィンヤーズ IGP ペイ・ドック・シャルドネ（白） [&#39;19] ジャン・クロード・マス　エステーツ＆ブランズ</title>
      <link>https://nryotaro.dev/gallery/vinus/</link>
      <pubDate>Sat, 20 Feb 2021 13:33:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/vinus/</guid>
      <description>香りがついた感じ。たぶん香りのつけられたシャルドネあまりすきじゃない。</description>
    </item>
    
    <item>
      <title>論文メモ Tree Indexing on Solid State Drives</title>
      <link>https://nryotaro.dev/posts/tree_index_on_solid_state_drives/</link>
      <pubDate>Mon, 15 Feb 2021 15:53:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/tree_index_on_solid_state_drives/</guid>
      <description>&lt;p&gt;SSDのランダムな書き込みを高速化するために、インデックスのためのデータ構造FD-treeを提案した。
FD-treeのエントリ数が\(n\), ページサイズが\(B\)であれば、ランダムな読み込みと書き込みの計算量はともに\(\mathcal{O}(\log_B(n))\)になる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>IGP ドック・dA・メルロ[2017] ドメーヌ・アストラック</title>
      <link>https://nryotaro.dev/gallery/d_a_merlot/</link>
      <pubDate>Sun, 14 Feb 2021 11:31:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/d_a_merlot/</guid>
      <description>前回飲んだものの赤の方。 最後に飲んだ赤がLa Vieの薄めの飲みやすいものだったけど、こっちは別に薄くない。 おいしい。</description>
    </item>
    
    <item>
      <title>論文メモ Isolation Forest</title>
      <link>https://nryotaro.dev/posts/isolation_forest/</link>
      <pubDate>Sat, 13 Feb 2021 19:52:34 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/isolation_forest/</guid>
      <description>&lt;p&gt;Isolation Forestは、完全二分木による異常検知の手法で、iForestともよばれる。時間計算量が線形で、ハイパーパラメタがわずか2つで、メモリ効率がよい。
時間、空間計算量が少なく高次元のデータに向く。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>IGP ドック・dA・シャルドネ（白）[2018] </title>
      <link>https://nryotaro.dev/gallery/d_a_chardonnay/</link>
      <pubDate>Sun, 07 Feb 2021 13:33:13 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/d_a_chardonnay/</guid>
      <description>IGP ドック・dA・シャルドネ（白）[2018] ドメーヌ・アストラック。 前回飲んだ白のDARK HORSEがわざとらしく香りをつけていたのに対して、妙な自己主張のない自然な辛口の白。 こっちのほうが断然おいしい。自分は変に樽香をつけたシャルドネが苦手かもしれない。 これはまた買うつもり。</description>
    </item>
    
    <item>
      <title>論文メモ TAO: Facebook&#39;s Distributed Data Store for the Social Graph</title>
      <link>https://nryotaro.dev/posts/tao_facebooks_distributed_data_store_for_social_graph/</link>
      <pubDate>Thu, 04 Feb 2021 18:47:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/tao_facebooks_distributed_data_store_for_social_graph/</guid>
      <description>&lt;p&gt;TAOは、Facebookで開発されたソーシャルグラフのためのマルチリージョンの分散システムで、秒間10億件の読み込みと数百万件の書き込みの性能を発揮する。
Facebookは、もともとソーシャルグラフを、MySQLに保存し、memcacheでキャッシュし、PHPで問いあわせるシステムで構成していた。
TAOは、そのシステムの現状を引きつぎ、MySQLをストレージに採用している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>La Vie PINOT NOIR 2018</title>
      <link>https://nryotaro.dev/gallery/la_vie/</link>
      <pubDate>Sun, 31 Jan 2021 00:58:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/la_vie/</guid>
      <description>某所でおすすめされたワイン。香りがよく、飲みやすい。 1300円とは信じられないくらいおいしい。 明日3本くらい追加で買うつもり。</description>
    </item>
    
    <item>
      <title>論文メモ The Daily Life of Software Engineers during the COVID-19 Pandemic</title>
      <link>https://nryotaro.dev/posts/the_daily_life_of_software_engineers_during_the_covid_19_pandemic/</link>
      <pubDate>Sat, 30 Jan 2021 13:19:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_daily_life_of_software_engineers_during_the_covid_19_pandemic/</guid>
      <description>&lt;p&gt;COVID19でソフトウェア開発者が在宅稼動(WFH)をはじめたことによる稼動時間の使い方、良好性(Well-being), 生産性の変化を調査した。
ロックダウンを実施した国々のエンジニア500名の中から、2020年4月20日から26日の一波について192名、2020年5月4日から10日の二波について184名を選び、サンプルを集めた。
結果、会社での勤務とWFHの間で、稼動時間の使い方はほぼ変わっていないかった。
また、一波において休憩と生産性の間に負の相関がみられたが、それ以外では良好性、生産性、社会性、心理の4つと特定の業務内容の間に相関関係はみられなかった。
結果、組織やエンジニアにとってWFHそれ自体が課題になるわけではないと結論づけている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DARK HORSE CHARDONNAY 2018</title>
      <link>https://nryotaro.dev/gallery/darkhorse/</link>
      <pubDate>Tue, 26 Jan 2021 01:04:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/darkhorse/</guid>
      <description>アメリカのシャネルドネ。1本自宅近くのスーパーで買ったあとに、飲んでもないのに、Amazonでもう一本買った。 飲んだ瞬間、シャルドネらしからぬ強い香りがした。商品説明には濃いとあったが、ここまで強いと思っておらず、正直きついと感じた。たぶん二度と買わない。</description>
    </item>
    
    <item>
      <title>論文メモ Dapper, a Large-Scale Distributed Systems Tracing Infrastructure</title>
      <link>https://nryotaro.dev/posts/dapper/</link>
      <pubDate>Sat, 23 Jan 2021 14:50:16 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dapper/</guid>
      <description>&lt;p&gt;分散トレーシングシステムDapperをGoogle社内で開発、デプロイ、運用した知見がまとめられている。
運用期間は2年にわたる。
Dapperをもとに、TwitterはZipkinを、UberはJaegerを&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873119038/&#34;&gt;開発した&lt;/a&gt;。
Dapper以前に開発された&lt;a href=&#34;https://www.usenix.org/legacy/publications/library/proceedings/hotos03/tech/full_papers/barham/barham_html/paper.html&#34;&gt;Magpie&lt;/a&gt;や&lt;a href=&#34;https://www.usenix.org/conference/nsdi-07/x-trace-pervasive-network-tracing-framework&#34;&gt;X-Trace&lt;/a&gt;との違いは、サンプリングされたリクエストのみをトレースし負荷を下げるられたり、少数の共通ライブラリだけを測定対象したりする点にある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Convolutional 2D Knowledge Graph Embeddings</title>
      <link>https://nryotaro.dev/posts/convolutional_2d_knowledge_graph_embeddings/</link>
      <pubDate>Mon, 11 Jan 2021 17:24:16 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/convolutional_2d_knowledge_graph_embeddings/</guid>
      <description>&lt;p&gt;ナレッジグラフの未知のリンクを予測するモデルは、一般に大きなグラフをあつかえるようにネットワークを浅くし、処理性能の高速化をはかる。一方、代償として層の深いモデルと比べて表現力を欠く。
提唱されるネットワークConvEは、畳み込み層をつかった深めのネットワークで予測性能の向上をはかる。
層が深くなると計算コストの増加や過学習が課題になるが、先行研究の&lt;a href=&#34;https://arxiv.org/abs/1412.6575&#34;&gt;DistMult&lt;/a&gt;や&lt;a href=&#34;https://arxiv.org/abs/1703.06103&#34;&gt;R-GCN&lt;/a&gt;と比べたConvEのパラメタ数は1/8や1/17であり、パラメタ効率がよい。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Multiversion Concurrency Control - Theory and Algorithms</title>
      <link>https://nryotaro.dev/posts/mvcc/</link>
      <pubDate>Wed, 06 Jan 2021 16:02:37 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/mvcc/</guid>
      <description>&lt;p&gt;データベースのトランザクション制御Multiversion Concurrency Control(MVCC, 多版型同時実行制御) 下のトランザクションが逐次実行と等価な結果になる条件を定義した。
また、その定義を既存のMVCCのアルゴリズム3つにあてはめ、アルゴリズムの正しさを確かめた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Paxos Made Simple</title>
      <link>https://nryotaro.dev/posts/paxos_made_simple/</link>
      <pubDate>Thu, 31 Dec 2020 19:17:13 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/paxos_made_simple/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf&#34;&gt;The Part-Time Parliament&lt;/a&gt;で提唱された分散含意アルゴリズムPaxosをLamport自身が平易に解説した。
エージェントの処理速度やメッセージが配信されるまでの長さに仮定はない。
メッセージは複製、喪失してもよい。
他方で、ビザンチン将軍問題は扱わず、メッセージが壊れることは考えない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Impossibility of Distributed Consensus with One Faulty Process</title>
      <link>https://nryotaro.dev/posts/impossibility_of_distributed_consensus_with_one_faulty_process/</link>
      <pubDate>Fri, 18 Dec 2020 22:18:59 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/impossibility_of_distributed_consensus_with_one_faulty_process/</guid>
      <description>&lt;p&gt;プロセスが1つでもクラッシュしうる場合には常に含意を保証できる完全な非同期アルゴリズムは存在しないことを示した。
この定理はFLP帰結とよばれる。
FLPは、著者Fischer, Lynch, Patersonの頭文字に由来する。
ここでの完全は、プロセスの処理速度やメッセージの配信遅延に仮定をおかず、同期クロックがないためにタイムアウトを使えず、ほかのプロセスが別のプロセスの障害を検知できないことを意味する。
いいかえると、含意アルゴリズムを実装するには上のいずれかを仮定しなければないことを示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Availability in Globally Distributed Storage Systems</title>
      <link>https://nryotaro.dev/posts/availability_in_globally_distributed_storage_systems/</link>
      <pubDate>Sat, 12 Dec 2020 20:53:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/availability_in_globally_distributed_storage_systems/</guid>
      <description>&lt;p&gt;Googleの分散ストレージで生じた障害の統計をとり、ストレージの可用性の予測モデルを提唱した。
ディスク、ノード、ラックなどハードウェアの粒度を変えて、粒度ごとの平均故障間隔を計測し、故障原因を分類した。
2分のウィンドウで生じた障害をグループにまとめると、ほとんどの障害が同時多発的な障害の一部であった。
20以上のノードを巻き込む大きな障害では、別々のラックにあるノードに障害が起きるよりも、特定のラックのノードに障害が起きることが多かった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ What You Always Wanted to Know About Datalog</title>
      <link>https://nryotaro.dev/posts/what_you_always_wanted_to_know_about_datalog/</link>
      <pubDate>Sat, 12 Dec 2020 18:02:01 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/what_you_always_wanted_to_know_about_datalog/</guid>
      <description>&lt;p&gt;論理型のデータベースのクエリ言語Datalogの構文、意味論、最適化が解説されている。
最適化の節はサーベイ論文の形式で、最適化を分類し、各種類の先行研究に案内がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Translating Embeddings for Modeling Multi-relational Data</title>
      <link>https://nryotaro.dev/posts/translating_embeddings_for_modeling_multi_relational_data/</link>
      <pubDate>Sat, 05 Dec 2020 20:21:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/translating_embeddings_for_modeling_multi_relational_data/</guid>
      <description>&lt;p&gt;ナレッジグラフを低次元のベクトル空間に埋め込むアルゴリズムTransEを提案した。
エンティティは複数種類のラベルをもってよく、埋め込まれたエンティティやラベルの距離を計算することで、入力されたグラフに欠けているリンクを推定できる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ The Declarative Imperative</title>
      <link>https://nryotaro.dev/posts/the_declarative_imperative/</link>
      <pubDate>Sat, 05 Dec 2020 16:19:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_declarative_imperative/</guid>
      <description>&lt;p&gt;宣言型言語Datalogを拡張した言語でネットワークプロトコルと分散システムを開発した7年間の経験から、次世代の並列分散プログラミング言語の基礎になる理論上の予想を4つ提唱した。
Datalogは、論理プログラミング言語Prologのサブセットの構文をもった言語である。
予想の説明に使われるDatalogの拡張言語&lt;a href=&#34;https://www2.eecs.berkeley.edu/Pubs/TechRpts/2009/EECS-2009-173.pdf&#34;&gt;Dedalus&lt;/a&gt;は、分散システムのノードが互いの時刻を直接的に推論できない性質を、送受信するデータから離れたノードの時刻を推論する問題に帰着する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Bigtable: A Distributed Storage System for Structured Data</title>
      <link>https://nryotaro.dev/posts/bigtable/</link>
      <pubDate>Mon, 30 Nov 2020 20:18:18 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bigtable/</guid>
      <description>&lt;p&gt;Bigtableは、数千のコモディティサーバ上でペタバイト級のデータをホスティングできる分散ストレージであり、行、列、タイムスタンプをキーとして値の文字列を保存する。
論文の発表された2005年時点で、検索エンジンのインデックス, Google Earth, Google Financeなどの多様なアプリケーションの実装に使用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Aerospike: Architecture of a Real-Time Operational Database</title>
      <link>https://nryotaro.dev/posts/aerospike/</link>
      <pubDate>Sat, 28 Nov 2020 21:22:34 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/aerospike/</guid>
      <description>&lt;p&gt;Aerospikeは、高い対障害性をもった分散データベースで、正式にはCitrusleafという。
CPU, DRAM, HDDやSSDを搭載したコモディティなサーバでクラスタを組める。
ノード同士はTCP/IPで通信し、シェアードナッシングなクラスタを構成する。
処理性能の向上のために、スケールアウトだけでなく、スケールアップも重視しており、ハードウェアを意識した実装で高速化をはかっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Spanner: Google&#39;s Globally Distributed Database</title>
      <link>https://nryotaro.dev/posts/spanner/</link>
      <pubDate>Fri, 27 Nov 2020 16:56:57 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/spanner/</guid>
      <description>&lt;p&gt;Spannerは、世界中のデータセンタにデータを複製する高可用な分散データベースで、&lt;a href=&#34;http://bitsavers.trailing-edge.com/pdf/xerox/parc/techReports/CSL-81-8_Information_Storage_in_a_Decentralized_Computer_System.pdf&#34;&gt;外部整合性&lt;/a&gt;のある分散トランザクションを保証する。
ユーザからみると半リレーショナルなデータモデルのデータベースであり、各テーブルに一つ以上の順序つき主キーが必要なところがリレーショナルデータモデルと違う。
一方、内部は文字列とタイムスタンプの組をキーにしたキーバリューストアであり、Single Paxos状態機械でデータの一貫性を守りながら複数のデータセンタにデータを複製する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Relational Model of Data for Large Shared Data Banks</title>
      <link>https://nryotaro.dev/posts/a_relational_model_of_data_for_large_shared_data_banks/</link>
      <pubDate>Sat, 21 Nov 2020 13:51:57 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_relational_model_of_data_for_large_shared_data_banks/</guid>
      <description>&lt;p&gt;Coddがリレーショナルデータモデルを提唱した70年の論文。
データをリレーション(SQLでのテーブル)として束ね、リレーションを順序なしのタプル(SQLの行)で構成する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ On Designing and Deploying Internet-Scale Services</title>
      <link>https://nryotaro.dev/posts/on_designing_and_deploying_internet-scale_services/</link>
      <pubDate>Fri, 20 Nov 2020 18:55:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/on_designing_and_deploying_internet-scale_services/</guid>
      <description>&lt;p&gt;MSNとWindows Liveで培われたシステム管理者による運用負担を減らすためのベストプラクティス集。
07年に発表された。
プラクティス集は、10のグループに分かれ、それぞれ複数のアドバイスからなる。
特徴的な内容に絞って以下に要約する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Weighted Voting for Replicated Data</title>
      <link>https://nryotaro.dev/posts/weighted_voting_for_replicated_data/</link>
      <pubDate>Thu, 19 Nov 2020 21:21:33 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/weighted_voting_for_replicated_data/</guid>
      <description>&lt;p&gt;1979年に発表されたレプリケーション管理のクオーラムモデルのアルゴリズムの論文で、以前紹介したように&lt;a href=&#34;https://awsmedia.awsstatic-china.com/blog/2017/aurora-design-considerations-paper.pdf&#34;&gt;Amazon Aurora&lt;/a&gt;や&lt;a href=&#34;https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&#34;&gt;Dynamo&lt;/a&gt;で採用されている。
ファイルの読み込みや書き込みのトランザクションは、複製されたファイルのもつ票を集め、所定の数、クオーラムを越えたときのみ実行される。
これにより、読み込み、書き込みの線形の一貫性が保証され、実行中のトランザクションが高々一つであるかのように見せかけられる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</title>
      <link>https://nryotaro.dev/posts/amazon_aurora/</link>
      <pubDate>Fri, 13 Nov 2020 17:51:53 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/amazon_aurora/</guid>
      <description>&lt;p&gt;AWSで提供されるRDBM, Amazon Auroraのアーキテクチャを解説した論文。
分散システムをクラウドにおく場合、計算やIOはノードに分散され、ボトルネックではなくなる。
そして、ボトルネックは、DBインスタンスとストレージ間のネットワークになる。
この仮説もと、プライマリインスタンスが、別テナントのストレージに直接Redoログを送ることで、レプリカインスタンスとストレージ間の負荷を減らし、処理性能の向上をはかる。
また、レプリケーションのために、MySQLがRedoログだけでなくバイナリログなど複数種類のログをスレーブに送るのに対し、AuroraはRedoログだけを転送する。
これにより、リカバリや縮退、フェールオーバの性能も向上している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ &#34;One Size Fits All&#34;: An Idea Whose Time Has Come and Gone</title>
      <link>https://nryotaro.dev/posts/one_size_fit_all/</link>
      <pubDate>Fri, 13 Nov 2020 16:05:23 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/one_size_fit_all/</guid>
      <description>&lt;p&gt;2011年に発表された論文で、これまでのようにDBMSを様々なデータ中心のアプリケーションに利用することがデータベース市場で受け入れられなくなったと主張する。
データウェアハウスとストリーミング処理を例にとり、これらに特化したデータベースをDBMSで代用することの限界が説明されている。
表題の&amp;quot;One Size Fits All&amp;quot;はフリーサイズ、転じて、万能、汎用的を意味する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Dynamo: Amazon&#39;s Highly Available Key-value Store</title>
      <link>https://nryotaro.dev/posts/dynamo_amazons_highly_available_key_value_store/</link>
      <pubDate>Fri, 06 Nov 2020 17:06:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dynamo_amazons_highly_available_key_value_store/</guid>
      <description>&lt;p&gt;Amazonで社内運用されている高可用性のKVS, Dynamoのアーキテクチャを解説している。
まぎらわしいが、Dynamoは、AWSサービスのDynamo DBとは違う&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873118703/&#34;&gt;*&lt;/a&gt;。
Dynamoは、リーダーレスレプリケーションモデルで、Dynamo DBはシングルリーダレプリケーションモデルを採用している。
Dynamoは、高信頼性が必要なシステムの状態管理に使用される。
その用途から、トランザクション分離レベルのサポートは不要で、可用性を優先するために結果整合性を許容する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Zero-shot Word Sense Disambiguation using Sense Definition Embeddings</title>
      <link>https://nryotaro.dev/posts/zero_shot_word_sense_disambiguation_using_sense_definition_embeddings/</link>
      <pubDate>Fri, 30 Oct 2020 18:58:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/zero_shot_word_sense_disambiguation_using_sense_definition_embeddings/</guid>
      <description>&lt;p&gt;語義曖昧性解消のためのアーキテクチャ, Extended WSD Incorporating Sense Embeddings(EWISE)を発表した。
EWISEは単語の意味をアノテーションしあテキストと辞書を教師データにもちいる。
実験では、辞書にWordNetをつかい、概念同士の上下関係や関係を示す分散表現を獲得する。
学習であたえられていない意味を推定するために、離散値ではなく分散表現でラベルの意味を表現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Simple Testing Can Prevent Most Critical Failures</title>
      <link>https://nryotaro.dev/posts/simple_testing_can_prevent_most_critical_failures/</link>
      <pubDate>Thu, 29 Oct 2020 20:53:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/simple_testing_can_prevent_most_critical_failures/</guid>
      <description>&lt;p&gt;5つの分散システムのバグのうち198件を無作為に抽出、調査したところ、エラーハンドリングに対する単純なテストが有効であることが分かった。
198件のうちの48件は、論文でcatastrophic failuresと形容された、多くのユーザに影響を与える障害が占めた。
調査対象は、Cassandra, HBase, HDFS, Hadoop MapReduce, Redisの5つである。
catastrophic failuresの35%の原因は、エラーハンドラがログの出力だけしかしていない、過剰に上位の例外クラスが宣言されたcatch構文で例外を処理していること、例外に&lt;code&gt;FIXME&lt;/code&gt;, &lt;code&gt;TODO&lt;/code&gt;コメントがある、の3パターンに分類された。
Javaのバイトコードから以上の3パターンを検出するツールを実装し、9種類の分散システムに適用したことで、121件の未知のバグを特定することができた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ From Diversity by Numbers to Diversity as Process</title>
      <link>https://nryotaro.dev/posts/from_diversity_by_numbers_to_diversity_as_process/</link>
      <pubDate>Fri, 16 Oct 2020 23:58:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/from_diversity_by_numbers_to_diversity_as_process/</guid>
      <description>開発におけるブレーンストーミングが、マイノリティに属する開発者の満足度の向上に貢献することを実験的に示した。 ここでの開発は、ハッカソンのような短時間かつ集中が求められるものが想定されている。 満足度は、開発プロセスと成果物に対するもので分けて扱われ、どちらの観点でもブレーンストーミングは満足度に対してよい効果をもたらした。
  論文をこちらからダウンロードできます。  </description>
    </item>
    
    <item>
      <title>論文メモ End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</title>
      <link>https://nryotaro.dev/posts/end_to_end_sequence_labeling_via_bi_directional_lstm_cnns_crf/</link>
      <pubDate>Fri, 16 Oct 2020 22:17:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_sequence_labeling_via_bi_directional_lstm_cnns_crf/</guid>
      <description>&lt;p&gt;タスク固有の特徴を使わないEnd to Endの系列ラベリングのためのネットワークアーキテクチャを発表した。
実験では、Penn Treebank WSJの品詞タグ付けで97.55%のaccuracy, CoNLL 2003の固有表現抽出で91.21%のF1値を発揮し、発表当時の先行研究を上まわる性能を示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Becoming Agile: A Grounded Theory of Agile Transitions in Practice</title>
      <link>https://nryotaro.dev/posts/becoming_agile/</link>
      <pubDate>Fri, 16 Oct 2020 17:34:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/becoming_agile/</guid>
      <description>&lt;p&gt;アジャイル開発に熟練する過程でチームに生じる変化をグラウンデッドセオリーで調査した。
調査のために、ニュージーランド、オーストラリア、アメリカ、インド、ポルトガルの5カ国から18のチームを選び、その中の31名に半構造化された約1時間の面接を実施した。
面接では、職歴、自己組織化の実践、仕事のわりあて方の3つを話してもらった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Software Development Waste</title>
      <link>https://nryotaro.dev/posts/software_development_waste/</link>
      <pubDate>Sun, 11 Oct 2020 15:02:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/software_development_waste/</guid>
      <description>&lt;p&gt;Pivotal Labs(Pivoital社の一部門、PivotalはSpring Frameworkを開発している会社。昨年VM Wareに買収された？)における8プロジェクトを、グラウンデットセオリーにしたがって参与観察し、ソフトウェア開発においる無駄を特定し、無駄を9つの区分に分類した。
論文では、無駄は「リソースを使っのに顧客にとっての価値を生みださなかった活動」と定義されている。
調査期間は2年5ヶ月で、調査結果は、ソフトウェア開発者、インタラクションデザイナ、プロダクトマネジャーからなる33名のステークホルダに面接した結果もふまえてある。
分類のほかに、無駄を生みだす二項対立や原因にも言及されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ End-to-end Neural Coreference Resolution</title>
      <link>https://nryotaro.dev/posts/end_to_end_neural_coreference_resolution/</link>
      <pubDate>Sat, 10 Oct 2020 00:12:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_neural_coreference_resolution/</guid>
      <description>&lt;p&gt;ニューラルネットワークによる共参照解析の手法で、End-to-Endとあるように、構文解析やルールベースの参照表現に頼らず、先行研究を上回る性能を発揮した。
文書中の全ての単語系列を参照表現の候補とみなし、ある単語系列の組が照応関係にある確率の分布を学習する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Build it yourself! Homegrown Tools in a Large Software Company</title>
      <link>https://nryotaro.dev/posts/build_it_yourself/</link>
      <pubDate>Fri, 02 Oct 2020 20:22:20 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/build_it_yourself/</guid>
      <description>&lt;p&gt;マイクロソフトにおいて、誰が(RQ1)、どんな(RQ2)自作ツールを、どのような動機(RQ3)で、いつ(RQ3)開発し、どのように普及するのか(RQ4)を調査した。
調査結果では、大多数の開発者はツールを自作し、そのほとんどは所属するチームの外までは普及せす、ツールの使用者と共同開発者は一人以上いることが多かった。
受容的な組織文化はツールの自作を促進し、また、自作ツールは組織に大きな影響をあたえる可能性があることを示唆している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Universal Sentence Encoder</title>
      <link>https://nryotaro.dev/posts/universal_sentence_encoder/</link>
      <pubDate>Fri, 02 Oct 2020 18:20:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/universal_sentence_encoder/</guid>
      <description>&lt;p&gt;転移学習のための文の分散表現を獲得するモデルを提案した。
提案されたモデルは2つで、両者には精度と計算量の間にトレードオフがある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ How much Up-Front? A Grounded Theory of Agile Architecture</title>
      <link>https://nryotaro.dev/posts/how_much_up-front/</link>
      <pubDate>Fri, 25 Sep 2020 20:40:50 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/how_much_up-front/</guid>
      <description>&lt;p&gt;「アジャイル開発において、実装前のアーキテクチャ設計にどれだけ工数を割くべきか？」という問いの回答指針を、44名のソフトウェア開発者に面接し、その結果からグラウンデッド・セオリーで提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Character-level Convolutional Networks for Text Classification</title>
      <link>https://nryotaro.dev/posts/character_level_convolutional_networks_for_text_classification/</link>
      <pubDate>Fri, 25 Sep 2020 18:10:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/character_level_convolutional_networks_for_text_classification/</guid>
      <description>&lt;p&gt;文字単位のCNNによる文書の分類を、ほかのモデルと比較して評価した。
先行研究より、CNNを訓練するときは大量の教師データが必要になると分かっている。
のため、比較のためのデータセットは大きく、訓練データの事例数は最低でも12万件におよぶ。
文字単位のCNNに大量の訓練データをあたえれば、別途単語の意味をモデルにあたえずとも性能を発揮することを示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ What Makes A Great Software Engineer?</title>
      <link>https://nryotaro.dev/posts/what_makes_a_great_software_engineer/</link>
      <pubDate>Fri, 18 Sep 2020 20:19:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/what_makes_a_great_software_engineer/</guid>
      <description>&lt;p&gt;優れたエンジニアの特徴を知るために、マイクロソフト社のアーキテクト59名と半構造化された面接をし、グラウンデッドセオリーで内容から特徴を抽出した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title>
      <link>https://nryotaro.dev/posts/maml/</link>
      <pubDate>Fri, 18 Sep 2020 17:54:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/maml/</guid>
      <description>&lt;p&gt;表題の略称MAMLで知られるメタ学習であり、少ない教師データで新しいタスクに対応することを目的としている。
Model-Agnosticとあるように、MAMLの汎用性は高く、勾配法をもちいるモデルであえば適用可能である。
論文には、教師あり学習だけでなく強化学習の事例もある。
さまざまなタスクに適した初期パラメタを見つけ、データ件数の削減をねらう。
目的のパラメタを求めるためには、複数のタスクを用意し、これらの損失関数の合計値を最小にするように勾配法でパラメタの更新を繰り返す。
最後に更新されたパラメタをモデルの初期値に設定する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Truth in Advertising: The Hidden Cost of Mobile Ads for Software Developers</title>
      <link>https://nryotaro.dev/posts/truth_in_advertising/</link>
      <pubDate>Fri, 11 Sep 2020 20:01:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/truth_in_advertising/</guid>
      <description>&lt;p&gt;モバイルアプリを無料で提供し、アプリ内の広告で収益をえるビジネスが普及している。
このビジネスモデルでは、一見、ユーザには、画面に広告を表示されること以外のコストがないように思える。
表題の論文は、それ以外のコストを確かめるために、CPU, 電力, ネットワーク, 広告関連のためのリリース, アプリケーションへのユーザからの評価へ広告が及ぼす影響を調査した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Skip-Thought Vectors</title>
      <link>https://nryotaro.dev/posts/skip_thought_vectors/</link>
      <pubDate>Fri, 11 Sep 2020 16:09:15 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/skip_thought_vectors/</guid>
      <description>&lt;p&gt;様々なタスクで性能を発揮できる文の分散表現を生成するモデルSkip-Thougtを提案した。
表題のSkip-Tought Vectorsは、Skip-Toughtで生成されるベクトルである。
Skip-Thoughtは、文書を入力とする教師なし学習であり、与えられた文から隣接する左右の文を推定できるようにパラメタを学習する。
学習後は、語彙を増やすために、Word2Vecの単語のベクトルからSkip-Toughtのベクトルを推定するための正則化なしの回帰モデルを学習させる。
学習データにない単語のベクトルを回帰モデルの推定結果で代用し、未知の単語を含む文の分散表現もつくれるようにする。
Skip-Toughtを8タスクに適用し、汎用性を確かめた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Beyond Accuracy: Behavioral Testing of NLP Models with CHECKLIST</title>
      <link>https://nryotaro.dev/posts/beyond_accuracy/</link>
      <pubDate>Fri, 04 Sep 2020 21:54:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/beyond_accuracy/</guid>
      <description>&lt;p&gt;ホールドアウト法にかわる自然言語処理モデルの汎化性能を評価するための手法CHECKLISTを提案した。
テストデータと訓練データが同じ方法で集められたときなど、ホールドアウト法はモデルを過大評価することがある。
CHECKLISTは、ソフトウェア開発のブラックボックステストにならい、半自動生成したテストデータで汎化性能を評価する。
CHECKLISTの汎用性と性能を評価するために、感情分析、Quoraの重複質問検出、読解の3タスクについて、商用やSoTAに近いモデルを学習させ、CHECKLISTでモデルがあつかえない入力パターンをどれだけ生成できるか実験した。
感情分析の評価には、Microsoft, Google, AmazonのAPIとBERT, RoBERTaを使い、重複検出にはBERTとRoBERTa, 読解にはBERTを使用した。
CHECKLISTはOSSとして&lt;a href=&#34;https://github.com/marcotcr/checklist&#34;&gt;公開&lt;/a&gt;されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Why Good Developers Write Bad Code: An Observational Case Study of the Impacts of Organizational Factors on Software Quality</title>
      <link>https://nryotaro.dev/posts/why_good_developers_write_bad_code/</link>
      <pubDate>Fri, 04 Sep 2020 20:54:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/why_good_developers_write_bad_code/</guid>
      <description>&lt;p&gt;創立40年以上の電気通信系企業における内製システムのリプレースプロジェクトを観察し、コードに悪影響をおよぼす10の組織的な要因をまとめた。
表題には、&amp;ldquo;Good Developers&amp;quot;とあるが、開発者のスキルの高さは議論されていない。
列挙された要因は、包括的ではなく、また、あくまでコードの品質を悪化させるものであり、プロジェクトの失敗に直結するわけではない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Comparative Study of Programming Lanugages in Rosetta Code</title>
      <link>https://nryotaro.dev/posts/a_comparative_study_of_programming_languages_in_rosetta_code/</link>
      <pubDate>Fri, 28 Aug 2020 20:19:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_comparative_study_of_programming_languages_in_rosetta_code/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://rosettacode.org/wiki/Rosetta_Code&#34;&gt;Rosetta Code&lt;/a&gt;に投稿された実装で言語の性能を比較した。
比較した言語は、Ruby, F#, Java, C#, Go, C, Python, Haskellの8つである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ SQuAD: 100,000&#43; Questions for Machine Comprehension of Text</title>
      <link>https://nryotaro.dev/posts/squad/</link>
      <pubDate>Fri, 28 Aug 2020 19:36:42 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/squad/</guid>
      <description>&lt;p&gt;読解タスクのテストデータセットSQuADをつくり、ロジスティック回帰で難易度を評価した。
難易度は、ベースラインのF1スコアが20%, 強いモデルで51.0%, 人間で86.8%程度である。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Extensible Effects An Alternative to Monad Transformers</title>
      <link>https://nryotaro.dev/posts/extensible_effects/</link>
      <pubDate>Sun, 23 Aug 2020 13:34:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/extensible_effects/</guid>
      <description>&lt;p&gt;モナド変換子にかわるモナドの合成方法Extensible Effectsの実装を示す。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ When and Why Your Code Starts to Smell Bad</title>
      <link>https://nryotaro.dev/posts/when_and_why_your_code_starts_to_smell_bad/</link>
      <pubDate>Fri, 21 Aug 2020 18:03:14 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/when_and_why_your_code_starts_to_smell_bad/</guid>
      <description>&lt;p&gt;200件のAndroid, Apache, EclipseのOSSプロジェクトのコミット履歴を調査し、不吉な匂いが生じる原因と理由を調査した。
常識では、改修の繰返しによって匂いのない既存のコードに匂いが生じると考えられているが、これに反して、不吉な匂いのするコードのほとんどが作成時点で不吉な匂いを出していたことを明らかにした。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Extracting and Composing Robust Features with Denoising Autoencoders</title>
      <link>https://nryotaro.dev/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/</link>
      <pubDate>Fri, 21 Aug 2020 17:04:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/</guid>
      <description>&lt;p&gt;ノイズを含む入力からノイズのない入力を復元するように学習すると、次元圧縮の性能を向上できることを示した。
層の深いautoencoderを学習するには、良い初期値を与えなければらないことが知られていた。
&lt;a href=&#34;https://www.cs.toronto.edu/~hinton/science.pdf&#34;&gt;先行研究&lt;/a&gt;は、各中間層を個別に学習することで、良い初期値を求められることを示した。
具体的には、各中間層について、前の層の入力から次の層の出力を推定できるよう個別に学習させる。
一方で、何が良い初期値をなすのかは知られていなかった。
表題の論文は、その条件は入力に含まれるノイズに対して頑強であると仮説をおき、ノイズを除去できるように目的関数を設定することで、次元圧縮の性能が上がることを示し、仮説の正しさを確かめた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Statistical Errors in Software Engineering Experiments: A Preliminary Literature Review</title>
      <link>https://nryotaro.dev/posts/statistical_errors_in_software_engineering_experiments/</link>
      <pubDate>Fri, 14 Aug 2020 18:39:35 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/statistical_errors_in_software_engineering_experiments/</guid>
      <description>&lt;p&gt;ソフトウェア工学の実験において、統計をもちいた手法がどれだけ誤用されているかを調査した。
薬学や心理学の実験では、統計による手法が時に誤って使われていることが知られている。
一方で、ソフトウェア工学では、どの程度誤用がみられるのかは分かっていない。
著者らは、2006から2015年のソフトウェア工学のトップ会議ICSEで発表された論文770件から、実験や評価に統計的手法をもちいたものを選び、10の観点からなる判断基準で、手法の妥当性を評価した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Semi Supervised Learning with Ladder Networks</title>
      <link>https://nryotaro.dev/posts/semi-supervised_learning_with_ladder_networks/</link>
      <pubDate>Fri, 14 Aug 2020 17:01:02 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/semi-supervised_learning_with_ladder_networks/</guid>
      <description>&lt;p&gt;Ladder Networkを半教師あり学習に応用する。
Ladder Networkは、2015年に、著者の一人Valpolaによって教師なし学習のためのネットワークとして発表されている&lt;a href=&#34;https://arxiv.org/abs/1411.7783&#34;&gt;*&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ An Empirical Study On Program Failures On Deep Learning Jobs</title>
      <link>https://nryotaro.dev/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/</link>
      <pubDate>Fri, 07 Aug 2020 18:50:12 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/</guid>
      <description>&lt;p&gt;Microsoftの社内では深層学習のプラットフォームPhillyが運用されており、そこで起きた4960件のジョブの失敗原因を調査した。
調査では、失敗の原因を20のカテゴリに分類し、カテゴリごとに失敗の件数を集計した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Improving Language Understanding by Generative Pre-Training</title>
      <link>https://nryotaro.dev/posts/improving_language_understanding_by_generative_pre_training/</link>
      <pubDate>Fri, 07 Aug 2020 16:45:55 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/improving_language_understanding_by_generative_pre_training/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;GPTの略称で知られる教師なしの事前学習である。
評価実験では、12の自然言語処理タスクのうち9つで、当時のSoTAを上まわる性能を発揮した。
ネットワークはTransformerであり、事前学習では言語モデルを学習する。
手法の独自性は、ファインチューニングでの入力データの作り方にある。
入力形式を工夫し、事前学習時のネットワーク構成を維持することで、効率的な転移学習を実現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Tale from the Trenches: Cognitive Biases and Software Development</title>
      <link>https://nryotaro.dev/posts/a_tale_from_the_trenches/</link>
      <pubDate>Fri, 31 Jul 2020 18:55:54 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_tale_from_the_trenches/</guid>
      <description>&lt;p&gt;エンジニア10人の普段の開発状況から、認知バイアスが開発者にあたえる影響やバイアスの頻度、対策方法について調査した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Factorization Machines</title>
      <link>https://nryotaro.dev/posts/factorization_machines/</link>
      <pubDate>Fri, 31 Jul 2020 16:50:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/factorization_machines/</guid>
      <description>&lt;p&gt;Factorization Machineは、Matrix factorizationのようなFactorization modelとSVMの両方の利点をもつ。
Matrix modelには疎な特徴を入力することができるが、予測のモデルに使うには汎用性に欠ける。
一方、SVMは、汎用的であるが、推薦システムで使われるような疎な特徴を扱うことができない。
Factorizatiom Machineは、両者の利点をそなえており、疎な任意の実数を要素にもつ特徴ベクトルを扱うことができる。
また、予測の計算量が線形であり、必要なパラメタの数も線形であるため、SVMのサポートベクタのように訓練データをモデルに持たせる必要がない。
そのために、大量の訓練データを使う学習も可能となる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exploration of Technical Debt in Start-ups</title>
      <link>https://nryotaro.dev/posts/exploration_of_technical_debt_in_start_ups/</link>
      <pubDate>Fri, 24 Jul 2020 15:26:42 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/exploration_of_technical_debt_in_start_ups/</guid>
      <description>&lt;p&gt;スタートアップ86社を調査し、スタートアップにおける技術的負債を招く要因(precedents)、負債を抱える側面(dimentions)、その影響(outcomes)について調査した。
チームの人数の多さと熟練度の低さが負債の要因を誘発し、負債はテストの不足によくみられた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Deep Learning Recommendation Model for Personalization and Recoomendation Systems</title>
      <link>https://nryotaro.dev/posts/deep_learning_recommendation_model_for_personalization_and_recommendation_systems/</link>
      <pubDate>Fri, 24 Jul 2020 13:53:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_learning_recommendation_model_for_personalization_and_recommendation_systems/</guid>
      <description>&lt;p&gt;協調フィルタリングのような推薦システムのためのネットワークアーキテクチャを提案した。
特徴の疎・密にかかわらず入力として与えることができる。
論文の例題では、個人の選好を示すアイテムとユーザからなる疎な行列を受け取り、ユーザがアイテムをクリックする確率を推定するタスクが使われている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Explaining Pair Programming Session Dynamics from Knowledge Gaps</title>
      <link>https://nryotaro.dev/posts/explaining_pair_programming_session_dynamics_from_knowledge_gaps/</link>
      <pubDate>Fri, 17 Jul 2020 19:20:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/explaining_pair_programming_session_dynamics_from_knowledge_gaps/</guid>
      <description>&lt;p&gt;ペアプログラミングによる知識移転の効果を知るために、9社の社員からなる26組のペアプログラミングを、グラウンデッド・セオリーで調査した。
従来は、熟練度合いで開発者を分けて、ペアプログラミングを分析・評価することが多い。
今回の調査では、システムの要件・仕様のようなシステム固有の知識と、言語、デザインパターン、開発ツールなどの開発全般の知識の2軸で、開発者と知識を分ける重要性を定性的に示した。
一方がシステム固有の知識に欠け、他方が開発全般の知識に欠けるときに、最も知識の伝達が活発だった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Bag of Tricks for Efficient Text Classification</title>
      <link>https://nryotaro.dev/posts/bag_of_trics_for_efficient_text_classification/</link>
      <pubDate>Fri, 17 Jul 2020 17:09:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bag_of_trics_for_efficient_text_classification/</guid>
      <description>&lt;p&gt;2016年における分類のSOTAと互角の精度でありながら、格段に高速に学習、推定可能なモデルを&lt;code&gt;fastText&lt;/code&gt;で構築できることを示した。
評価実験には、&lt;a href=&#34;http://projects.dfki.uni-kl.de/yfcc100m/&#34;&gt;YFCC100M&lt;/a&gt;のキャプションとタイトルからタグを予測するタスク、8つのデータセットによる感情分析が採用された。
タグの予測では、312116個のユニークなタグをつかい、大きなクラス数でもモデルがうまくはたらくことが確かめられた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Recognizing Developers&#39; Emotions while Programming</title>
      <link>https://nryotaro.dev/posts/recognizing_developers_emotions_while_programming/</link>
      <pubDate>Sat, 11 Jul 2020 12:45:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/recognizing_developers_emotions_while_programming/</guid>
      <description>&lt;p&gt;23人の被検者に30分間のプログラミングをさせ、その間5分ごとに進捗と感情を自己申告してもらい、その結果から感情と進捗の関係を調査した。
作業後にインタービューを実施し、感情が変化する要因と良くない感情への対処法をヒアリングした。
感情を測定するため最低限必要な非侵襲的器具を調べるために、被検者には、脳波、皮膚電位、脈波、心拍数を測定する器具を装着して開発してもらった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Pytorch: An Imperative Style, High-Performane Deep Learning Library</title>
      <link>https://nryotaro.dev/posts/pytorch_an_imperative_style_high_performance_deep_learning_library/</link>
      <pubDate>Sat, 11 Jul 2020 01:47:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/pytorch_an_imperative_style_high_performance_deep_learning_library/</guid>
      <description>&lt;p&gt;Pytorchの使い勝手と実行速度について解説した論文である。
ここでの使い勝手は、命令型かつPythonらしいコードでPytorchのAPIを呼びだせることを意味する。
Pytorchは、4つの設計原則として、PythonらしいAPI、機械学習の複雑な処理をPytorch内に隠蔽する、使い勝手のために過度にパフォーマンスを犠牲にしない、完璧な解決策よりも実装の単純さを重視する、をかかげる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Here We Go Again: Why Is It Difficult for Developers to Learn Another Programming Language?</title>
      <link>https://nryotaro.dev/posts/here_we_go_again/</link>
      <pubDate>Sat, 04 Jul 2020 13:55:02 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/here_we_go_again/</guid>
      <description>&lt;p&gt;既知のプログラミング言語の知識は新しい言語を覚える役に立つ。
一方で、新しい言語の学習の妨げにもなることをStack Overflowの質問とプログラマへのインタビューで明らかにした。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Automatic differentiation in Pytorch</title>
      <link>https://nryotaro.dev/posts/automatic_differentiation_in_pytorch/</link>
      <pubDate>Sat, 04 Jul 2020 12:06:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/automatic_differentiation_in_pytorch/</guid>
      <description>&lt;p&gt;Pytorchの自動微分を解説したプレプリントのショートペーパである。
Pytorchの自動微分特徴として、in-placeアルゴリズム、微分の導出に不要な計算を省く仕組みのあるテープ、C++による実装をあげている。
&lt;a href=&#34;https://pytorch.org/blog/pytorch-0_4_0-migration-guide/&#34;&gt;0.4.0での仕様変更&lt;/a&gt;によって&lt;code&gt;Tensors&lt;/code&gt;と&lt;code&gt;Variables&lt;/code&gt;がマージされたことや&lt;code&gt;volatile&lt;/code&gt;が非推奨になったことをふまえていない。
読むときは、以上の点をはじめとする現在のAPIとの差異に注意する必要がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ ROUGE: A Package for Automatic Evaluation of Summaries</title>
      <link>https://nryotaro.dev/posts/rouge/</link>
      <pubDate>Sat, 27 Jun 2020 12:55:45 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/rouge/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;生成された要約を機械的に評価するための指標, Recall-Oriented Understudy for Gisting Evaluation(ROUGE)を提案した論文である。
人が作成した複数の要約文書との再現率で要約文書を評価する。
ROUGEは、ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, ROUGE-SUの5つの指標の総称である。
同じ要約へのROUGEスコアと人の評価の相関によって、ROUGEの指標としての有用性を評価した。
その結果、ROUGE-2, ROUGE-L, ROUGE-W, ROUGE-Sは、文書の要約の評価に向き、ROUGE-1, ROUGE-L, ROUGE-W, ROUGE-SU4, ROUGE-SU9はヘッドラインほどの短い要約文の評価に向いていることがわかった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Do Developers Discover New Tools On The Toilet?</title>
      <link>https://nryotaro.dev/posts/do_developers_discover_new_tools_on_the_toilet/</link>
      <pubDate>Sat, 20 Jun 2020 22:33:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/do_developers_discover_new_tools_on_the_toilet/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mike-bland.com/2011/10/25/testing-on-the-toilet.html&#34;&gt;Testing on the Toilet&lt;/a&gt;の効果を&lt;a href=&#34;https://research.google/pubs/pub41854/&#34;&gt;CausalImpact&lt;/a&gt;で示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Neural Attention Model for Sentence Summarization</title>
      <link>https://nryotaro.dev/posts/a_neural_attention_model_for_sentence_summarization/</link>
      <pubDate>Sat, 20 Jun 2020 16:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_neural_attention_model_for_sentence_summarization/</guid>
      <description>&lt;p&gt;注意機構による深層学習で文を要約する手法である。
もとの文にない単語を含む要約文を生成できるが、生成前に文の長さを決めておかなければならない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ BLEU: a Method for Automatic Evaluation of Machine Translation</title>
      <link>https://nryotaro.dev/posts/bleu/</link>
      <pubDate>Sat, 13 Jun 2020 13:48:07 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bleu/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;自動翻訳を定量的に評価するための指標BLEUを提案した論文である。
指標は、専門家の翻訳に翻訳に高い評価をあたえるよう設計されている。
BLEUは、ひとつの候補訳に対する1つ以上の参照訳をあたえ、0から1の値をとるスコアを出力する。
スコアは高いほどよい。
BLEUは、参照訳にある単語を過剰に含むことや文の短さにペナルティをあたえ、適合率で候補訳を評価する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Sequence to Sequence Learning with Nueral Networks</title>
      <link>https://nryotaro.dev/posts/sequence_to_sequence_learning_with_neural_networks/</link>
      <pubDate>Sat, 06 Jun 2020 00:18:16 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/sequence_to_sequence_learning_with_neural_networks/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;Sequence to Sequenceの論文。
入出力が系列データを学習する場合、入力と出力の長さが等しかったり対応関係にある箇所が系列の方向に単調でなければならなかったりする。
これらの制約に対処するために、Sequence to Sequenceでは、入力全体を固定長のベクトルに一度変換し、そのベクトルをもとに出力を予測する。
2種類のLSTMをもち、入力を与えるLSTMの最終層の隠れ状態で、固定長ベクトルをつくる。
固定長のベクトルは、単調の制約を緩めるはたらきをする。
このベクトルは、もう一方のLSTMにあたえられ、その主力が最終的な出力になる。
実験では、入力系列を反転してあたえると、入力と出力の対応関係にある箇所の距離が近づき、予測性能が上がることが確認された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Google&#39;s Neural Machine Transltation System: Bridging the Gap between Human and Machine Translation</title>
      <link>https://nryotaro.dev/posts/google_neural_machine_translation_system/</link>
      <pubDate>Sat, 30 May 2020 16:09:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/google_neural_machine_translation_system/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;ニューラルネットワークをもちいた機械翻訳システムの論文である。
解決したい問題として、学習と推論時の処理時間の長さ、低頻出の単語を翻訳する難しさ、入力文の一部が翻訳されないことをあげ、注意機構でつながれたEncoderとDecoderからなるアーキテクチャを提案した。
学習時間を短縮するために、Decoderの最初の層とEncodeerの出力層から注意をつくる注意機構を採用し、Decoderを並列に学習できるようにしている。
また、量子化によって推論時間を短縮をしている。
低頻出の単語でも翻訳できるようにwordpieceでエンコードされた入力をうけとる。
入力文の一部が翻訳されない問題に対しては、短い出力文に罰則を課すビームサーチで出力文の候補を探索する仕組みが導入されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Zero-Shot Learning with Semantic Output Codes</title>
      <link>https://nryotaro.dev/posts/zero_shot_learning_with_semantic_output_codes/</link>
      <pubDate>Sat, 23 May 2020 14:04:24 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/zero_shot_learning_with_semantic_output_codes/</guid>
      <description>&lt;p&gt;学習データにないラベルを推定する問題に対してzero-shot leanringと名づけ、ラベルを推定できる確率と条件を形式化した論文である。
形式化するモデルは、複数の二値分類器と1つの最近傍探索器からなる。
最近傍探索は、2値分類器の出力を要素とするベクトルをうけとり、最近傍のラベルに対応するベクトルを探す。
PACフレームワークにもとづく必要な学習データの件数を示し、そのデータで訓練されたモデルが学習データにないラベルを推定できる確率を示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING</title>
      <link>https://nryotaro.dev/posts/a_structured_self_attentivesentence_embedding/</link>
      <pubDate>Sat, 16 May 2020 14:05:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_structured_self_attentivesentence_embedding/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;自己注意機構をもちいて、可変長の文を埋め込み行列に変換するアーキテクチャを発表した論文である。
埋め込み行列の各行は、それぞれ文中の異なる箇所の意味を反映する。
アーキテクチャは2つの構成からなり、入力から出力にむかい双方向LSTMを、次に自己注意機構をもつ。
自己注意機構を導入した背景は、回帰結合型のネットワークでは、全ての時刻わたって入力の意味を保持することは難しく、また不要であるという著者らの仮説である。
3つの実験により、文の分散表現を獲得する先行研究と比較し、自己注意機構の効果が確認された。
注意機構は複数のベクトルのどれを重視するかを学習できるため、埋め込まれた文の箇所を可視化できることも示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Poincaré Embeddings for Learning Hierarchical Representations</title>
      <link>https://nryotaro.dev/posts/poincare_embeddings/</link>
      <pubDate>Sat, 09 May 2020 14:42:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/poincare_embeddings/</guid>
      <description>概要 単語のように上位下位関係のある記号を、ポアンカレ球体模型という双曲空間に埋め込む手法を発表した論文である。 ユークリッド空間よりも、記号間の類似度や上位下位関係が保たれていることを実験的に示した。 記号を木のノードとして配置し関係を表現するとき、ノード数は深さ\(l\)対して指数関数的に増加する。 双曲幾何学では、円板の面積や周は半径\(r\)に対して指数関数的に増大するため、木を2次元でモデル化できる。 たとえば、深さ\(l\)以下のノードを半径\(r \varpropto l \)の空間に配置することができる。 一方、2次元のユークリッド空間の場合、半径\(r\)に対する円周は線形、円の面積は2次関数的であるため、モデル化が難しい。 実験では、次元数が少ないほど、ポアンカレ球体模型とユークリッド空間の間で、上下関係や類似度の表現力に差があった。
損失関数 埋め込みたい上下関係\(\mathcal{D}=\{(u, v)\}\)を記号の数を\(n\)として入力すると、アルゴリズムは、埋め込みベクトルの集合\({\rm \Theta}=\{\boldsymbol{\theta}_i\}^n_{i=1}\)を出力する。 ただし、\(\boldsymbol{\theta}\in \mathcal{B}^d\), \(\mathcal{B}^d=\{\boldsymbol{x}\in \mathbb{R}^d\mid ||\boldsymbol{x}||&amp;lt;1\}\)とする。 学習では、次の損失関数\(\mathcal{L}(\Theta)\)をもちいる。
$$ \mathcal{L}(\Theta)=\sum_{(u, v)\in \mathcal{D}}\log\frac{e^{-d(\boldsymbol{u}, \boldsymbol{v})}}{\sum_{\boldsymbol{v}&#39;\in \mathcal{N}(u)}e^{-d(\boldsymbol{u}, \boldsymbol{v}&#39;)}} $$ \(\mathcal{N}(u)=\{v&amp;rsquo;\mid (u, v&amp;rsquo;)\notin \mathcal{D}\} \cup \{v\}\)は\(v\)を含んだ\(u\)に対する負例である。 実験では、正例に対して10の負例をサンプリングしていた。 \(d\)は、\(\boldsymbol{u}, \boldsymbol{v}\in \mathcal{B}^d\)の距離であり、次の式であたえらえる。
$$ d(\boldsymbol{u}, \boldsymbol{v}) = \mathrm{arccosh}\left(1+2\frac{||\boldsymbol{u}-\boldsymbol{v}||^2}{(1-||\boldsymbol{u}||^2)(1-||\boldsymbol{v}||^2)}\right) $$
最適化 RSGDやRSVRGで損失関数の値を最小化する埋め込みベクトルを探す。 ここでは、RSGDについて説明する。 RSGDでは、次のパラメタの更新式をとる。
$$ \boldsymbol{\theta}_{t+1} = \mathfrak{R}_{\theta_t}(-\eta_t\nabla_R\mathcal{L}(\boldsymbol{\theta}_t)) $$ \(\mathfrak{R}_{\theta_t}\)はレトラクションで、ここでは\(\mathfrak{R}_\theta(\boldsymbol{v})=\boldsymbol{\theta}+\boldsymbol{v}\)をもちいる。 \(\eta_t\)は時刻\(t\)の学習率をさす。 \(\nabla_R\)はリーマン多様体上の勾配であり、ユークリッド空間上の勾配\(\nabla_E\)とは
$$ \nabla_R = \frac{(1-||\boldsymbol{\theta_t}||^2)^2}{4}\nabla_E $$ の関係がある。 以上より、更新式は
$$ \mathrm{proj}(\boldsymbol{\theta})= \begin{cases} \boldsymbol{\theta}/||\boldsymbol{\theta}|| - \epsilon &amp;amp;\mathrm{if}\ ||\boldsymbol{\theta}||\ge 1 \\</description>
    </item>
    
    <item>
      <title>論文 メモ Learning Joint Multilingual Sentence Representations with Neural Machine Translation</title>
      <link>https://nryotaro.dev/posts/learning_joint_multilingual_sentence_representations_with_neural_machine_translation/</link>
      <pubDate>Wed, 29 Apr 2020 14:40:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_joint_multilingual_sentence_representations_with_neural_machine_translation/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;多言語の文をあつかう分散表現モデルを発表した論文である。
異なる言語の文であっても、意味が同じであれば、同様の分散表現に変換される。
モデルのアーキテクチャにはseq2seqを、入力と出力には対訳コーパスをつかう。
ミニバッチごとに、入力または出力の言語をいれかえ、言語に依存しない文の意味の分散表現への変換方法を学習する。
本論文の成果は多言語に対応する分散表現のモデルのライブラリ&lt;a href=&#34;https://github.com/facebookresearch/LASER&#34;&gt;LASER&lt;/a&gt;に応用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS</title>
      <link>https://nryotaro.dev/posts/albert/</link>
      <pubDate>Sat, 25 Apr 2020 13:12:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/albert/</guid>
      <description>&lt;p&gt;BERTのパラメタ数を削減し、学習時間の短縮と正則化による予測性能の向上を両立したモデルALBERTを提案し、GLUE, RACE, SQuADでSoTAを実現した。
BERT-largeと比べると、ALBERT-largeのパラメタ数は約5.3%の18Mであり、学習時間は1.7倍速い。
パラメタを削減するために、単語のOne-hotベクトルをあたえられる単語埋め込み行列の次元を減らし、隠れ層の順伝播ネットワークや注意機構のパラメタを層の間で共有した。
また、Next Sentence Prediction(NSP)による学習を、与えられた2文の前後関係を判定する学習Sentence Order Prediction(SOP)におきかえ、主タスクの予測性能を向上をはかった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Random Walks in recommender Systems: Exact Computation and Simulations</title>
      <link>https://nryotaro.dev/posts/random_walks_in_recommender_systems/</link>
      <pubDate>Sat, 18 Apr 2020 01:25:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/random_walks_in_recommender_systems/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/4072747&#34;&gt;F. Foussら&lt;/a&gt;や&lt;a href=&#34;https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-444.pdf&#34;&gt;M. Goriら&lt;/a&gt;のランダムウォークによる推薦システムの先行研究を、質や計算量について比較した論文である。
比較対象には、著者らの用意したも含まれる。
実験には、MovieLensのデータセットが使われた。
F. Foussらの実験で使われた評価指標や上位kの推薦結果のヒット数で評価したところ、著者らの用意した単純な手法\(P^s\)やその拡張\(P_\alpha^s\)が質と計算量の両方で最も優れた結果を残した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Domain Adversarial Training of Neural Networks</title>
      <link>https://nryotaro.dev/posts/domain_adversarial_training_of_neural_networks/</link>
      <pubDate>Sat, 11 Apr 2020 15:07:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/domain_adversarial_training_of_neural_networks/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;ニューラルネットワークをもちいたドメイン適用の論文である。
ソースドメインのラベルつきデータと目標ドメインのラベルのないデータでモデルを訓練し、目標ドメインに対する分類性能を引きあげる。
目的関数は、ソースドメインの分類器の目的関数とデータのドメインを判定する識別器の目的関数からなる。
後者は、前者の正則化項としてはたらく。
これにより、ドメイン間に共通する特徴からソースドメインのデータのラベルを高い性能で予測できるようになる。
目標関数から、ドメイン間のデータの分布が近いほど、目標ドメインのデータでも高い分類性能を発揮する。
先行研究との違いは、できるだけ共通するする特徴で分類するという着想を、通常の分類と同じく、確率的勾配降下法で実現したところにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Character-Aware Neural Language Models</title>
      <link>https://nryotaro.dev/posts/character_aware_neural_language_models/</link>
      <pubDate>Sat, 04 Apr 2020 16:46:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/character_aware_neural_language_models/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;文字単位の入力から次に出現する単語を予測するニューラル言語モデルの論文である。
アーキテクチャは入力から近い順にCNN, highway network, LSTMからなる。
実験データにPenn Treebankを、評価指標にPerplexityを採用してモデルを評価したところ、
論文が発表された2016年時点での&lt;a href=&#34;https://arxiv.org/abs/1409.2329&#34;&gt;SOTA&lt;/a&gt;の60%程度のパラメタしかないモデルでありながら、これに匹敵する性能を発揮した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Deep contextualized word representations</title>
      <link>https://nryotaro.dev/posts/deep_contextualized_word_representations/</link>
      <pubDate>Tue, 24 Mar 2020 01:59:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_contextualized_word_representations/</guid>
      <description>&lt;p&gt;文脈をふまえた単語の分散表現を生成する手法を提案し、教師あり学習に応用することで評価した論文である。
文字単位の学習済み双方向LSTM言語モデルへの入力と各層の出力から分散表現をつくる。
言語モデルの入力やどの層をどれだけ重視するかは、教師あり学習のときに更新するパラメタのひとつになる。
実験では、構文にかかわるタスクであれば入力層に近い層が、意味にかかわるものであれば出力層に近い層が、重視された。
モデルは、Embeddings from Language Modelsにちなみ、ELMoと名付けられた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ The Seven Sins: Security Smells in Infrastructure as Code Scripts</title>
      <link>https://nryotaro.dev/posts/the_seven_sins/</link>
      <pubDate>Fri, 20 Mar 2020 15:14:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_seven_sins/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;OSSの調査にもとづき、Infrastrucure as Code(IaC)スクリプトに潜む主要なセキュリティ上の不吉な匂い(Security Smells)を7つ列挙し、これらを検出するツールを実装した論文である。
論文のねらいは、開発者がIaCスクリプトに不吉な匂いを混ぜないようにすることにある。
著者らは、本論文で、ICSE2019のDistinguished Paper Awardを受賞した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Semi-supervised Sequence Learning</title>
      <link>https://nryotaro.dev/posts/semi_supervised_sequence_learning/</link>
      <pubDate>Sat, 14 Mar 2020 23:46:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/semi_supervised_sequence_learning/</guid>
      <description>&lt;p&gt;系列データの教師あり学習において、ラベルのないデータを学習した言語モデルやオートエンコーダーの重みでLSTMを初期化することの有用性を実験的に示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ In Search of an Understandable Consensus Algorithm</title>
      <link>https://nryotaro.dev/posts/raft/</link>
      <pubDate>Mon, 09 Mar 2020 02:17:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/raft/</guid>
      <description>&lt;p&gt;コンセンサスアルゴリズムRaftを提案した論文である。
Raftは、Multi Paxosと同様の実行結果をもたらす。
実行するコマンドのログをサーバ間で交換することで、状態を同期し、サーバの一部が落ちてもシステムを継続することができる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</title>
      <link>https://nryotaro.dev/posts/sentence_piece/</link>
      <pubDate>Sat, 29 Feb 2020 21:15:17 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/sentence_piece/</guid>
      <description>&lt;p&gt;SentencePieceは、深層学習向けのトークナイザ・脱トークナイザである。
特定の言語を意識した処理がないため、あらゆるテキストに利用できる。
本論文では、C++やPythonによる&lt;a href=&#34;https://github.com/google/sentencepiece&#34;&gt;実装&lt;/a&gt;と翻訳への適用実験について書かれている。
アルゴリズムの解説は、&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162.pdf&#34;&gt;Sennrich et al.&lt;/a&gt;や&lt;a href=&#34;https://arxiv.org/pdf/1804.10959.pdf&#34;&gt;Kudo.&lt;/a&gt;にゆずられている。
これらの論文について2019年7月13日の&lt;a href=&#34;../neural_machine_translation_of_rate_words/&#34;&gt;記事&lt;/a&gt;と2019年7月17日の&lt;a href=&#34;./subword_regularization/&#34;&gt;記事&lt;/a&gt;で解説している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Latent Dirichlet Allocation</title>
      <link>https://nryotaro.dev/posts/latent_dirichlet_allocation/</link>
      <pubDate>Sun, 23 Feb 2020 21:54:59 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/latent_dirichlet_allocation/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;トピックモデルの潜在的ディリクレ配分法(LDA)の原論文である。
LDAは、テキストコーパスのような離散データの確率的生成モデルである。
意味のあるデータのまとまりに対する端的な説明を与える情報を見つけることを目的としている。
3つの階層からなる階層ベイズモデルである。
、データの要素は、各トピックを表すモデルの混合モデルから生成される。
トピックもまた混合モデルから確率的に生成される。
推論にはベイズ変分法を、パラメタの推定にはEMアルゴリズムをもちいらる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Unsupervised Pretraining for Sequence to Sequence Learning</title>
      <link>https://nryotaro.dev/posts/unsupervised_pretraining_for_sequence_to_sequence_learning/</link>
      <pubDate>Sun, 16 Feb 2020 14:21:55 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/unsupervised_pretraining_for_sequence_to_sequence_learning/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;事前学習とファインチューニングにより&lt;a href=&#34;https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf&#34;&gt;seq2seq&lt;/a&gt;の汎化性能を改善する手法を提案した論文である。
encoderの重みを学習済み言語モデルの重みで初期化する。
decoderについても、encoderと別の言語モデルを用意し、その重みで初期化する。
ただし、工夫のないファインチューニングをすると&lt;a href=&#34;https://arxiv.org/pdf/1312.6211.pdf&#34;&gt;破滅的忘却&lt;/a&gt;が生じてしまう。
そこで、ファインチューニングでは言語モデルとseq2seqの目的関数の両方を学習につかうことで、過学習をさけ、汎化性能を確保する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Playing Atari with Deep Reinforcement Learning</title>
      <link>https://nryotaro.dev/posts/playing_atari_with_deep_reinforcement_learning/</link>
      <pubDate>Sun, 09 Feb 2020 17:05:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/playing_atari_with_deep_reinforcement_learning/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;深層強化学習をAtari2600の7つのゲームに応用し、うち6つについて先行手法の性能を超えたDeep Q-Networks(DQN)を提案した論文である。
ピクセルデータを直接入力として与え、深層学習で方策を学習する手法としては初めて提案された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ context2vec: Learning Generic Context Embedding with Bidirectional LSTM</title>
      <link>https://nryotaro.dev/posts/context2vec/</link>
      <pubDate>Sun, 02 Feb 2020 19:19:46 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/context2vec/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;文書の文脈の分散表現を獲得するニューラルネットワークのアーキテクチャ&lt;em&gt;context2vec&lt;/em&gt;を提案、評価した論文である。
アーキテクチャの基本構造は&lt;a href=&#34;https://arxiv.org/pdf/1301.3781.pdf&#34;&gt;CBOW&lt;/a&gt;と同様で、周辺の単語から中心の単語を当てられるようにコーパスをもとにモデルを訓練する。
CBOWとの違いは、文脈の算出方法にある。
CBOWは、ウィンドウ内のベクトルの平均値で文脈の分散表現を求める。
一方、&lt;em&gt;context2vec&lt;/em&gt;では、双方向LSTMの出力をもとに算出する。&lt;/p&gt;
&lt;!-- raw HTML omitted --&gt;</description>
    </item>
    
    <item>
      <title>論文メモ NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE</title>
      <link>https://nryotaro.dev/posts/neural_machine_translation_by_jointly_learning_to_align_and_translate/</link>
      <pubDate>Sat, 01 Feb 2020 17:21:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/neural_machine_translation_by_jointly_learning_to_align_and_translate/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;Decoderに注意機構を採用したencoder-decoderモデルを提案した論文である。
ICLR2015で発表された。
論文の発表当時、encoder-decoderモデルによる翻訳の多くは、encoderが入力文を固定長ベクトルに変換し、固定長ベクトルから翻訳された文を出力していた。
著者らは、固定長ベクトルへの変換が長い文の翻訳性能を下げていると考え、固定長ベクトルを注意機構におきかえたencoder-decoderモデルを提案する。
モデルは、翻訳に加え、生成する単語と入力文の箇所の関係を学習する。
推定時には、まず、次に生成する単語に関係する入力文の箇所を推定する。
次に、推定された箇所と生成済の単語列をもとに、単語を生成する。
特に長い文書の翻訳において、固定長ベクトルをつかうモデルよりも、提案手法が優れていることを実験的に示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ &#34;Why Should I Trust You?&#34; Explaining the Predictions of Any Classifier</title>
      <link>https://nryotaro.dev/posts/why_should_i_trust_you/</link>
      <pubDate>Sun, 26 Jan 2020 01:38:57 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/why_should_i_trust_you/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;モデルの予測に説明をあたえる手法、Local Interpretable Model-agnostic Explanations (LIME)を提案する。
モデルが回帰や分類器であれば、アルゴリズムによらずLIMEを適用できる。
説明を与えたい事例近くにある事例を解釈可能なモデルに学習させ、解釈可能なモデルで予測を説明する。
また、個別の予測ではなく、モデル自体をよく説明する事例を集める手法Submodullar Pick (SP)-LIMEを提案する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Active Learning for Ranking through Expected Loss Optimization</title>
      <link>https://nryotaro.dev/posts/active_learning_for_ranking_through_expected_loss_optimization/</link>
      <pubDate>Sun, 19 Jan 2020 18:23:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/active_learning_for_ranking_through_expected_loss_optimization/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;Yahoo! Labsで開発されたランキングのための能動学習の論文である。
提案手法は、Yahoo!検索エンジンでの&lt;a href=&#34;https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf&#34;&gt;採用実績&lt;/a&gt;がある。
手法は、Expected Loss Optimization(ELO)とよばれ、ベイズ決定則によって識別したときの損失の期待値が最大になるデータを選ぶ。
ELOに用いる損失関数にDCGを採用したExpected DCG Loss Optimization(ELO-DCG)を提案し、実験で評価した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AtCoderに提出したコードをテストするためのDockerイメージ</title>
      <link>https://nryotaro.dev/posts/docker-cmake-clang/</link>
      <pubDate>Tue, 14 Jan 2020 00:29:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/docker-cmake-clang/</guid>
      <description>AtCoderに提出したコードをテストするためのDockerイメージを実装した。 イメージのDockerfileはこちらにある。 AtCoderで提出したコードをgithubで管理していて、これをテストするために作った。</description>
    </item>
    
    <item>
      <title>論文メモ Unsupervised Models for Named Entity Classification</title>
      <link>https://nryotaro.dev/posts/unsupervised_models_for_named_entity_classification/</link>
      <pubDate>Mon, 13 Jan 2020 19:54:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/unsupervised_models_for_named_entity_classification/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;1999年に発表された教師なしの固有表現抽出の手法である。
発表時期が古いことに注意してほしい。
2つの手法が提案されている。
ひとつは、DL-CoTrainと呼ばれるルールベースの手法であり、教師なしデータに既存のルールを適用、適用結果から導出したルールを既存のルールに追加、をくりかえしてルールを増やす。
もう一方は、AdaBoostを応用したCoBoostとよばれる手法である。
ルールベースの手法のほうがCoBoostよりもよい実験結果であったので、前者のみを説明する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Multilabel Classification with Label Correlations and Missing Labels</title>
      <link>https://nryotaro.dev/posts/multilabel_classification_with_label_correlations_and_missing_labels/</link>
      <pubDate>Mon, 06 Jan 2020 22:27:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/multilabel_classification_with_label_correlations_and_missing_labels/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;ラベルの相関関係を学習し推論に利用するマルチラベルの線形モデルを提案した論文である。
相関関係のあるラベル集合を相関関係のないラベル集合に変換し、ラベルごとに分けて学習する手法、Label transformationを応用する。
分類器は、相関関係だけなく、学習データに与えられていないラベルを推定するように拡張できる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>大砲ラーメン</title>
      <link>https://nryotaro.dev/gallery/taihoh/</link>
      <pubDate>Sun, 05 Jan 2020 13:25:04 +0900</pubDate>
      
      <guid>https://nryotaro.dev/gallery/taihoh/</guid>
      <description>帰省して食べに行きました。 中高校生から食べに行っていました。 そのころは、ラーメン大が600円くらいだった記憶でしたが、帰省の度に高くなって今は800円くらいしました。 隔世の感があります。</description>
    </item>
    
    <item>
      <title>論文メモ Learning Deep Structured Semantic Models for Web Search using Clickthrough Data</title>
      <link>https://nryotaro.dev/posts/learning_deep_structured_semantics_models_for_web_search_using_clickthrough_data/</link>
      <pubDate>Sat, 04 Jan 2020 23:25:20 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_deep_structured_semantics_models_for_web_search_using_clickthrough_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;クエリと文書を同じ低次元の空間に射影する深層学習のモデルを提案した論文である。
クエリと文書は、適合度合いが高いほど、近くに配置される。
教師データは、クエリと文書の組からなる教師データである。
実験では、商用検索エンジンから抽出した16510件のクエリと対応するWeサイトのタイトルがつかわれる。
Web文書の大量の語彙をあつかうために、語彙の増加に対して次元数を抑えるbag-of-wordsの手法、word hasingも提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Classification in the Presence of Label Noise: a Survey</title>
      <link>https://nryotaro.dev/posts/classification_in_the_presence_of_label_noise/</link>
      <pubDate>Mon, 30 Dec 2019 16:07:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/classification_in_the_presence_of_label_noise/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;ノイズのある教師データによるクラス分類の&lt;a href=&#34;https://romisatriawahono.net/lecture/rm/survey/machine%20learning/Frenay%20-%20Classification%20in%20the%20Presence%20of%20Label%20Noise%20-%202014.pdf&#34;&gt;サーベイ論文&lt;/a&gt;である。発表時期は、&lt;a href=&#34;https://ieeexplore.ieee.org/document/6685834&#34;&gt;2013年の12月&lt;/a&gt;である。
主な内容は、ノイズの分類、ノイズが分類に及ぼす影響、ノイズへの対策である。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Distributed Representations of Sentences and Documents</title>
      <link>https://nryotaro.dev/posts/distributed_representations_of_sentences_and_documents/</link>
      <pubDate>Sat, 28 Dec 2019 00:56:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/distributed_representations_of_sentences_and_documents/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://radimrehurek.com/gensim/models/doc2vec.html&#34;&gt;Doc2Vec&lt;/a&gt;のアルゴリズムとして採用されたニューラル言語モデルParagraph Vectorを提案した論文である。
bag of wordsは、文書の単語順を記憶せず、また、似た意味の単語ベクトルと無関係なベクトルを単語にわりあてる。
Paragraph Vectorは、文脈中の単語と抽出元のパラグラフから文脈の中心の単語をあてられるように学習することで、可変長文字列から固定長の文書埋め込みベクトルを生成できるようになる。
これにより、単語順と単語の意味を記憶したベクトルの生成を実現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ GloVe: Global Vectors for Word Representation</title>
      <link>https://nryotaro.dev/posts/glove_vectors_for_word_representation/</link>
      <pubDate>Sat, 21 Dec 2019 23:53:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/glove_vectors_for_word_representation/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.aclweb.org/anthology/D14-1162.pdf&#34;&gt;GloVe&lt;/a&gt;は,コーパスに出現する単語の共起回数を学習するニューラル言語モデルである。
既存手法を単語の出現頻度の統計値つかう手法と対数双線形モデルに分類し、両者の長所を備え短所を補う手法として、GloVeを提案する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ BERT: Pre-training of Deep Bidirectional Transformers for Lnaguages Understaing</title>
      <link>https://nryotaro.dev/posts/bert/</link>
      <pubDate>Sat, 14 Dec 2019 17:39:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bert/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;BERTは&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;Attention Is All You Need&lt;/a&gt;にあるTransformerをアーキテクチャに導入した分散表現のモデルであり、本稿は、事前学習済みのBERTにファインチューニングを適用しQAタスクや自然言語推論のベンチマークにおいて既存研究を上回る結果を示している。
なお、アーキテクチャに関する説明は少なく、子細に知りたい場合は&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;Attention Is All You Need&lt;/a&gt;や&lt;a href=&#34;http://nlp.seas.harvard.edu/2018/04/03/attention.html&#34;&gt;The Annotated Transformer&lt;/a&gt;を参照するように案内されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ 150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com</title>
      <link>https://nryotaro.dev/posts/150_successfuly_machine_learning_modes/</link>
      <pubDate>Sat, 14 Dec 2019 13:25:04 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/150_successfuly_machine_learning_modes/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;宿泊予約サービス&lt;a href=&#34;http://booking.com/&#34;&gt;Booking.com&lt;/a&gt;におけるモデルの開発運用でえられた教訓を6つにまとめたKDD2019の論文である。
教訓の主眼を収益におき、6つの教訓を通して、実運用環境における仮説と実験を反復する重要性を強調する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Ranking Relevance In Yahoo Search</title>
      <link>https://nryotaro.dev/posts/ranking_relevance_in_yahoo_search/</link>
      <pubDate>Sat, 07 Dec 2019 15:10:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/ranking_relevance_in_yahoo_search/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;Yahooの検索エンジンを解説するKDD16の論文である。
論文におけるランキングの課題は、クエリと文書の語彙がことなること、ほとんどのクエリは滅多に入力されないこと、クエリの意味の解釈が難しいことである。
これらの課題に対する手法として、ランキングのモデル、特徴のつくりかた、クエリを文書によせる翻訳モデルを解説する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Dual Embedding Space Model for Document Ranking</title>
      <link>https://nryotaro.dev/posts/a_dual_embedding_space_model_for_document_ranking/</link>
      <pubDate>Sat, 30 Nov 2019 08:18:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_dual_embedding_space_model_for_document_ranking/</guid>
      <description>&lt;p&gt;Dual Embedding Space Model(DESM)は、word2vecで単語埋め込みベクトルにしたクエリと文書のランキング関数である。
実験における比較対象のBM25は、クエリの単語の文書での出現頻度をもとに順序をつける。
DESMは、クエリの単語に関係する単語をもとに判断する。
単語埋め込みベクトルの作りに特徴があり、入力側のone-hotベクトル表現にわりあてる単語埋め込みベクトルでクエリを、出力側でベクトルで文書を分散表現にする。
実験から、DESMだけで順位づけをすると偽陽性が高くなるが、DESMとBM25の加重平均をとるとBM25よりも高いNDCG値になることが分かった。
アルゴリズムを実装したライブラリへのリンクは&lt;a href=&#34;https://github.com/nryotaro/desm&#34;&gt;こちら&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ On Calibration of Modern Neural Networks</title>
      <link>https://nryotaro.dev/posts/on_calibration_of_modern_neural_networks/</link>
      <pubDate>Sat, 23 Nov 2019 14:37:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/on_calibration_of_modern_neural_networks/</guid>
      <description>&lt;p&gt;ネットワークの複雑化、バッチ正則化、重み減衰を使わない、負の対数尤度の過学習が汎化精度を上げるが、予測確率と精度のズレを大きくすることを実験的に示した。
予測確率を補正する6つの手法を19種類のクラス分類のデータセットに適用した結果、
最も補正できたものは、温度つきソフトマックスの出力を予測確率にする場合であった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Trinary-Projection Trees for Approximate Nearest Neighbor Search</title>
      <link>https://nryotaro.dev/posts/trinary_projection_trees/</link>
      <pubDate>Sat, 16 Nov 2019 13:12:52 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/trinary_projection_trees/</guid>
      <description>&lt;p&gt;Trinary-Projection Trees(TP trees)は、kd木のように、ユークリッド空間の分割を二分木で表現できるデータ構造である。
超平面は1または-1の重みのついた少数の座標軸で定義される。
これにより、探索時の分岐にかかる計算が、加算と減算だけからなる\(O(1)\)となる。
また、射影されたデータの分散の大きい超平面を探し、同じ分割にある点同士の距離を小さくすることで、精度を向上させている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers</title>
      <link>https://nryotaro.dev/posts/get_another_label/</link>
      <pubDate>Sat, 09 Nov 2019 21:46:12 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/get_another_label/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;ある確率でデータに誤ったラベルをふるlabelerでデータにラベルをふるときに、
既にラベルのあるデータに重ねてラベルをふるべきか調査した。
12種類のラベルつきデータセットを使い、
正解ラベルを誤ったラベルに置換する割合や同一のデータのもつラベルの数を変化させ、モデルの精度の違いを観察した。
加えて、ラベルをふるべきデータを推定する手法も提案している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ ActiveClean: Interactive Data Cleaning For Statistical Modeling</title>
      <link>https://nryotaro.dev/posts/active_clean/</link>
      <pubDate>Sat, 09 Nov 2019 15:37:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/active_clean/</guid>
      <description>&lt;p&gt;ActiveCleanは、教師データの誤りを修正し、モデルの精度を改善する手法である。
優先して修正すべきデータを推定し、データが修正されたら修正されたデータでモデルを学習する。
この修正と学習を条件を満たすまでくりかえす。
反復的な学習で大域的最適解をえられるモデルであれば、最適解への収束が保証される。
データの修正件数が等しい場合に、先行研究と比べて最大2.5倍の精度改善を達成した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ WebTables: Exploring the Power of Tables on the Web</title>
      <link>https://nryotaro.dev/posts/web_tables/</link>
      <pubDate>Thu, 31 Oct 2019 21:09:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/web_tables/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題の論文は、Web上の表から抽出した大量の関係モデルを対象にした検索を提案・評価した
。検索の他にも、一部の属性を入力とするスキーマの補完、入力した属性ないしスキーマに類似のものを推定するアルゴリズムの議論もある。
ここのスキーマは属性のリストである。論文の著者らは研究時にGoogleに在籍しており、論文で使われたコーパスはグーグルの汎用ウェブクローラで集めた141億のHTMLの表から抽出した高精度な154百万の関係モデルである。
コーパスに使うものはHTML形式の表から抽出した関係モデルのみである。
手法の新規性は、1億以上もの大量のテーブルを対象にしていることにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ A Survey on Data Collection for Machine Learning</title>
      <link>https://nryotaro.dev/posts/a_survey_on_data_collection_for_machine_learning/</link>
      <pubDate>Sat, 26 Oct 2019 14:27:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_survey_on_data_collection_for_machine_learning/</guid>
      <description>&lt;p&gt;表題の論文は、文字通り、機械学習に使う教師データに関するサーベイ論文であり、
機械学習や自然言語処理などのデータの応用分野だけでなく、データの管理にまつわる分野の調査も含まれているところに特徴がある。
データの管理に着目している理由は、深層学習の発展によって必要な教師データが増えたことで、データの管理の課題が顕在化してきたことである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</title>
      <link>https://nryotaro.dev/posts/structure_estimation_for_dscrete_graphical_models/</link>
      <pubDate>Sat, 19 Oct 2019 16:21:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/structure_estimation_for_dscrete_graphical_models/</guid>
      <description>&lt;p&gt;表題の論文は、マルコフ確率場をなす無向グラフとグラフの構造を反映した逆共分散行列の間の対応関係を証明し、
観測した確率変数の値からグラフの構造を復元する実験を通じて、対応関係を確認した。
この手法は&lt;a href=&#34;https://arxiv.org/pdf/1810.02840.pdf&#34;&gt;Snorkel&lt;/a&gt;というWeak supervisionの手法において、
正解データのない環境で、ノイズつきの教師データを生成する異なるソース間の相関関係を推定するために応用された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Feature Selection for Text Categorization on Imbalanced Data</title>
      <link>https://nryotaro.dev/posts/feature_selection_for_text_categorization_on_imbalance_data/</link>
      <pubDate>Sat, 12 Oct 2019 15:59:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/feature_selection_for_text_categorization_on_imbalance_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題の論文は、特徴選択において、正例に顕著な特徴から選ぶ割合を明示的に決めることで、正例と負例それぞれに顕著な特徴の割合を調整することが、不均衡な文書分類における予測性能の向上に役立つことを示した。
情報利得やオッズ比など単変量統計にもとづく特徴選択において、統計量の値によって暗黙的に決められた割合と異なる割合の場合の方が予測性能が高いことを実験的に示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale</title>
      <link>https://nryotaro.dev/posts/snorkel_drybell_case_study/</link>
      <pubDate>Sat, 05 Oct 2019 00:45:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/snorkel_drybell_case_study/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題の論文では、&lt;a href=&#34;https://www.snorkel.org&#34;&gt;Snorkel&lt;/a&gt;というWeak Supervisionの手法をGoogleで適用した結果の考察と評価がなされている。
Weak Supervisionは、人手よりも効率良くノイズ交じりの教師データを生成する手法である。
Snorkelは、引数にサンプルを返り値にラベルを返す複数の関数をラベルなしデータに適用し、結果から関数の精度を予測し、個々の関数よりも高い精度でデータにラベルを与える。この関数をラベリング関数という。Snorkel DryBellは、Snorkelのアルゴリズムをスケールさせるために、MapReduceに適用できるように修正されたものをさす。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Training Complex Models with Multi-Task Weak Supervision</title>
      <link>https://nryotaro.dev/posts/training_complex_models_with_multi_task_weak_supervision/</link>
      <pubDate>Sat, 28 Sep 2019 14:53:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/training_complex_models_with_multi_task_weak_supervision/</guid>
      <description>&lt;p&gt;論文の表題は、ソース間の粒度や精度が揃っていることを前提とせず、&lt;a href=&#34;https://arxiv.org/pdf/1212.0478.pdf&#34;&gt;LohとWainwrightらの手法&lt;/a&gt;でソースの精度を推定し、ソースのラベルよりも精度が高いラベルをデータに与えるWeak supervsionの手法である。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Snorkel: Rapid Traning Data Creation with Weak Supervision</title>
      <link>https://nryotaro.dev/posts/snorkel_rapid_training_data_creation_with_weak_supervision/</link>
      <pubDate>Sat, 21 Sep 2019 12:01:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/snorkel_rapid_training_data_creation_with_weak_supervision/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題の論文は、Weak supervisionの一種であるSnorkelを学習データの収集効率と予測性能についての既存手法や教師あり学習と比べた評価をまとめてる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Software Engineering for Machine Learning: A Case Study</title>
      <link>https://nryotaro.dev/posts/software_engineering_for_machine_learning/</link>
      <pubDate>Sat, 14 Sep 2019 11:26:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/software_engineering_for_machine_learning/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題の論文は、マイクロソフトでのAIを応用したアプリケーションの開発についての調査結果をまとている。
著者らは、9人中の8名がMicrosoft Researchに所属し、本論文で2019年のICSEのSoftware Engineering in Practiceの分野でBest Paper Awardを受賞した。
主な貢献は、各チームにおける開発フローを9のステージに分けて解説したこと、機械学習を応用するアプリケーションやプラットフォームの開発におけるベストプラクティスを示したこと、機械学習を応用するアプリケーションの開発に固有の課題にまつわる論考の3つである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Class Imbalance, Redux</title>
      <link>https://nryotaro.dev/posts/class_imbalance_redux/</link>
      <pubDate>Sat, 07 Sep 2019 15:34:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/class_imbalance_redux/</guid>
      <description>&lt;p&gt;表題の論文は、不均衡データの特徴が二値分類の予測性能に及ぼす影響を理論づける論文である。
理論と実験を通じて、多くのケースにおいて、アンダーサンプリングによる均衡データのバギングで予測性能があがったことを示している。
バギングは、アンダーサンプリングによる偏りを抑えて予測性能を安定させるために使われる。
論文で扱うモデルは、SVMなどの学習で経験損失を最小化するモデルに限定されている。発表学会は2011年のICDMである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Learning on the Border: Active Learning in Imbalanced Data Classification</title>
      <link>https://nryotaro.dev/posts/learning_on_border/</link>
      <pubDate>Sat, 31 Aug 2019 02:05:53 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_on_border/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題にある論文は、不均衡データの二値分類についての予測性能を能動学習で改善する手法を提案している。
着想は、学習器のマージン付近では正例と負例がよりバランスしていると仮定し、
マージン付近にあるデータを集めることで、均衡のとれたデータセットを用意することにある。
具体的には、ラベルづけしたデータでSVMをオンライン学習し、無作為に抽出されたラベルのないデータの中で最も超平面に近いデータにラベルをつける手順をマージンの中にあるデータ数が変わらなくなるまで繰り返す。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Distilling the Knowledge in a Neural Network</title>
      <link>https://nryotaro.dev/posts/distilling_the_knowledge_in_a_neural_network/</link>
      <pubDate>Sat, 24 Aug 2019 23:04:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/distilling_the_knowledge_in_a_neural_network/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題にあるニューラルネットワークの蒸留についての論文を紹介する。
蒸留は、既存のモデルを使い、できるだけ予測性能を落とさずに、より小さいモデルを作るための学習手法である。
既存のモデルとして想定されているのは、複数のモデルからなるモデルや正則化された大きなモデルのように予測性能は高いが計算コストが高いものであり、
蒸留の目的は本番の運用に耐えられるデプロイ可能なモデル作ることにある。
本論文は、出力層の活性化関数に温度つきソフトマックスを使った多クラス分類のモデルを蒸留する手法を提案し、実験により手法を評価している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ FastXML: A Fast, Accurate and Stable Tree-classifier for eXtreme Multi-label Learning</title>
      <link>https://nryotaro.dev/posts/fastxml/</link>
      <pubDate>Sat, 24 Aug 2019 15:45:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/fastxml/</guid>
      <description>&lt;p&gt;表題にあるExtreme multi-label classificationの手法を紹介する。
Extreme multi-label classificationの目的は、大量のラベルの候補から与えられたデータに関連する複数のラベルを推定する学習器を構築することにある。
FastXMLは、弱学習器に決定木を使うアンサンブル学習であり、ノードの分割の評価関数にnDCGを採用することで、学習にかかる時間と予測精度の向上を意図している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Advantages and Disadvantages of a Monolithic Repository</title>
      <link>https://nryotaro.dev/posts/advantages_and_disadvantages_of_a_monolithic_repository/</link>
      <pubDate>Sat, 17 Aug 2019 14:49:48 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/advantages_and_disadvantages_of_a_monolithic_repository/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題は、マルチリポジトリと比べたときのモノリシックリポジトリの長所と短所の調べた論文のタイトルである。
論文は2018年のICSEでGoogleから発表された。
調査方法はGoogle社のエンジニアへのアンケートとエンジニアの行動ログの分析が採用されている。
Googleではモノリシックリポジトリが採用されており、エンジニアがこれまで経験したマルチリポジトリが比較対象となっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ CatBoost: unbaiased boosting with categorical features</title>
      <link>https://nryotaro.dev/posts/cat_boost/</link>
      <pubDate>Sat, 10 Aug 2019 23:27:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/cat_boost/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題はNeurIPS 2018で発表されたCatBoostという勾配ブースティングの手法を論文にちなむ。
Target Statisticsというカテゴリカル特徴量の前処理と勾配ブースティングの学習時に生じる一種のleakageが起きることを示し、leakageをさけて前処理と学習をする手法を示した。
CatBoostは二進木の決定木を弱識別器に用いる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches</title>
      <link>https://nryotaro.dev/posts/are_we_really_making_much_progress/</link>
      <pubDate>Sat, 10 Aug 2019 14:39:11 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/are_we_really_making_much_progress/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題は、ニューラルネットワークを用いた推薦システムを提案、評価した論文における実験の再現性と予測性能の再評価した論文のタイトルにあたる。
発表学会は、2019年のRecSys。著者らは、以下の2つのRQに回答するためにトップ会議で発表された18の論文を調査した。その結果、実験を再現できた論文は7稿であり、その中でも単純な手法を上回る性能が認められたのは1稿だけだった。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RQ1: ニューラルネットワークを用いた推薦システムの研究の再現性はどの程度か&lt;/li&gt;
&lt;li&gt;RQ2: 最近発表されたアルゴリズムは、ハイパーパラメタチューニングされた単純な手法と比べてどの程度性能がいいか&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>メモ Gaussian Processes for Regression</title>
      <link>https://nryotaro.dev/posts/gaussian_processes_for_regression/</link>
      <pubDate>Sat, 03 Aug 2019 21:54:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/gaussian_processes_for_regression/</guid>
      <description>&lt;p&gt;表題はガウス過程の回帰問題への応用を提案した論文。著者らは、scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process&#34;&gt;ガウス過程回帰&lt;/a&gt;の
元になっている&lt;a href=&#34;http://www.gaussianprocess.org/gpml/chapters/RW.pdf&#34;&gt;Gaussian Processes for Machine Learning&lt;/a&gt;の著者と同じ。
論文の構成は、ガウス過程回帰の予測分布の式、ハイパーパラメタ推定方法、実験による評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Google Vizier: A Service for Black-Box Optimization</title>
      <link>https://nryotaro.dev/posts/google_vizier/</link>
      <pubDate>Sat, 03 Aug 2019 17:18:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/google_vizier/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題にあるVizierはGoogleにおいてデファクトになっているブラックボックス最適化のためのサービスであり、
論文は、Vizierのシステムアーキテクチャの構成とアルゴリズムの説明とその評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Learning Active Learning from Data</title>
      <link>https://nryotaro.dev/posts/learning_active_learning_from_data/</link>
      <pubDate>Sat, 27 Jul 2019 16:40:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_active_learning_from_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題にある論文は、次にラベルを与えるべきデータが何かという能動学習における問題を、
あるサンプルを教師データに追加したときの損失関数の減少値を予測する回帰の問題としてとらえる。
能動学習の目的は最小限データで最大の予測性能をもつモデルを構築することであり、次にアノテーションすべきデータが何かを正しく予測することが課題になる。
論文は、アノテーションすべきサンプルを予測する回帰モデルを学習するアルゴリズムを提案、評価する。アルゴリズムは2値分類の分類器を対象としている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 TextRank: Bringing Order into Texts</title>
      <link>https://nryotaro.dev/posts/textrank/</link>
      <pubDate>Sat, 20 Jul 2019 17:49:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/textrank/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題にある論文は、ドキュメントからキーワードとキーセンテンスを抽出するためのグラフベースのアルゴリズムTextRankを提案、評価した。
TextRankは、名前から推測できるようにPageRankを応用した手法であり、頂点の重要度を、頂点の内容のような局所的な情報ではなく、他の頂点との辺の接続関係を含むグラフ全体の大域的な情報から決定する。PageRankとTextRankのアルゴリズムの違いは、TextRankの場合は辺ごとに重みが設定できるところにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates</title>
      <link>https://nryotaro.dev/posts/subword_regularization/</link>
      <pubDate>Wed, 17 Jul 2019 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/subword_regularization/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題は、過去に&lt;a href=&#34;../neural_machine_translation_of_rate_words/&#34;&gt;紹介&lt;/a&gt;した&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162&#34;&gt;論文&lt;/a&gt;と同様、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）の元になった論文にあたる。
ノイズに対する頑強さのために、単語のサブワード（部分文字列）を生成するユニグラム言語モデルの学習方法と、モデルから生成されたサブワード列を入力とする機械翻訳モデルの学習方法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Neural Machine Trasnslation of Rare Words with Subword Units</title>
      <link>https://nryotaro.dev/posts/neural_machine_translation_of_rate_words/</link>
      <pubDate>Sat, 13 Jul 2019 17:19:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/neural_machine_translation_of_rate_words/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;内容は、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）のトークナイズで使われるアルゴリズムになっている。単語をサブワード（単語の部分文字列）に分割し、サブワードを組み合わせて珍しい単語や未知語を表現することで、これらの出現頻度の低い単語の翻訳上げるというもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ The Annotated Transformer</title>
      <link>https://nryotaro.dev/posts/the_annotated_transformer/</link>
      <pubDate>Mon, 01 Jul 2019 12:57:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_annotated_transformer/</guid>
      <description>&lt;p&gt;論文は、当サイトで紹介した&lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;Attention Is All You Need&lt;/a&gt;で提案されたTransformerのアーキテクチャを、サンプルコードとオリジナルの論文の引用を交えて解説している。 実装にはPyTorchを使用している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Embedding Logical Queries on Knowledge Graphs</title>
      <link>https://nryotaro.dev/posts/embedding_logical_queries_on_knowledge_graphs/</link>
      <pubDate>Sun, 17 Feb 2019 17:03:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/embedding_logical_queries_on_knowledge_graphs/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;一階述語論理式で表現されたクエリを満たすノードを、分散表現に変換し、ナレッジグラフの中から計算時間上効率よく見つけるアルゴリズムを提案した。
クエリに現れるエッジの数に対して計算時間が線形であることが特徴。
ただし、クエリには、存在量化と連接を使えるが、全称量化、選択、否定を使うことができない制約がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Regularizing and Optimizing LSTM Language Models</title>
      <link>https://nryotaro.dev/posts/regularizing_and_optimizing_lstm_language_models/</link>
      <pubDate>Fri, 23 Nov 2018 19:27:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/regularizing_and_optimizing_lstm_language_models/</guid>
      <description>&lt;p&gt;本稿は、LSTMを用いた言語モデルに対して正規化と最適化を適用し、実験を通して既存の先行研究とperplexityの観点で予測性能を評価した。本稿の手法の利点は、LSTMの実装に変更を加えずに適用できるために、NVIDIA cuDNNなどの高速でブラックボックスなライブラリで実装できることにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Deep Joint Entity Disambiguation with Local Neural Attention</title>
      <link>https://nryotaro.dev/posts/deep_joint_entity_disambiguation/</link>
      <pubDate>Fri, 09 Nov 2018 21:11:50 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_joint_entity_disambiguation/</guid>
      <description>&lt;p&gt;本稿は、当ページで紹介した&lt;a href=&#34;https://aclweb.org/anthology/K18-1050&#34;&gt;End-to-End Neural Entity Linking&lt;/a&gt;(End-to-End) の著者らの先行研究にあたる。
End-to-EndがEntity LinkingのMention Detection(MD)とEntity Disambiguation(ED)の両方をアプローチの対象にしているのに対し、本稿ではEDのみが対象となっている。
したがって、文章からmention（参照表現）が抽出されていることが前提にあり、提案の中心は、参照表現に対応するエンティティを候補の中から正しく求める手法にある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ End-to-end Neural Entity Linking</title>
      <link>https://nryotaro.dev/posts/end_to_end_neural_entity_linking/</link>
      <pubDate>Fri, 02 Nov 2018 16:59:14 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_neural_entity_linking/</guid>
      <description>&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;
&lt;p&gt;本稿は、End to EndなEntity Linkingモデルのアーキテクチャを提案し、予測性能の評価実験で有用性を評価した。
実験のデータセットには、Entity annotationの評価に使える様々なデータセットを集めた&lt;a href=&#34;https://github.com/dice-group/gerbil/wiki&#34;&gt;Gerbil Platform&lt;/a&gt;が使われている。そのうちの&lt;a href=&#34;https://natural-language-understanding.fandom.com/wiki/AIDA-CoNLL&#34;&gt;AIDA/CoNLL&lt;/a&gt;データセットにおいて、提案手法は既存手法を超える予測性能を発揮した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DeepType: Multilingual Entity Linking by Neural Type System Evolution(2018)</title>
      <link>https://nryotaro.dev/posts/deeptype/</link>
      <pubDate>Fri, 26 Oct 2018 20:53:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deeptype/</guid>
      <description>&lt;p&gt;本稿は、既存のオントロジから型システムを構築するアルゴリズムと型システムによるEntity Linking(EL)を提案した。実験を通じて既存手法と比較し、精度の向上を確認した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
      <link>https://nryotaro.dev/posts/conditional_random_fields_probabilistic_models_for_segmenting_and_labeling_sequence/</link>
      <pubDate>Fri, 12 Oct 2018 18:39:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/conditional_random_fields_probabilistic_models_for_segmenting_and_labeling_sequence/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;本稿は、条件付き確率場（Conditional Random Fields, CRF）を提案し、品詞タグづけにおけるerror rateをもとに評価した。
評価の比較対象には、Maximum entropy Markov models(MEMMs)が採用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Bidirectional LSTM-CRF Models for Sequence Tagging</title>
      <link>https://nryotaro.dev/posts/bidirectional_lstm_crf_models_for_sequence_tagging/</link>
      <pubDate>Fri, 05 Oct 2018 18:46:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bidirectional_lstm_crf_models_for_sequence_tagging/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;本稿では、NLPにおける系列ラベリングためのニューラルネットワークアーキテクチャの提案と評価がなされている。
このアーキテクチャは、当ページで以前紹介した&lt;a href=&#34;https://aclweb.org/anthology/papers/C/C18/C18-1139/&#34;&gt;Contextual String Embeddings for Sequence Labeling&lt;/a&gt;で応用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Contextual String Embeddings for Sequence Labeling</title>
      <link>https://nryotaro.dev/posts/context_string_embeddings_for_sequence_labeling/</link>
      <pubDate>Fri, 28 Sep 2018 16:29:46 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/context_string_embeddings_for_sequence_labeling/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;表題の論文は、ライブラリflairのアルゴリズムを提案、評価したもの。&lt;/p&gt;
&lt;p&gt;論文は、テキストの系列ラベリングに向いた単語の分散表現モデルを提案し、
提案手法が予測性能において既存手法より優れいたことを実験的に示した。
本手法における単語の分散表現は、単語の字面だけでなく、文中における単語の出現位置によって決まる。
いいかえると、同じ単語であっても、文中における出現位置が異なれば、単語は異なる分散表現に変換される。
著者らは、分散表現に文脈の情報を含められることを強調して、提案手法をContextual String Embeddingsと名付けた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Universal Language Model Fine-tuning for Text Classification</title>
      <link>https://nryotaro.dev/posts/universal_language_model_fine_tuning_for_text_classification/</link>
      <pubDate>Fri, 14 Sep 2018 16:33:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/universal_language_model_fine_tuning_for_text_classification/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;UMLFiTという、様々なNLPの問題に適用可能なファインチューニングの手法を提案、評価した。
評価手段として、6種のテキスト分類のタスクにおける既存手法とのエラー率の比較が採られている。
主要な評価として、100件のラベル付きデータだけでその100倍のデータを要した事前学習を用いない手法と同等の予測性能が出たことを報告している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ metapath2vec: Scalable Representation Learning for Heterogeneous Networks</title>
      <link>https://nryotaro.dev/posts/metapath2vec/</link>
      <pubDate>Fri, 07 Sep 2018 18:31:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/metapath2vec/</guid>
      <description>&lt;p&gt;異種混合ネットワークから、ノード数x次元数の分散表現を獲得するための手法。
異種混合とは、企業、業界、ニュースなど複数の種類の概念がグラフのノードとして扱われていることを意味する。
獲得した分散表現を訓練データとして分類、クラスタリング、検索に応用し、既存手法と比較している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Applying Deep Learning To Airbnb Search</title>
      <link>https://nryotaro.dev/posts/applying_deep_learning_to_airbnb_search/</link>
      <pubDate>Fri, 31 Aug 2018 19:21:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/applying_deep_learning_to_airbnb_search/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;論文では、Airbnbが深層学習を宿泊先検索に適用した時の試行錯誤と結果を紹介している。
採用したモデルのアルゴリズムと特徴量エンジニアリングの説明が本稿の大部分を占める。
深層学習を試す以前はGBDTを採用おり、以下の順にアルゴリズムを変えていった。
当初は、アルゴリズムを段階的に高度にしていくつもりはなく、1.以前には複雑なアルゴリズムをいきなり試したが、失敗に終わっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ The Relationship Between Precision-Recall and ROC Curve</title>
      <link>https://nryotaro.dev/posts/the_relationship_between_precision_recall_and_roc_curve/</link>
      <pubDate>Sat, 25 Aug 2018 00:56:13 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_relationship_between_precision_recall_and_roc_curve/</guid>
      <description>ROCとPrecision Recallの関係を示した論文。
 1 Recallが0でなければ、ROC曲線には一対一に対応するPR曲線がある。 2 PR曲線AがPR曲線Bに対して常に優位であることとは、ROC曲線においてAがBより常に優位であることの必要十分条件。 3 1,2よりROC空間上の凸包に対応するPR曲線は、他の妥当なPR曲線よりも優位な曲線になる。 4 線形補間でROC曲線を描くことは妥当。一方で、Recallの分母は固定値であるが、Precisionの分母の値はRecallが上がると増える。そのため、PR曲線を線形補間でプロットすると、評価の甘い曲線になる。   論文はこちらからダウンロードできます。</description>
    </item>
    
    <item>
      <title>メモ Enriching Word Vectors with Subword Information</title>
      <link>https://nryotaro.dev/posts/enriching_word_vectors_with_subword_information/</link>
      <pubDate>Fri, 10 Aug 2018 17:29:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/enriching_word_vectors_with_subword_information/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;Fasttextを提案、評価した論文。
Character n-gramsを入力としてskip-gramのモデルを作る方法を提案、評価している。
単語の部分文字列（subword）を使わない手法や形態素解析に頼る手法よりも提案手法が優れていることを実験で示した。
部分文字列のベクトルの和が単語のベクトルとなる。
実験の考察では、そのために、未知語の部分文字列が学習データにあれば、未知語に対しても妥当な分散表現を与えることができるとあった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 When Do Chagnes Induce Fixes?</title>
      <link>https://nryotaro.dev/posts/when_do_changes_induce_fixes/</link>
      <pubDate>Fri, 03 Aug 2018 21:47:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/when_do_changes_induce_fixes/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;ざっくり言うと、バージョン管理ツールとバグチケット管理ツールを導入しているプロジェクトにおいて、
バージョン管理ツールで追跡されている変更とバグチケット管理ツールで追跡されているバグを紐付ける手法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 A Simple Semi-supervised Algorithm For Named Entity Recognition</title>
      <link>https://nryotaro.dev/posts/a_simple_semi_supervised_for_ner/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_simple_semi_supervised_for_ner/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;
&lt;p&gt;CRFに入力する学習データを集めるための半教師学習の手法を提案と評価した論文。
本手法はCRFに与える学習データを集めるための手法であり、CRFのアルゴリズム自体に変更を加えることはない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 Applying Conditional Random Fields to Japanese Morphological Analysis</title>
      <link>https://nryotaro.dev/posts/applying_crf_to_japanese_morph_analysis/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/applying_crf_to_japanese_morph_analysis/</guid>
      <description>&lt;p&gt;Mecabの中の人の&lt;a href=&#34;http://chasen.naist.jp/chaki/t/2009-09-30/doc/mecab-cabocha-nlp-seminar-2009.pdf&#34;&gt;資料&lt;/a&gt;で紹介でされている、Mecabのアルゴリズムを提案・評価した論文。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Text Classification from Labeled and Unlabeled Documents using EM</title>
      <link>https://nryotaro.dev/posts/text_cls_from_lbl_and_unlbl_doc_em/</link>
      <pubDate>Sun, 08 Jul 2018 01:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/text_cls_from_lbl_and_unlbl_doc_em/</guid>
      <description>&lt;h3 id=&#34;アルゴリズム&#34;&gt;アルゴリズム&lt;/h3&gt;
&lt;p&gt;提案手法は、Naive BayesとEMアルゴリズムを組み合わせたもの。
ラベル付きデータが\(D^l\)でラベルなしデータが\(D^u\)で表されるとき、対数尤度\(\log P(D^l)P(D^u)\)を最大化する問題を解く。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://nryotaro.dev/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nryotaro.dev/about/</guid>
      <description>Disclaimer 当ウェブサイトに掲載されている情報の正確性については万全を期していますが、当ウェブサイトの著者は利用者が当ホームページの情報を用いて行う一切の行為について、何らの責任を負うものではありません。</description>
    </item>
    
  </channel>
</rss>