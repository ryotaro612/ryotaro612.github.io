<!DOCTYPE html>
<html>
  <head>
	<meta name="generator" content="Hugo 0.92.2" />
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://nryotaro.dev/scss/base.min.852c1c9119a48dcf6a4274cb71a00bd3b5d55b5040e4d37d525e743de1d0e8da.css">
    

<link rel="stylesheet" href="https://nryotaro.dev/scss/articles.min.ad090cad4f6d9fadf06a509c7ea790bd1fc13b24802f351ad71342659fdebf9f.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>    
    
    <title>Blanket</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="/about">About me</a></li>
          <li><a href="/posts">Posts</a></li>
          <li><a href="/tags">Tags</a></li>
        </ul>
      </nav>
    </header>
    
<main>
    <h1>Posts</h1>
    
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/distilling_the_knowledge_in_a_neural_network/">メモ Distilling the Knowledge in a Neural Network</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題にあるニューラルネットワークの蒸留についての論文を紹介する。
蒸留は、既存のモデルを使い、できるだけ予測性能を落とさずに、より小さいモデルを作るための学習手法である。
既存のモデルとして想定されているのは、複数のモデルからなるモデルや正則化された大きなモデルのように予測性能は高いが計算コストが高いものであり、
蒸留の目的は本番の運用に耐えられるデプロイ可能なモデル作ることにある。
本論文は、出力層の活性化関数に温度つきソフトマックスを使った多クラス分類のモデルを蒸留する手法を提案し、実験により手法を評価している。</p></div>
        <div class="article-footer">
	  
          <span class="date">August 24, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/fastxml/">メモ FastXML: A Fast, Accurate and Stable Tree-classifier for eXtreme Multi-label Learning</a></h3>
        <div class="summary"><p>表題にあるExtreme multi-label classificationの手法を紹介する。
Extreme multi-label classificationの目的は、大量のラベルの候補から与えられたデータに関連する複数のラベルを推定する学習器を構築することにある。
FastXMLは、弱学習器に決定木を使うアンサンブル学習であり、ノードの分割の評価関数にnDCGを採用することで、学習にかかる時間と予測精度の向上を意図している。</p></div>
        <div class="article-footer">
	  
          <span class="date">August 24, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/advantages_and_disadvantages_of_a_monolithic_repository/">メモ Advantages and Disadvantages of a Monolithic Repository</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題は、マルチリポジトリと比べたときのモノリシックリポジトリの長所と短所の調べた論文のタイトルである。
論文は2018年のICSEでGoogleから発表された。
調査方法はGoogle社のエンジニアへのアンケートとエンジニアの行動ログの分析が採用されている。
Googleではモノリシックリポジトリが採用されており、エンジニアがこれまで経験したマルチリポジトリが比較対象となっている。</p></div>
        <div class="article-footer">
	  
          <span class="date">August 17, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/cat_boost/">メモ CatBoost: unbaiased boosting with categorical features</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題はNeurIPS 2018で発表されたCatBoostという勾配ブースティングの手法を論文にちなむ。
Target Statisticsというカテゴリカル特徴量の前処理と勾配ブースティングの学習時に生じる一種のleakageが起きることを示し、leakageをさけて前処理と学習をする手法を示した。
CatBoostは二進木の決定木を弱識別器に用いる。</p></div>
        <div class="article-footer">
	  
          <span class="date">August 10, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/are_we_really_making_much_progress/">メモ Are We Really Making Much Progress? A Worrying Analysis of Recent Neural Recommendation Approaches</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題は、ニューラルネットワークを用いた推薦システムを提案、評価した論文における実験の再現性と予測性能の再評価した論文のタイトルにあたる。
発表学会は、2019年のRecSys。著者らは、以下の2つのRQに回答するためにトップ会議で発表された18の論文を調査した。その結果、実験を再現できた論文は7稿であり、その中でも単純な手法を上回る性能が認められたのは1稿だけだった。</p>
<ul>
<li>RQ1: ニューラルネットワークを用いた推薦システムの研究の再現性はどの程度か</li>
<li>RQ2: 最近発表されたアルゴリズムは、ハイパーパラメタチューニングされた単純な手法と比べてどの程度性能がいいか</li>
</ul></div>
        <div class="article-footer">
	  
          <span class="date">August 10, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/gaussian_processes_for_regression/">メモ Gaussian Processes for Regression</a></h3>
        <div class="summary"><p>表題はガウス過程の回帰問題への応用を提案した論文。著者らは、scikit-learnの<a href="https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process">ガウス過程回帰</a>の
元になっている<a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf">Gaussian Processes for Machine Learning</a>の著者と同じ。
論文の構成は、ガウス過程回帰の予測分布の式、ハイパーパラメタ推定方法、実験による評価からなる。</p></div>
        <div class="article-footer">
	  
          <span class="date">August 3, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/google_vizier/">概要 Google Vizier: A Service for Black-Box Optimization(2017)</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>VizierはGoogleで開発されたブラックボックス最適化のためのサービスである。
論文は、Vizierのシステムアーキテクチャの構成とアルゴリズムの説明とその評価からなる。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E3%83%8F%E3%82%A4%E3%83%91%E3%83%BC%E3%83%91%E3%83%A9%E3%83%A1%E3%83%BC%E3%82%BF%E3%83%81%E3%83%A5%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0/">
		#ハイパーパラメータチューニング
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">August 3, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/learning_active_learning_from_data/">抄訳 Learning Active Learning from Data(2017)</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>能動学習は、できるだけ少数のサンプルでモデルの予測性能を向上できる学習データセットを集める技術である。
論文は、2値分類問題のための能動学習で、サンプルを教師データに追加したときの汎化誤差の減少値を予測し、追加すべきサンプルを推定する。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/active-learning/">
		#Active Learning
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">July 27, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/textrank/">抄訳 TextRank: Bringing Order into Texts(2004)</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>TextRankは、ドキュメントからキーワードとキーセンテンスを抽出するためのグラフベースのアルゴリズムである。
TextRankは、単語を頂点、文書をグラフとみなすことで、PageRankを応用する。
頂点の重要度を、頂点の内容のような局所的な情報ではなく、他の頂点との辺の接続関係を含むグラフ全体の大域的な情報から決定する。
TextRankは、PageRankと違い、辺ごとに重みを設定できる。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E3%82%AD%E3%83%BC%E3%83%AF%E3%83%BC%E3%83%89%E6%8A%BD%E5%87%BA/">
		#キーワード抽出
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">July 20, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/subword_regularization/">概要 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>過去に<a href="../neural_machine_translation_of_rate_words/">紹介</a>した<a href="https://www.aclweb.org/anthology/P16-1162">論文</a>と同様、SentencePiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）の元になった論文である。
ノイズに対するロバストさを上げるために、単語のサブワード（部分文字列）を生成するユニグラム言語モデルの学習方法と、モデルから生成されたサブワード列を入力とする機械翻訳モデルの学習方法を提案した。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3/">
		#機械翻訳
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/sentencepiece/">
		#SentencePiece
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">July 17, 2019</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">  
    
    <li>
      <a href="/">
	<i class="fa-solid fa-xl fa-angles-left"></i>
      </a>
    </li>
    <li>
      <a href="/page/23/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/page/25/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    <li>
      <a href="/page/26/">
	<i class="fa-solid fa-xl fa-angles-right"></i>
      </a>
    </li>
    
</ul>

    <footer>
      <ul>
        
        <li>
          <a href="https://github.com/nryotaro">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
        
      </ul>
      <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
