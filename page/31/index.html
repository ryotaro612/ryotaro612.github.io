<!DOCTYPE html>
<html lang="ja">
  <head>
	<meta name="generator" content="Hugo 0.131.0">
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
    
    <link rel="stylesheet" href="https://ryotaro.dev/scss/base.ja.min.66816a64bc4ce50ec1c4b76199ca9d69163fc8a69f7abc6ea758d1968d8618b0.css">
    

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    <title>Blanket</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="https://ryotaro.dev/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="https://ryotaro.dev/about">About</a></li>
          <li><a href="https://ryotaro.dev/posts">Posts</a></li>
          <li><a href="https://ryotaro.dev/tags">Tags</a></li>
	  
	  <li><a href="https://ryotaro.dev/en/">en</a></li>
	  
        </ul>	
	<ul>
          
          <li>
            <a href="https://github.com/ryotaro612">
              <i class="fab fa-github"></i>
            </a>
          </li>
          
          
          <li>
            <a href="https://www.linkedin.com/in/ryotaro612/">
              <i class="fab fa-linkedin-in"></i>
            </a>
          </li>
          
          <li>
	    <a href="https://ryotaro.dev/index.xml">
	      <i class="fas fa-rss"></i>
            </a>
	  </li>
          
        </ul>	
      </nav>
    </header>
    
<main>
    <h1>Posts</h1>
    
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/the_annotated_transformer/">The Annotated Transformer (2018)</a></h3>
        <div class="summary"><p><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a>で提案されたTransformerのアーキテクチャを、サンプルコードとオリジナルの論文の引用を交えて解説している。 PyTorchで実装されている。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">July 1, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/embedding_logical_queries_on_knowledge_graphs/">抄訳 Embedding Logical Queries on Knowledge Graphs(2018)</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>一階述語論理式で表現されたクエリを満たすノードを、分散表現に変換し、ナレッジグラフの中から計算時間上効率よく見つけるアルゴリズムを提案した。
クエリに現れるエッジの数に対して計算時間が線形であることが特徴。
ただし、クエリには、存在量化と連接を使えるが、全称量化、選択、否定を使うことができない制約がある。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/knowledge-graph/">
		#Knowledge Graph
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">February 17, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/regularizing_and_optimizing_lstm_language_models/">抄訳 Regularizing and Optimizing LSTM Language Models(2017)</a></h3>
        <div class="summary"><p>LSTMをつかった言語モデルに正規化と最適化を適用し、実験でperplexityを評価した。
LSTMの実装に変更を加えない手法なので、NVIDIAやcuDNNなどの高速でブラックボックスなライブラリで実装できる。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">November 23, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/deep_joint_entity_disambiguation/">抄訳 Deep Joint Entity Disambiguation with Local Neural Attention(2017)</a></h3>
        <div class="summary"><p>当ページで紹介した<a href="https://aclweb.org/anthology/K18-1050">End-to-End Neural Entity Linking</a>(End-to-End) の著者らの先行研究にあたる。
End-to-EndがEntity LinkingのMention Detection(MD)とEntity Disambiguation(ED)の両方をアプローチの対象にしているのに対し、今回の論文はEDのみが対象となっている。
したがって、文章からmention（参照表現）が抽出されていることが前提にあり、提案の中心は、参照表現に対応するエンティティを候補の中から正しく求める手法にある。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/entity-disambiguation/">
		#Entity Disambiguation
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">November 9, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/end_to_end_neural_entity_linking/">抄訳 End-to-end Neural Entity Linking(2018)</a></h3>
        <div class="summary"><h3 id="背景">背景</h3>
<p>End to EndなEntity Linkingモデルのアーキテクチャを提案し、予測性能の評価実験で有用性を評価した。
実験のデータセットには、Entity annotationの評価に使える様々なデータセットを集めた<a href="https://github.com/dice-group/gerbil/wiki">Gerbil Platform</a>が使われている。そのうちの<a href="https://natural-language-understanding.fandom.com/wiki/AIDA-CoNLL">AIDA/CoNLL</a>データセットにおいて、提案手法は既存手法を超える予測性能を発揮した。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/entity-linking/">
		#Entity Linking
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">November 2, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/deeptype/">抄訳 DeepType: Multilingual Entity Linking by Neural Type System Evolution(2018)</a></h3>
        <div class="summary"><p>既存のオントロジから型システムを構築するアルゴリズムと型システムによるEntity Linking(EL)を提案した。
DeepTypeにおける型は、Wikipediaのようなオントロジにおける関係を意味する。
たとえば、オントロジに<code>Human</code>という根から<code>instance of</code>で結ばれる子ノードがあれば、<code>IsHuman</code>を型とみなす。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/entity-linking/">
		#Entity Linking
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">October 26, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/conditional_random_fields_probabilistic_models_for_segmenting_and_labeling_sequence/">メモ Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>条件付き確率場（Conditional Random Fields, CRF）を提案し、品詞タグづけにおけるerror rateをもとに評価した。
評価の比較対象には、Maximum entropy Markov models(MEMMs)が採用されている。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/crf/">
		#CRF
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">October 12, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/bidirectional_lstm_crf_models_for_sequence_tagging/">抄訳 Bidirectional LSTM-CRF Models for Sequence Tagging(2015)</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>NLPにおける系列ラベリングためのニューラルネットワークアーキテクチャの提案と評価がなされている。
このアーキテクチャは、当サイトで以前紹介した<a href="https://aclweb.org/anthology/papers/C/C18/C18-1139/">Contextual String Embeddings for Sequence Labeling</a>で応用されている。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E7%B3%BB%E5%88%97%E3%83%A9%E3%83%99%E3%83%AA%E3%83%B3%E3%82%B0/">
		#系列ラベリング
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">October 5, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/context_string_embeddings_for_sequence_labeling/">抄訳 Contextual String Embeddings for Sequence Labeling(2018)</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題の論文は、<a href="https://github.com/flairNLP/flair">flair</a>のアルゴリズムを提案、評価したもの。
論文は、テキストの系列ラベリングに向いた単語の分散表現モデルを提案し、
提案手法が予測性能において既存手法より優れいたことを実験的に示した。
本手法における単語の分散表現は、単語の字面だけでなく、文中における単語の出現位置によって決まる。
いいかえると、同じ単語であっても、文中における出現位置が異なれば、単語は異なる分散表現に変換される。
著者らは、分散表現に文脈の情報を含められることを強調して、提案手法をContextual String Embeddingsと名付けた。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/word-embedding/">
		#Word Embedding
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/ner/">
		#NER
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">September 28, 2018</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/universal_language_model_fine_tuning_for_text_classification/">メモ Universal Language Model Fine-tuning for Text Classification</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>UMLFiTという、様々なNLPの問題に適用可能なファインチューニングの手法を提案、評価した。
評価手段として、6種のテキスト分類のタスクにおける既存手法とのエラー率の比較が採られている。
主要な評価として、100件のラベル付きデータだけでその100倍のデータを要した事前学習を用いない手法と同等の予測性能が出たことを報告している。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/fine-tuning/">
		#Fine Tuning
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">September 14, 2018</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">  
    
    <li>
      <a href="/">
	<i class="fa-solid fa-xl fa-angles-left"></i>
      </a>
    </li>
    <li>
      <a href="/page/30/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/page/32/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    <li>
      <a href="/page/32/">
	<i class="fa-solid fa-xl fa-angles-right"></i>
      </a>
    </li>
    
</ul>

    <footer>
      <small>© Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
