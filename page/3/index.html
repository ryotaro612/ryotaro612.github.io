<!DOCTYPE html>
<html>
  <head>
	<meta name="generator" content="Hugo 0.119.0">
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://nryotaro.dev/scss/base.min.87b8f4076c47000c129b0c8b240a71216448e3aedd7144174c55776680a783b0.css">
    
    <link rel="stylesheet" href="https://nryotaro.dev/scss/base.ja.min.66816a64bc4ce50ec1c4b76199ca9d69163fc8a69f7abc6ea758d1968d8618b0.css">
    

<link rel="stylesheet" href="https://nryotaro.dev/scss/articles.min.ad090cad4f6d9fadf06a509c7ea790bd1fc13b24802f351ad71342659fdebf9f.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    <title>Blanket</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="https://nryotaro.dev/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="https://nryotaro.dev/about">About</a></li>
          <li><a href="https://nryotaro.dev/posts">Posts</a></li>
          <li><a href="https://nryotaro.dev/tags">Tags</a></li>
	  
	  <li><a href="https://nryotaro.dev/en/">en</a></li>
	  
        </ul>
      </nav>
    </header>
    
<main>
    <h1>Posts</h1>
    
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/unsupervised_cross_lingual_representation_learning_at_scale/">Unsupervised Cross-lingual Representation Learning at Scale(2020)</a></h3>
        <div class="summary"><p>多言語モデルを大規模なコーパスで訓練し、含意関係認識、質問応答、固有表現抽出において、多言語版の<a href="https://arxiv.org/abs/1810.04805">BERT</a>を上まわる予測性能を実現した。
モデルのアーキテクチャは<a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>で、<a href="https://arxiv.org/abs/1901.07291">Lample and Conneau, 2019</a>に近い方法でモデルを訓練する。
LampleとConneauの手法を含む従来の多言語の言語モデルの評価実験では、wipediaやwikipediaと同程度の大きさのコーパスが使われていた。
従来の訓練データに対し、100言語からなる2.5TBのCommonCrawlをコーパスに使い、コーパスを大規模化することによるモデルへの影響を分析した。
パラメタ数などのモデル大きさを固定し、言語の種類数を30まで増やしたところ、コーパスの小さい言語の性能が向上したが、それ以上増やすと逆に予測性能が低下した。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E5%A4%9A%E8%A8%80%E8%AA%9E%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#多言語言語モデル
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">June 3, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/a_mojority_consensus_approach_to_concurrency_control_for_multiple_copy_databases/">A Majority Consensus Approach to Concurrency Control for Multiple Copy Databases(1979)</a></h3>
        <div class="summary"><p>データベースを同期するためのアルゴリズム<a href="https://pages.cs.wisc.edu/~remzi/Classes/739/Fall2018/Papers/thomas79-quorums.pdf">majority consensus</a>を提案する。
アプリケーションは任意のデータベースに更新リクエストを送信でき、データベースは更新リクエストの処理について含意をとる。
データベースは、タイムスタンプのついたレコードの集合である。
タイムスタンプは、レコードの値の更新時刻をあらわす。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E5%88%86%E6%95%A3%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0/">
		#分散システム
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">May 27, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/word_translation_without_parallel_data/">WORD TRANSLATION WITHOUT PARALLEL DATA(2018)</a></h3>
        <div class="summary"><p>対訳コーパスを使わずに、ある言語のエンベディングから別の言語のエンベディングへの写像を学習する。
はじめに、敵対的生成ネットワークで写像を学習する。
次に、出現頻度の高い単語について、写像されたエンベディングと目的言語のエンベディングにプロクラステス分析を適用し、より正確な写像関数を求める。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/embedding/">
		#Embedding
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3/">
		#機械翻訳
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">May 21, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/skip_lists_a_probablistic_alternative_to_balanced_trees/">Skip Lists: A Probabilistic Alternative to Balanced Trees(1990)</a></h3>
        <div class="summary"><p><a href="https://15721.courses.cs.cmu.edu/spring2018/papers/08-oltpindexes1/pugh-skiplists-cacm1990.pdf">Skip Lists</a>は、バランス木の代用になるアルゴリズムである。
Skip listsのノードは、ランダムに選ばれた後続のノードへのポインタをもつ。
ランダムに参照するノードを選ぶことで、バランス木よりも単純なアルゴリズムで、計算量を均衡をでき、さらに最悪計算量をより小さくできる。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E3%83%87%E3%83%BC%E3%82%BF%E6%A7%8B%E9%80%A0/">
		#データ構造
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">May 6, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/an_image_is_worth_16x16_words_transformers_for_image_recognition_at_scale/">AN IMAGE IS WORTH 16x16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE(2021)</a></h3>
        <div class="summary"><p>画像認識に<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Transformer</a>を使う手法を提案し、<a href="https://arxiv.org/abs/1912.11370">Big Transfer</a>と<a href="https://arxiv.org/abs/1911.04252">Noisy Student</a>と比較した。
論文が発表された2021年でも、画像認識にニューラルネットワークを使う場合、畳込みニューラルネット(CNN)が基本の選択肢になる。
自己注意機構を使った画像処理の<a href="https://arxiv.org/abs/2003.07853">先行研究</a>はあるが、スケールするアーキテクチャではない。</p>
<p>AN IMAGE IS WORTH 16x16 WORDSは、分割した画像をトークン（単語）のようにTransformerへ入力することで、Transformerを画像認識へ応用できるこを示した。
TransformerはCNNのように画像の向きや局所性を帰納バイアスにもたず、データが不十分でないと汎化性能は低い。
しかし、学習データを14M-300Mまで増やすと、CNNを越える汎化性能を発揮した。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98/">
		#画像認識
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 29, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/virtual_time_and_global_states_of_distributed_systems/">Virtual Time and Global States of Distributed Systems(1988)</a></h3>
        <div class="summary"><p>分散システムのプロセス間で時刻が常に同期しているとは限らない。
プロセスの時刻から判断すると、プロセスでは、ほかのプロセスのイベントと比べてどちらが先に起きたか分からないイベントが起きえる。
<a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf">Lamport</a>は、各プロセスに単調増加する論理的な時刻をもたせ、メッセージとともに時刻をプロセス間で交換することで、イベントの依存関係と矛盾せずにイベントを全順序に並べる手法を提案した。
先行するイベントは、必ず後続のイベントよりも小さい時刻をもつ。
しかし、逆は必ずしも成り立たない。
先行する場合もあれば、前後関係がないこともある。
<a href="http://www.vs.inf.ethz.ch/publ/papers/VirtTimeGlobStates.pdf">Virtual Time and Global States of Distributed Systems</a>は、各プロセスの時刻を、プロセス数とおなじ数の長さの配列で表現する。
これにより、時刻の前後関係が定義されていることがイベント間に前後関係があることの必要十分条件であることを可能にした。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E5%88%86%E6%95%A3%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0/">
		#分散システム
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 22, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/generating_long_sequences_with_sparse_transformers/">Generating Long Sequences with Sparse Transformers(2019)</a></h3>
        <div class="summary"><p><a href="https://arxiv.org/abs/1706.03762">Transformer</a>のQKV注意機構に入力するベクトルを限定し、長さ\(n\)の系列をQKV注意機構に入力したときの空間計算量を\(\mathcal{O}(n\sqrt{n})\)まで減らした<a href="https://arxiv.org/abs/1904.10509">研究</a>である。
Transformerであれば、系列の要素は、要素自体の位置と以前の要素すべてを注意し、時間と空間計算量は\(\mathcal{O}(n^2)\)になる。
Sparse Transformerは、\(p\)個のパターンを用意し、パターンに該当する要素のみを各注意機構に入力し、\(p\)個の注意を生成する。
そして、\(p\)個の注意を合成し、1つの注意に変換する。
パターンは、画像やテキストなど、入力するデータの種類によって決めておく規則であり、たとえば、直近にある一定数の要素や等間隔に離れた要素を指定するパターンがありえある。
パターンが\(p\)であれば、計算量は\(\mathcal{O}\sqrt[p]{n}\)になる。実験の設定は\(p=2\)である。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 15, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/storing_a_sparse_table_with_o1_worst_case_access_time/">Storing a Sparse Table with O(1) Worst Case Access Time(1984)</a></h3>
        <div class="summary"><p>単射のハッシュ関数は完全である。完全ハッシュ関数により、衝突することのないハッシュテーブルのデータ構造と計算時間量の証明を示す。
データ構造は、はじめに、\(U(|U|=m)\)の部分集合\(S\)(\(|S|=n\))の要素\(x\)をハッシュテーブルに格納するとき、ある\(U\)の要素\(k\)を使った関数\(f(x)=(kx\mod p)\mod n\)で\(x\)を格納するブロック\(W_j(0\le j &lt; n)\)を決める。
\(p\)は\(p=m+1\)の素数である。
次に\(U\)の要素\(k&rsquo;_j\)をもちいた関数\(g(x) = ((k&rsquo;_jx) \mod p)\mod |W_j|^2\)で、\(x\)のエントリを特定する。
データ構造の証明は、\(f, g\)によって重複なくエントリを特定できる\(k\), \(k&rsquo;_j\)があることを示す。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E3%83%8F%E3%83%83%E3%82%B7%E3%83%A5%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB/">
		#ハッシュテーブル
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 8, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/language_models_are_unsupervised_multitask_learners/">概要 Language Models are Unsupervised Mmultitask Learners(2018)</a></h3>
        <div class="summary"><p>Zero-shotかつマルチタスク用のモデルとして<a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">GPT-1</a>の後経のGPT-2を提案した。
<a href="https://www.semanticscholar.org/paper/Multitask-Learning-Caruana/161ffb54a3fdf0715b198bb57bd22f910242eb49">マルチタスク学習</a>は、複数のタスクむけにモデルを訓練する手法である。
特徴の入力形式はタスクによらず同じであり、タスク間で知識を補うことで各タスクの汎化性能を向上させる。
GPT-1の用途がファインチューニングであるため、GPT-1とGPT-2では解けるタスクが違う。
学習のために、45,000,000件のリンクを含む高品質なコーパスであるWebTextを人の手もかりて用意した。
GPT-2のアーキテクチャは、GPT-1に層正規化の位置を変え、residual layerの重みをスケールしただけであり、GPT-1と大きな違いはない。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 1, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/proving_correctness_of_multiprocess_programs/">Proving the Correctness of Multiprocess Programs (1977)</a></h3>
        <div class="summary"><p>マルチプロセスプログラムの正しさを証明するための公理を提案する。
正しさの条件は、プログラムが安全性と活性を満たすことである。
安全はプログラムが特定の状態になりえないことを、活性はプログラムが特定の状態に必ず到達することを意味する。
たとえば、キューにメッセージを配信するproducerとキューから取り出すconsumerがあるとする。
このとき、容量以上のメッセージがキューに蓄積しない性質が安全性に、キューが満杯時にconsumerがメッセージを消費する性質が活性になりえる。
プログラム、安全性、活性を形式化し、安全性と活性を証明することで、プログラムの正しさを示す。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E5%88%86%E6%95%A3%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0/">
		#分散システム
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://nryotaro.dev/tags/%E5%BD%A2%E5%BC%8F%E6%89%8B%E6%B3%95/">
		#形式手法
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">March 25, 2023</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">  
    
    <li>
      <a href="/">
	<i class="fa-solid fa-xl fa-angles-left"></i>
      </a>
    </li>
    <li>
      <a href="/page/2/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/page/4/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    <li>
      <a href="/page/30/">
	<i class="fa-solid fa-xl fa-angles-right"></i>
      </a>
    </li>
    
</ul>

    <footer>
      <ul>
        
        <li>
          <a href="https://github.com/nryotaro">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        <li><a href="https://nryotaro.dev/index.xml"><i class="fas fa-rss"></i></a></li>
        
      </ul>
      <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
