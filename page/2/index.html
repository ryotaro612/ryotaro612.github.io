<html>
  <head>
	<meta name="generator" content="Hugo 0.54.0" />
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155190626-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'UA-155190626-1');
    </script>
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css"></link>
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/skeleton/2.0.4/skeleton.css"></link>
    <link href="https://fonts.googleapis.com/css?family=Lato|M+PLUS+1p|M+PLUS+Rounded+1c|Roboto&display=swap" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/css/base.css"></link>
    
  <link rel="stylesheet" type="text/css" href="/css/index.css"></link>

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>
  <body class="container">
    <header>
      <h1><a href="/">Coda</a></h1>
      <nav>
	<ul>
	  <li><a href="/posts/">Posts</a></li>
	  <li><a href="/about/">About</a></li>
	</ul>
      </nav>
    </header>
    <main>
      
  
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/">論文メモ Extracting and Composing Robust Features with Denoising Autoencoders</a></h2>
	  <p>August 21, 2020</p>
	</header>
	<div class="excerpt"><p>ノイズを含む入力からノイズのない入力を復元するように学習すると、次元圧縮の性能を向上できることを示した。
層の深いautoencoderを学習するには、良い初期値を与えなければらないことが知られていた。
<a href="https://www.cs.toronto.edu/~hinton/science.pdf">先行研究</a>は、各中間層を個別に学習することで、良い初期値を求められることを示した。
具体的には、各中間層について、前の層の入力から次の層の出力を推定できるよう個別に学習させる。
一方で、何が良い初期値をなすのかは知られていなかった。
表題の論文は、その条件は入力に含まれるノイズに対して頑強であると仮説をおき、ノイズを除去できるように目的関数を設定することで、次元圧縮の性能が上がることを示し、仮説の正しさを確かめた。</p></div>
	<a class="readmore" href="/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/statistical_errors_in_software_engineering_experiments/">論文メモ Statistical Errors in Software Engineering Experiments: A Preliminary Literature Review</a></h2>
	  <p>August 14, 2020</p>
	</header>
	<div class="excerpt"><p>ソフトウェア工学の実験において、統計をもちいた手法がどれだけ誤用されているかを調査した。
薬学や心理学の実験では、統計による手法が時に誤って使われていることが知られている。
一方で、ソフトウェア工学では、どの程度誤用がみられるのかは分かっていない。
著者らは、2006から2015年のソフトウェア工学のトップ会議ICSEで発表された論文770件から、実験や評価に統計的手法をもちいたものを選び、10の観点からなる判断基準で、手法の妥当性を評価した。</p></div>
	<a class="readmore" href="/posts/statistical_errors_in_software_engineering_experiments/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/semi-supervised_learning_with_ladder_networks/">論文メモ Semi Supervised Learning with Ladder Networks</a></h2>
	  <p>August 14, 2020</p>
	</header>
	<div class="excerpt"><p>Ladder Networkを半教師あり学習に応用する。
Ladder Networkは、2015年に、著者の一人Valpolaによって教師なし学習のためのネットワークとして発表されている<a href="https://arxiv.org/abs/1411.7783">*</a>。</p></div>
	<a class="readmore" href="/posts/semi-supervised_learning_with_ladder_networks/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/">論文メモ An Empirical Study On Program Failures On Deep Learning Jobs</a></h2>
	  <p>August 7, 2020</p>
	</header>
	<div class="excerpt"><p>Microsoftの社内では深層学習のプラットフォームPhillyが運用されており、そこで起きた4960件のジョブの失敗原因を調査した。
調査では、失敗の原因を20のカテゴリに分類し、カテゴリごとに失敗の件数を集計した。</p></div>
	<a class="readmore" href="/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/improving_language_understanding_by_generative_pre_training/">論文メモ Improving Language Understanding by Generative Pre-Training</a></h2>
	  <p>August 7, 2020</p>
	</header>
	<div class="excerpt"><h3 id="概要">概要</h3>

<p>GPTの略称で知られる教師なしの事前学習である。
評価実験では、12の自然言語処理タスクのうち9つで、当時のSoTAを上まわる性能を発揮した。
ネットワークはTransformerであり、事前学習では言語モデルを学習する。
手法の独自性は、ファインチューニングでの入力データの作り方にある。
入力形式を工夫し、事前学習時のネットワーク構成を維持することで、効率的な転移学習を実現する。</p></div>
	<a class="readmore" href="/posts/improving_language_understanding_by_generative_pre_training/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/a_tale_from_the_trenches/">論文メモ A Tale from the Trenches: Cognitive Biases and Software Development</a></h2>
	  <p>July 31, 2020</p>
	</header>
	<div class="excerpt"><p>エンジニア10人の普段の開発状況から、認知バイアスが開発者にあたえる影響やバイアスの頻度、対策方法について調査した。</p></div>
	<a class="readmore" href="/posts/a_tale_from_the_trenches/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/factorization_machines/">論文メモ Factorization Machines</a></h2>
	  <p>July 31, 2020</p>
	</header>
	<div class="excerpt"><p>Factorization Machineは、Matrix factorizationのようなFactorization modelとSVMの両方の利点をもつ。
Matrix modelには疎な特徴を入力することができるが、予測のモデルに使うには汎用性に欠ける。
一方、SVMは、汎用的であるが、推薦システムで使われるような疎な特徴を扱うことができない。
Factorizatiom Machineは、両者の利点をそなえており、疎な任意の実数を要素にもつ特徴ベクトルを扱うことができる。
また、予測の計算量が線形であり、必要なパラメタの数も線形であるため、SVMのサポートベクタのように訓練データをモデルに持たせる必要がない。
そのために、大量の訓練データを使う学習も可能となる。</p></div>
	<a class="readmore" href="/posts/factorization_machines/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/exploration_of_technical_debt_in_start_ups/">Exploration of Technical Debt in Start-ups</a></h2>
	  <p>July 24, 2020</p>
	</header>
	<div class="excerpt"><p>スタートアップ86社を調査し、スタートアップにおける技術的負債を招く要因(precedents)、負債を抱える側面(dimentions)、その影響(outcomes)について調査した。
チームの人数の多さと熟練度の低さが負債の要因を誘発し、負債はテストの不足によくみられた。</p></div>
	<a class="readmore" href="/posts/exploration_of_technical_debt_in_start_ups/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/deep_learning_recommendation_model_for_personalization_and_recommendation_systems/">論文メモ Deep Learning Recommendation Model for Personalization and Recoomendation Systems</a></h2>
	  <p>July 24, 2020</p>
	</header>
	<div class="excerpt"><p>協調フィルタリングのような推薦システムのためのネットワークアーキテクチャを提案した。
特徴の疎・密にかかわらず入力として与えることができる。
論文の例題では、個人の選好を示すアイテムとユーザからなる疎な行列を受け取り、ユーザがアイテムをクリックする確率を推定するタスクが使われている。</p></div>
	<a class="readmore" href="/posts/deep_learning_recommendation_model_for_personalization_and_recommendation_systems/">Read more</a>
      </article>
    
  
    
      <article class="summary">
	<header>
	  <h2><a href="/posts/explaining_pair_programming_session_dynamics_from_knowledge_gaps/">論文メモ Explaining Pair Programming Session Dynamics from Knowledge Gaps</a></h2>
	  <p>July 17, 2020</p>
	</header>
	<div class="excerpt"><p>ペアプログラミングによる知識移転の効果を知るために、9社の社員からなる26組のペアプログラミングを、グラウンデッド・セオリーで調査した。
従来は、熟練度合いで開発者を分けて、ペアプログラミングを分析・評価することが多い。
今回の調査では、システムの要件・仕様のようなシステム固有の知識と、言語、デザインパターン、開発ツールなどの開発全般の知識の2軸で、開発者と知識を分ける重要性を定性的に示した。
一方がシステム固有の知識に欠け、他方が開発全般の知識に欠けるときに、最も知識の伝達が活発だった。</p></div>
	<a class="readmore" href="/posts/explaining_pair_programming_session_dynamics_from_knowledge_gaps/">Read more</a>
      </article>
    
  
  <div class="pagination">
  
    <a href="/"><i class="material-icons">first_page</i></a>
  
  
    <a href="/"><i class="material-icons">chevron_left</i></a>
  
  
    <a href="/page/3/"><i class="material-icons">chevron_right</i></a>
  
  
    <a href="/page/11/"><i class="material-icons">last_page</i></a>
  
</div>


    </main>
    <footer>
      <ul>
       
       <li>
	 <a href="https://github.com/nryotaro"><i class="fab fa-github"></i></a>
       </li>
       
       
       <li>
	 <a href="https://www.linkedin.com/in/nakamura-ryotaro">
	   <i class="fab fa-linkedin"></i>
	 </a>
       
       </li>
	<li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
      </ul>
      <small>&copy; Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>
</html>
