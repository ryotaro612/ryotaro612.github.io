<!DOCTYPE html>
<html>
    <head>
	<meta name="generator" content="Hugo 0.55.6" />
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    
    <title>
      
      Coda
      
		</title>

    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="alternate" type="application/rss&#43;xml" href="https://nryotaro.github.io/index.xml">
    
    <link href="https://fonts.googleapis.com/css?family=M+PLUS+Rounded+1c" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="/assets/css/all.min.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/normalize.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/icons.css" />
    <link rel="stylesheet" type="text/css" href="/assets/css/screen.css" />
    
    <link href="https://fonts.googleapis.com/css?family=Bree+Serif|Lato:100,100i,300,300i,400,400i,700,700i|Source+Code+Pro:300,400,500,700" rel="stylesheet">
    

    
    <script src="https://cdn.jsdelivr.net/npm/jquery@1.12.4/dist/jquery.min.js"></script>
    <script type="text/javascript" src="/assets/bigfoot/dist/bigfoot.js"></script>
    <link rel="stylesheet" type="text/css" href="/assets/bigfoot/dist/bigfoot-number.css" />
    <script type="text/javascript">
        $.bigfoot();
    </script>
    <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
    
    
</head>

    <body class="">
        <header class="main-header">
	<div class="main-header-content">
		<h1 class="blog-title">
			<a href="/">
				
           Coda
				
			</a>
		</h1>
		<h2 class="blog-description"></h2>
	</div>

	<div class="nav">
    
		
	</div>
</header>

        
	<main class="content" role="main">
    
    <div class="extra-pagination">
      

<nav class="pagination" role="navigation">
    
        <a class="newer-posts" href="/">&larr; Newer Posts</a>
    
    <span class="page-number">Page 2 of 3</span>
    
        <a class="older-posts" href="/page/3/">Older Posts &rarr;</a>
    
</nav>

    </div>
		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/google_vizier/">概要 Google Vizier: A Service for Black-Box Optimization</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>表題にあるVizierはGoogleにおいてデファクトになっているブラックボックス最適化のためのサービスであり、
論文は、Vizierのシステムアーキテクチャの構成とアルゴリズムの説明とその評価からなる。</p> &hellip; <a class="read-more" href="/post/google_vizier/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 03, 2019</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/learning_active_learning_from_data/">概要 Learning Active Learning from Data</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>表題にある論文は、次にラベルを与えるべきデータが何かという能動学習における問題を、
あるサンプルを教師データに追加したときの損失関数の減少値を予測する回帰の問題としてとらえる。
能動学習の目的は最小限データで最大の予測性能をもつモデルを構築することであり、次にアノテーションすべきデータが何かを正しく予測することが課題になる。
論文は、アノテーションすべきサンプルを予測する回帰モデルを学習するアルゴリズムを提案、評価する。アルゴリズムは2値分類の分類器を対象としている。</p> &hellip; <a class="read-more" href="/post/learning_active_learning_from_data/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">July 27, 2019</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/textrank/">概要 TextRank: Bringing Order into Texts</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>表題にある論文は、ドキュメントからキーワードとキーセンテンスを抽出するためのグラフベースのアルゴリズムTextRankを提案、評価した。
TextRankは、名前から推測できるようにPageRankを応用した手法であり、頂点の重要度を、頂点の内容のような局所的な情報ではなく、他の頂点との辺の接続関係を含むグラフ全体の大域的な情報から決定する。PageRankとTextRankのアルゴリズムの違いは、TextRankの場合は辺ごとに重みが設定できるところにある。</p> &hellip; <a class="read-more" href="/post/textrank/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">July 20, 2019</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/subword_regularization/">概要 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>表題は、過去に<a href="../neural_machine_translation_of_rate_words/">紹介</a>した<a href="https://www.aclweb.org/anthology/P16-1162">論文</a>と同様、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）の元になった論文にあたる。
ノイズに対する頑強さのために、単語のサブワード（部分文字列）を生成するユニグラム言語モデルの学習方法と、モデルから生成されたサブワード列を入力とする機械翻訳モデルの学習方法を提案した。</p> &hellip; <a class="read-more" href="/post/subword_regularization/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">July 17, 2019</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/neural_machine_translation_of_rate_words/">概要 Neural Machine Trasnslation of Rare Words with Subword Units</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>内容は、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）のトークナイズで使われるアルゴリズムになっている。単語をサブワード（単語の部分文字列）に分割し、サブワードを組み合わせて珍しい単語や未知語を表現することで、これらの出現頻度の低い単語の翻訳上げるというもの。</p> &hellip; <a class="read-more" href="/post/neural_machine_translation_of_rate_words/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">July 13, 2019</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/embedding_logical_queries_on_knowledge_graphs/">メモ Embedding Logical Queries on Knowledge Graphs</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>一階述語論理式で表現されたクエリを満たすノードを、分散表現に変換し、ナレッジグラフの中から計算時間上効率よく見つけるアルゴリズムを提案した。
クエリに現れるエッジの数に対して計算時間が線形であることが特徴。
ただし、クエリには、存在量化と連接を使えるが、全称量化、選択、否定を使うことができない制約がある。</p> &hellip; <a class="read-more" href="/post/embedding_logical_queries_on_knowledge_graphs/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">February 17, 2019</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/universal_language_model_fine_tuning_for_text_classification/">メモ Universal Language Model Fine-tuning for Text Classification</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>UMLFiTという、様々なNLPの問題に適用可能なファインチューニングの手法を提案、評価した。
評価手段として、6種のテキスト分類のタスクにおける既存手法とのエラー率の比較が採られている。
主要な評価として、100件のラベル付きデータだけでその100倍のデータを要した事前学習を用いない手法と同等の予測性能が出たことを報告している。</p> &hellip; <a class="read-more" href="/post/universal_language_model_fine_tuning_for_text_classification/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">September 14, 2018</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/metapath2vec/">メモ metapath2vec: Scalable Representation Learning for Heterogeneous Networks</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <p>異種混合ネットワークから、ノード数x次元数の分散表現を獲得するための手法。
異種混合とは、企業、業界、ニュースなど複数の種類の概念がグラフのノードとして扱われていることを意味する。
獲得した分散表現を訓練データとして分類、クラスタリング、検索に応用し、既存手法と比較している。</p> &hellip; <a class="read-more" href="/post/metapath2vec/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">September 07, 2018</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/applying_deep_learning_to_airbnb_search/">Applying Deep Learning To Airbnb Search</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      <h3 id="概要">概要</h3>

<p>論文では、Airbnbが深層学習を宿泊先検索に適用した時の試行錯誤と結果を紹介している。
採用したモデルのアルゴリズムと特徴量エンジニアリングの説明が本稿の大部分を占める。
深層学習を試す以前はGBDTを採用おり、以下の順にアルゴリズムを変えていった。
当初は、アルゴリズムを段階的に高度にしていくつもりはなく、1.以前には複雑なアルゴリズムをいきなり試したが、失敗に終わっている。</p> &hellip; <a class="read-more" href="/post/applying_deep_learning_to_airbnb_search/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 31, 2018</time>
	</footer>
</article>

		
      <article class="post">
	<header class="post-header">
    
		<h2 class="post-title"><a href="/post/the_relationship_between_precision_recall_and_roc_curve/">メモ The Relationship Between Precision-Recall and ROC Curve</a></h2>
	</header>
	<section class="post-excerpt">
    <p>
      ROCとPrecision Recallの関係を示した論文。
 1 Recallが0でなければ、ROC曲線には一対一に対応するPR曲線がある。 2 PR曲線AがPR曲線Bに対して常に優位であることとは、ROC曲線においてAがBより常に優位であることの必要十分条件。 3 1,2よりROC空間上の凸包に対応するPR曲線は、他の妥当なPR曲線よりも優位な曲線になる。 4 線形補間でROC曲線を描くことは妥当。一方で、Recallの分母は固定値であるが、Precisionの分母の値はRecallが上がると増える。そのため、PR曲線を線形補間でプロットすると、評価の甘い曲線になる。  論文はこちらからダウンロードできます。 &hellip; <a class="read-more" href="/post/the_relationship_between_precision_recall_and_roc_curve/">&raquo;</a>
    </p>
	</section>
	<footer class="post-meta">
    <time class="post-date">August 25, 2018</time>
	</footer>
</article>

		
    

<nav class="pagination" role="navigation">
    
        <a class="newer-posts" href="/">&larr; Newer Posts</a>
    
    <span class="page-number">Page 2 of 3</span>
    
        <a class="older-posts" href="/page/3/">Older Posts &rarr;</a>
    
</nav>

	</main>

        <footer class="site-footer">
  <section class="rss"><a class="subscribe-button icon-feed" href="/index.xml"></a></section>
  
  
  <section>
    <a class="fas fa-rss" href="/index.xml"></a>
    <a class="fab fa-github" href="https://github.com/nryotaro"></a>
    <a class="fab fa-linkedin" href="https://www.linkedin.com/in/nakamura-ryotaro"></a>
  </section>
  <section class="copyright">&copy; 2019 Nakamura, Ryotaro</section>
</footer>



    </body>
</html>
