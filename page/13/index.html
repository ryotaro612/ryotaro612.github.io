<!DOCTYPE html>
<html>

<head>
	<meta name="generator" content="Hugo 0.80.0" />
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-64L0YEFRY5"></script>
    <script>
        if (location.hostname != 'localhost') {
            window.dataLayer = window.dataLayer || [];
            function gtag() { dataLayer.push(arguments); }
            gtag('js', new Date());
            gtag('config', 'G-64L0YEFRY5');
        }
    </script>
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
        integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
        crossorigin="anonymous" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="/css/base.css">
    
    <link rel="stylesheet" href="/css/articles.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://kit.fontawesome.com/4e0e0c0a41.js" crossorigin="anonymous"></script>
    <title>Coda</title>
</head>

<body>
    <header class="navigation">
        <h2><a href="/">Coda</a></h2>
        <nav>
            <ul>
                <li><a href="/about">About me</a></li>
                <li><a href="/posts">Posts</a></li>
                <li><a href="/gallery">Gallery</a></li>
            </ul>
        </nav>
    </header>
    
<main>
    <h1>Posts</h1>

    
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/snorkel_rapid_training_data_creation_with_weak_supervision/">メモ Snorkel: Rapid Traning Data Creation with Weak Supervision</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題の論文は、Weak supervisionの一種であるSnorkelを学習データの収集効率と予測性能についての既存手法や教師あり学習と比べた評価をまとめてる。</p></div>
        <div class="article-footer">
            <span class="date">September 21, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/software_engineering_for_machine_learning/">メモ Software Engineerng for Machine Learning: A Case Study</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題の論文は、マイクロソフトでのAIを応用したアプリケーションの開発についての調査結果をまとている。
著者らは、9人中の8名がMicrosoft Researchに所属し、本論文で2019年のICSEのSoftware Engineering in Practiceの分野でBest Paper Awardを受賞した。
主な貢献は、各チームにおける開発フローを9のステージに分けて解説したこと、機械学習を応用するアプリケーションやプラットフォームの開発におけるベストプラクティスを示したこと、機械学習を応用するアプリケーションの開発に固有の課題にまつわる論考の3つである。</p></div>
        <div class="article-footer">
            <span class="date">September 14, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/class_imbalance_redux/">メモ Class Imbalance, Redux</a></h3>
        <div class="summary"><p>表題の論文は、不均衡データの特徴が二値分類の予測性能に及ぼす影響を理論づける論文である。
理論と実験を通じて、多くのケースにおいて、アンダーサンプリングによる均衡データのバギングで予測性能があがったことを示している。
バギングは、アンダーサンプリングによる偏りを抑えて予測性能を安定させるために使われる。
論文で扱うモデルは、SVMなどの学習で経験損失を最小化するモデルに限定されている。発表学会は2011年のICDMである。</p></div>
        <div class="article-footer">
            <span class="date">September 7, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/learning_on_border/">メモ Learning on the Border: Active Learning in Imbalanced Data Classification</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題にある論文は、不均衡データの二値分類についての予測性能を能動学習で改善する手法を提案している。
着想は、学習器のマージン付近では正例と負例がよりバランスしていると仮定し、
マージン付近にあるデータを集めることで、均衡のとれたデータセットを用意することにある。
具体的には、ラベルづけしたデータでSVMをオンライン学習し、無作為に抽出されたラベルのないデータの中で最も超平面に近いデータにラベルをつける手順をマージンの中にあるデータ数が変わらなくなるまで繰り返す。</p></div>
        <div class="article-footer">
            <span class="date">August 31, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/distilling_the_knowledge_in_a_neural_network/">メモ Distilling the Knowledge in a Neural Network</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題にあるニューラルネットワークの蒸留についての論文を紹介する。
蒸留は、既存のモデルを使い、できるだけ予測性能を落とさずに、より小さいモデルを作るための学習手法である。
既存のモデルとして想定されているのは、複数のモデルからなるモデルや正則化された大きなモデルのように予測性能は高いが計算コストが高いものであり、
蒸留の目的は本番の運用に耐えられるデプロイ可能なモデル作ることにある。
本論文は、出力層の活性化関数に温度つきソフトマックスを使った多クラス分類のモデルを蒸留する手法を提案し、実験により手法を評価している。</p></div>
        <div class="article-footer">
            <span class="date">August 24, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/fastxml/">メモ FastXML: A Fast, Accurate and Stable Tree-classifier for eXtreme Multi-label Learning</a></h3>
        <div class="summary"><p>表題にあるExtreme multi-label classificationの手法を紹介する。
Extreme multi-label classificationの目的は、大量のラベルの候補から与えられたデータに関連する複数のラベルを推定する学習器を構築することにある。
FastXMLは、弱学習器に決定木を使うアンサンブル学習であり、ノードの分割の評価関数にnDCGを採用することで、学習にかかる時間と予測精度の向上を意図している。</p></div>
        <div class="article-footer">
            <span class="date">August 24, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/advantages_and_disadvantages_of_a_monolithic_repository/">メモ Advantages and Disadvantages of a Monolithic Repository</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題は、マルチリポジトリと比べたときのモノリシックリポジトリの長所と短所の調べた論文のタイトルである。
論文は2018年のICSEでGoogleから発表された。
調査方法はGoogle社のエンジニアへのアンケートとエンジニアの行動ログの分析が採用されている。
Googleではモノリシックリポジトリが採用されており、エンジニアがこれまで経験したマルチリポジトリが比較対象となっている。</p></div>
        <div class="article-footer">
            <span class="date">August 17, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/cat_boost/">メモ CatBoost: unbaiased boosting with categorical features</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題はNeurIPS 2018で発表されたCatBoostという勾配ブースティングの手法を論文にちなむ。
Target Statisticsというカテゴリカル特徴量の前処理と勾配ブースティングの学習時に生じる一種のleakageが起きることを示し、leakageをさけて前処理と学習をする手法を示した。
CatBoostは二進木の決定木を弱識別器に用いる。</p></div>
        <div class="article-footer">
            <span class="date">August 10, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/are_we_really_making_much_progress/">メモ Are We Really Making Much Progress? A Worring Analysis of Recent Neural Recomendation Approaches</a></h3>
        <div class="summary"><h3 id="概要">概要</h3>
<p>表題は、ニューラルネットワークを用いた推薦システムを提案、評価した論文における実験の再現性と予測性能の再評価した論文のタイトルにあたる。
発表学会は、2019年のRecSys。著者らは、以下の2つのRQに回答するためにトップ会議で発表された18の論文を調査した。その結果、実験を再現できた論文は7稿であり、その中でも単純な手法を上回る性能が認められたのは1稿だけだった。</p>
<ul>
<li>RQ1: ニューラルネットワークを用いた推薦システムの研究の再現性はどの程度か</li>
<li>RQ2: 最近発表されたアルゴリズムは、ハイパーパラメタチューニングされた単純な手法と比べてどの程度性能がいいか</li>
</ul></div>
        <div class="article-footer">
            <span class="date">August 10, 2019</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/gaussian_processes_for_regression/">メモ Gaussian Processes for Regression</a></h3>
        <div class="summary"><p>表題はガウス過程の回帰問題への応用を提案した論文。著者らは、scikit-learnの<a href="https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process">ガウス過程回帰</a>の
元になっている<a href="http://www.gaussianprocess.org/gpml/chapters/RW.pdf">Gaussian Processes for Machine Learning</a>の著者と同じ。
論文の構成は、ガウス過程回帰の予測分布の式、ハイパーパラメタ推定方法、実験による評価からなる。</p></div>
        <div class="article-footer">
            <span class="date">August 3, 2019</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">
    
    <li>
        <a href="/"><span class="material-icons">first_page</span></a>
    </li>
    <li>
        <a href="/page/12/"><span class="material-icons">chevron_left</span></a>
    </li>
    
    
    <li>
        <a href="/page/14/"><span class="material-icons">chevron_right</span></a>
    </li>
    <li>
        <a href="/page/16/"><span class="material-icons">last_page</span></a>
    </li>
    
</ul>

    <footer>
        <ul>
            
            <li>
                <a href="https://github.com/nryotaro">
                    <i class="fab fa-github"></i>
                </a>
            </li>
            
            
            <li>
                <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
                    <i class="fab fa-linkedin-in"></i>
                </a>
            </li>
            
            <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
            
            <li class="atcoder"><a href="https://kenkoooo.com/atcoder/#/user/nryotaro">AtCoder</a></li>
            
        </ul>
        <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
</body>

</html>