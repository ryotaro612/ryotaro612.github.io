<!DOCTYPE html>
<html lang="ja">

<head>
	<meta name="generator" content="Hugo 0.131.0">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.ja.min.66816a64bc4ce50ec1c4b76199ca9d69163fc8a69f7abc6ea758d1968d8618b0.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/%20about">About</a></li>
        <li><a href="https://ryotaro.dev/%20posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/%20tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/en/">en</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
    <h1>Posts</h1>
    
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/fibonacci_heaps_and_their_uses_in_improving_network_optimization_algorithms/">Fibonacchi Heaps and Their Uses in Improved Network Optimization Algorithms(1987)</a></h3>
        <div class="summary"><p><a href="https://web.eecs.umich.edu/~pettie/matching/Fredman-Tarjan-Fibonacci-Heaps.pdf">Fibonacci heaps</a>(F-heaps)は、ダイクストラアルゴリズムの高速化ために開発された木構造の抽象データ型である。
ノードは、1つの値を保存し、親へのポインタをもつ。
また、2つのポインタによって、同じ階層にある兄弟ノードからなる双方向リストに組み込まれる。
ルート階層にあるノードはいずれも親をもたない。
そのほかにも、削除時に使用されるboolean型の変数がノードごとに1つある。
ヒープにある要素の数\(n\)に対して、要素を償却時間計算量\(O(\log n)\)でき、また、定数の償却時間計算量でほかの主要な操作を行える。</p>
<!-- Fibonacchi heapsは、Vuilleminによる[binomial queues](https://dl.acm.org/doi/pdf/10.1145/359460.359478)を拡張した --></div>
        <div class="article-footer">
	  
          <span class="date">June 24, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/layer_normalization/">Layer Normalization (2016)</a></h3>
        <div class="summary"><p><a href="https://arxiv.org/abs/1607.06450">層正規化</a> (Layer Normalization) はニューラルネットワークのユニットへの入力の重みつきの和を正規化し、学習時間を短縮する。
各層ごとの重みを掛けた入力の総和の平均と標準偏差を求め、この2つの統計量で層の各ユニットの総入力を正規化する
先行研究の<a href="https://arxiv.org/abs/1502.03167">バッチ正規化</a>は、ミニバッチごとに、各ユニットの入力の重みつき和の平均と分散を計算し、ユニットの総入力を正規化する。
バッチ正規化でも学習時間を短縮できるが、その効果はミニバッチのサイズに依存する。また、単純にはRNNに適用できない。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E5%B1%A4%E6%AD%A3%E8%A6%8F%E5%8C%96/">
		#層正規化
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">June 17, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/universal_classes_of_hash_functions/">Universal Classes of Hash Functions(1977)</a></h3>
        <div class="summary"><p>値の保存と参照からなる任意のリクエストの系列を、系列長の時間計算量で処理できるハッシュ関数と連想配列を示す。
求めるハッシュ関数の集合があるとき、各ハッシュ関数の時間計算量の平均がリクエストの系列長に等しくなる。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/hash-function/">
		#Hash Function
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">June 10, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/unsupervised_cross_lingual_representation_learning_at_scale/">Unsupervised Cross-lingual Representation Learning at Scale(2020)</a></h3>
        <div class="summary"><p>多言語モデルを大規模なコーパスで訓練し、含意関係認識、質問応答、固有表現抽出において、多言語版の<a href="https://arxiv.org/abs/1810.04805">BERT</a>を上まわる予測性能を実現した。
モデルのアーキテクチャは<a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>で、<a href="https://arxiv.org/abs/1901.07291">Lample and Conneau, 2019</a>に近い方法でモデルを訓練する。
LampleとConneauの手法を含む従来の多言語の言語モデルの評価実験では、wipediaやwikipediaと同程度の大きさのコーパスが使われていた。
従来の訓練データに対し、100言語からなる2.5TBのCommonCrawlをコーパスに使い、コーパスを大規模化することによるモデルへの影響を分析した。
パラメタ数などのモデル大きさを固定し、言語の種類数を30まで増やしたところ、コーパスの小さい言語の性能が向上したが、それ以上増やすと逆に予測性能が低下した。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E5%A4%9A%E8%A8%80%E8%AA%9E%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#多言語言語モデル
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">June 3, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/a_mojority_consensus_approach_to_concurrency_control_for_multiple_copy_databases/">A Majority Consensus Approach to Concurrency Control for Multiple Copy Databases(1979)</a></h3>
        <div class="summary"><p>データベースを同期するためのアルゴリズム<a href="https://pages.cs.wisc.edu/~remzi/Classes/739/Fall2018/Papers/thomas79-quorums.pdf">majority consensus</a>を提案する。
アプリケーションは任意のデータベースに更新リクエストを送信でき、データベースは更新リクエストの処理について含意をとる。
データベースは、タイムスタンプのついたレコードの集合である。
タイムスタンプは、レコードの値の更新時刻をあらわす。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E5%88%86%E6%95%A3%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0/">
		#分散システム
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">May 27, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/word_translation_without_parallel_data/">WORD TRANSLATION WITHOUT PARALLEL DATA(2018)</a></h3>
        <div class="summary"><p>対訳コーパスを使わずに、ある言語のエンベディングから別の言語のエンベディングへの写像を学習する。
はじめに、敵対的生成ネットワークで写像を学習する。
次に、出現頻度の高い単語について、写像されたエンベディングと目的言語のエンベディングにプロクラステス分析を適用し、より正確な写像関数を求める。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/embedding/">
		#Embedding
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E6%A9%9F%E6%A2%B0%E7%BF%BB%E8%A8%B3/">
		#機械翻訳
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">May 21, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/skip_lists_a_probablistic_alternative_to_balanced_trees/">Skip Lists: A Probabilistic Alternative to Balanced Trees(1990)</a></h3>
        <div class="summary"><p><a href="https://15721.courses.cs.cmu.edu/spring2018/papers/08-oltpindexes1/pugh-skiplists-cacm1990.pdf">Skip Lists</a>は、バランス木の代用になるアルゴリズムである。
Skip listsのノードは、ランダムに選ばれた後続のノードへのポインタをもつ。
ランダムに参照するノードを選ぶことで、バランス木よりも単純なアルゴリズムで、計算量を均衡をでき、さらに最悪計算量をより小さくできる。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E3%83%87%E3%83%BC%E3%82%BF%E6%A7%8B%E9%80%A0/">
		#データ構造
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">May 6, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/an_image_is_worth_16x16_words_transformers_for_image_recognition_at_scale/">AN IMAGE IS WORTH 16x16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE(2021)</a></h3>
        <div class="summary"><p>画像認識に<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Transformer</a>を使う手法を提案し、<a href="https://arxiv.org/abs/1912.11370">Big Transfer</a>と<a href="https://arxiv.org/abs/1911.04252">Noisy Student</a>と比較した。
論文が発表された2021年でも、画像認識にニューラルネットワークを使う場合、畳込みニューラルネット(CNN)が基本の選択肢になる。
自己注意機構を使った画像処理の<a href="https://arxiv.org/abs/2003.07853">先行研究</a>はあるが、スケールするアーキテクチャではない。</p>
<p>AN IMAGE IS WORTH 16x16 WORDSは、分割した画像をトークン（単語）のようにTransformerへ入力することで、Transformerを画像認識へ応用できるこを示した。
TransformerはCNNのように画像の向きや局所性を帰納バイアスにもたず、データが不十分でないと汎化性能は低い。
しかし、学習データを14M-300Mまで増やすと、CNNを越える汎化性能を発揮した。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E7%94%BB%E5%83%8F%E8%AA%8D%E8%AD%98/">
		#画像認識
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 29, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/virtual_time_and_global_states_of_distributed_systems/">Virtual Time and Global States of Distributed Systems(1988)</a></h3>
        <div class="summary"><p>分散システムのプロセス間で時刻が常に同期しているとは限らない。
プロセスの時刻から判断すると、プロセスでは、ほかのプロセスのイベントと比べてどちらが先に起きたか分からないイベントが起きえる。
<a href="https://lamport.azurewebsites.net/pubs/time-clocks.pdf">Lamport</a>は、各プロセスに単調増加する論理的な時刻をもたせ、メッセージとともに時刻をプロセス間で交換することで、イベントの依存関係と矛盾せずにイベントを全順序に並べる手法を提案した。
先行するイベントは、必ず後続のイベントよりも小さい時刻をもつ。
しかし、逆は必ずしも成り立たない。
先行する場合もあれば、前後関係がないこともある。
<a href="http://www.vs.inf.ethz.ch/publ/papers/VirtTimeGlobStates.pdf">Virtual Time and Global States of Distributed Systems</a>は、各プロセスの時刻を、プロセス数とおなじ数の長さの配列で表現する。
これにより、時刻の前後関係が定義されていることがイベント間に前後関係があることの必要十分条件であることを可能にした。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E5%88%86%E6%95%A3%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0/">
		#分散システム
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 22, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/posts/generating_long_sequences_with_sparse_transformers/">Generating Long Sequences with Sparse Transformers(2019)</a></h3>
        <div class="summary"><p><a href="https://arxiv.org/abs/1706.03762">Transformer</a>のQKV注意機構に入力するベクトルを限定し、長さ\(n\)の系列をQKV注意機構に入力したときの空間計算量を\(\mathcal{O}(n\sqrt{n})\)まで減らした<a href="https://arxiv.org/abs/1904.10509">研究</a>である。
Transformerであれば、系列の要素は、要素自体の位置と以前の要素すべてを注意し、時間と空間計算量は\(\mathcal{O}(n^2)\)になる。
Sparse Transformerは、\(p\)個のパターンを用意し、パターンに該当する要素のみを各注意機構に入力し、\(p\)個の注意を生成する。
そして、\(p\)個の注意を合成し、1つの注意に変換する。
パターンは、画像やテキストなど、入力するデータの種類によって決めておく規則であり、たとえば、直近にある一定数の要素や等間隔に離れた要素を指定するパターンがありえある。
パターンが\(p\)であれば、計算量は\(\mathcal{O}\sqrt[p]{n}\)になる。実験の設定は\(p=2\)である。</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB/">
		#言語モデル
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">April 15, 2023</span>
        </div>
    </article>
    
</main>

  

<ul class="pagination">  
    
    <li>
      <a href="/">
	<i class="fa-solid fa-xl fa-angles-left"></i>
      </a>
    </li>
    <li>
      <a href="/page/5/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/page/7/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    <li>
      <a href="/page/33/">
	<i class="fa-solid fa-xl fa-angles-right"></i>
      </a>
    </li>
    
</ul>

  <footer>
    <small>© Ryotaro. All Rights Reserved.</small>
  </footer>
</body>


</html>
