<!DOCTYPE html>
<html>
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=38897&amp;path=livereload" data-no-instant defer></script>
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="http://localhost:38897/scss/base.min.87b8f4076c47000c129b0c8b240a71216448e3aedd7144174c55776680a783b0.css">
    
    <link rel="stylesheet" href="http://localhost:38897/scss/base.ja.min.66816a64bc4ce50ec1c4b76199ca9d69163fc8a69f7abc6ea758d1968d8618b0.css">
    

<link rel="stylesheet" href="http://localhost:38897/scss/single.min.6706f2a051a6ab63f5377cb6e9a19e35f0265340ff70caf700b282f1962c59e1.css">

<link rel="stylesheet" href="http://localhost:38897/scss/posts/single.min.c8bed992e3e72febf0bd227ae4d39d51e4a5a169e0a19ca4cef950e3ab79cfe0.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    <title>メモ ActiveClean: Interactive Data Cleaning For Statistical Modeling(2016)</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="http://localhost:38897/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="http://localhost:38897/about">About</a></li>
          <li><a href="http://localhost:38897/posts">Posts</a></li>
          <li><a href="http://localhost:38897/tags">Tags</a></li>
	  
        </ul>
      </nav>
    </header>
    
<main>
  <h1>メモ ActiveClean: Interactive Data Cleaning For Statistical Modeling(2016)</h1>
  <ul class="tags">
    
    <li class="tag">
      <a href="http://localhost:38897/tags/weak-supervision/">
	#Weak Supervision
      </a>
    </li>
    
  </ul>  
  <span class="date">November 9, 2019</span>    
  <div>
    <p>ActiveCleanは、教師データの誤りを修正し、モデルの精度を改善する手法である。
優先して修正すべきデータを推定し、データが修正されたら修正されたデータでモデルを学習する。
この修正と学習を条件を満たすまでくりかえす。
反復的な学習で大域的最適解をえられるモデルであれば、最適解への収束が保証される。
データの修正件数が等しい場合に、先行研究と比べて最大2.5倍の精度改善を達成した。</p>
<p>ActiveCleanの全体像を以下の図に示す。外側の実線がActiveCleanの範囲であり、六角形はモデルを示す。
<img alt="Architecture" src="/active_clean/architecture.png">
Samplerは汚れのあるデータを推定する。Cleanerはデータの修復を示す。Updaterは汚れのないデータでモデルのパラメタを更新する。</p>
<p>大域的最適解への収束と汚れたデータの推定の最適化は、SGDの性質によって、担保される。
通常のSGDによる学習との違いは、汚れのある教師データで、汚れのないデータで求まる損失関数\(\phi\)の勾配を推定することである。
以下の図はパラメタの更新の様子を表す。縦軸と横軸は、それぞれ損失関数とパラメタの値に対応する。
赤線と青線は損失関数のグラフであり、両者はデータの汚れの有無がことなる。
<img alt="fig3" src="/active_clean/fig3.png">
左図のように、汚れのあるデータで求める最適なパラメタは、汚れのないデータのそれとは異なる。
そこで、これまでにえられた汚れのないデータで、全ての教師データが汚れていない場合の損失関数の勾配を推定する。
パラメタを\(\theta\)とすると、勾配の推定値は\(g(\theta)\)である。</p>
<p>$$
g (\theta) = \frac{\mid R_\mathcal{clean}\mid}{\mid R\mid}\cdot g_{C}(\theta)+\frac{\mid R_\mathcal{dirty}\mid}{\mid R\mid}\cdot g_S(\theta)
$$</p>
<p>$$
g_C (\theta) = \frac{1}{\mid R_\mathcal{clean}\mid}\sum_{i\in R_\mathcal{clean}} \nabla\phi(x_i^{( c )}, y_i^{( c )}, \theta)
$$</p>
<p>$$
g_S (\theta) = \frac{1}{\mid S\mid}\sum_{i\in S}\frac{1}{p(i)}\nabla\phi(x_i^{( c )}, y_i^{( c )}, \theta)
$$</p>
<p>\((x_i^{( c )}, y_i^{( c )})\)は修正後のデータとラベルの組、
\(R\)は\(x\)のと1対1の関係にあるレコード\(r\)の集合であり、修正とはレコード\(r\)をレコード\(r&rsquo;\)ないしは\(\emptyset\)に変換する操作をいう。
\(R_\mathcal{clean}\)は修正後のレコードの集合, \(R_\mathcal{dirty}\)は確率\(p\)で推定されていないレコードの集合を示す。
\(S\)はバッチを示す。
\(t\)回目の学習では、求めた推定値で学習率\(\gamma\)でパラメタを更新する。
$$
\theta^{(t+1)} \leftarrow \theta^{(t)} - \gamma\cdot g(\theta^{(t)})
$$</p>
<p>勾配を推定するために、汚れのあるレコードの推定方法\(p(i)\)を定める。
バッチサイズと反復回数が定数の場合、\(g^*\)を汚れのない教師データで計算した勾配と仮定すると、収束率の上界は\(\mathcal{O}(\sigma^2)\)である。ただし、\(\sigma^2\)を</p>
<p>$$
\sigma^{2} = \mathbb{E}(\mid\mid g- g^{*}\mid\mid^{2})
$$</p>
<p>とする。そこで</p>
<p>$$
\underset{p}{\operatorname{argmin}}\ \mathbb{E}(\mid\mid g_S - g^* \mid\mid^{2})
$$
が成り立つように\(p\)を定める。
<a href="http://tongzhang-ml.org/papers/icml15-sois.pdf">[1]</a>より
\(p_i \propto\mid\mid\nabla\phi(x_i^{( c )}, y_i^{( c )}, \theta^{(t)})\mid\mid\)であり、
また、学習と同様に、汚れのないデータを推定する方針で\(p\)を、</p>
<p>$$
\begin{aligned}
\nabla\phi(x_i^{( c )}, y_i^{( c )}, \theta^{(t)}) &amp;\approx \nabla\phi(x_i^{(d)}, y_i^{(d)}, \theta^{(t)})\\\
&amp; + \frac{\partial}{\partial X}\nabla\phi(x_i^{(d)}, y_i^{(d)}, \theta^{(t)})\cdot (x^{(d)} - x^{( c)}) \\\
&amp; + \frac{\partial}{\partial Y}\nabla\phi(x_i^{(d)}, y_i^{(d)}, \theta^{(t)})\cdot (x^{(d)} - x^{( c)})
\end{aligned}
$$
と近似する。\( (x_i^{(d)}, y_i^{(d)}) \)は修正前のデータを示す。</p>
<p>論文では、大域的最適解が保証されるモデルはconvex loss modelsとよばれている。
SVMや線形回帰、ロジスティック回帰などがconvex loss modelsにあたる。
Convex loss modelsでない場合、初期状態のデータで学習したパラメタに最も近い局所最適解に収束するので、ActiveCleanでえられる精度はモデルの初期状態に依存する。</p>
<hr>
<p>論文は<a href="http://www.vldb.org/pvldb/vol9/p948-krishnan.pdf">こちら</a>からダウンロードできます。
文章にある論文はすべて論文から引用されています。</p>
  </div>
</main>

    
<ul class="pagination">
    
    <li>
      <a href="/posts/web_tables/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/posts/get_another_label/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    
</ul>


    <footer>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        <li><a href="http://localhost:38897/index.xml"><i class="fas fa-rss"></i></a></li>
        
      </ul>
      <small>© Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
