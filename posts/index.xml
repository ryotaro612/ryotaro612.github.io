<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Coda</title>
    <link>https://nryotaro.dev/posts/</link>
    <description>Recent content on Coda</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Fri, 20 Nov 2020 18:55:51 +0900</lastBuildDate>
    
	<atom:link href="https://nryotaro.dev/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>論文メモ On Designing and Deploying Internet-Scale Services</title>
      <link>https://nryotaro.dev/posts/on_designing_and_deploying_internet-scale_services/</link>
      <pubDate>Fri, 20 Nov 2020 18:55:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/on_designing_and_deploying_internet-scale_services/</guid>
      <description>&lt;p&gt;MSNとWindows Liveで培われたシステム管理者による運用負担を減らすためのベストプラクティス集。
07年に発表された。
プラクティス集は、10のグループに分かれ、それぞれ複数のアドバイスからなる。
特徴的な内容に絞って以下に要約する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Weighted Voting for Replicated Data</title>
      <link>https://nryotaro.dev/posts/weighted_voting_for_replicated_data/</link>
      <pubDate>Thu, 19 Nov 2020 21:21:33 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/weighted_voting_for_replicated_data/</guid>
      <description>&lt;p&gt;1979年に発表されたレプリケーション管理のクオーラムモデルのアルゴリズムの論文で、以前紹介したように&lt;a href=&#34;https://awsmedia.awsstatic-china.com/blog/2017/aurora-design-considerations-paper.pdf&#34;&gt;Amazon Aurora&lt;/a&gt;や&lt;a href=&#34;https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&#34;&gt;Dynamo&lt;/a&gt;で採用されている。
ファイルの読み込みや書き込みのトランザクションは、複製されたファイルのもつ票を集め、所定の数、クオーラムを越えたときのみ実行される。
これにより、読み込み、書き込みの線形の一貫性が保証され、実行中のトランザクションが高々一つであるかのように見せかけられる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases</title>
      <link>https://nryotaro.dev/posts/amazon_aurora/</link>
      <pubDate>Fri, 13 Nov 2020 17:51:53 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/amazon_aurora/</guid>
      <description>&lt;p&gt;AWSで提供されるRDBM, Amazon Auroraのアーキテクチャを解説した論文。
分散システムをクラウドにおく場合、計算やIOはノードに分散され、ボトルネックではなくなる。
そして、ボトルネックは、DBインスタンスとストレージ間のネットワークになる。
この仮説もと、プライマリインスタンスが、別テナントのストレージに直接Redoログを送ることで、レプリカインスタンスとストレージ間の負荷を減らし、処理性能の向上をはかる。
また、レプリケーションのために、MySQLがRedoログだけでなくバイナリログなど複数種類のログをスレーブに送るのに対し、AuroraはRedoログだけを転送する。
これにより、リカバリや縮退、フェールオーバの性能も向上している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ &#34;One Size Fits All&#34;: An Idea Whose Time Has Come and Gone</title>
      <link>https://nryotaro.dev/posts/one_size_fit_all/</link>
      <pubDate>Fri, 13 Nov 2020 16:05:23 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/one_size_fit_all/</guid>
      <description>&lt;p&gt;2011年に発表された論文で、これまでのようにDBMSを様々なデータ中心のアプリケーションに利用することがデータベース市場で受け入れられなくなったと主張する。
データウェアハウスとストリーミング処理を例にとり、これらに特化したデータベースをDBMSで代用することの限界が説明されている。
表題の&amp;rdquo;One Size Fits All&amp;rdquo;はフリーサイズ、転じて、万能、汎用的を意味する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Dynamo: Amazon&#39;s Highly Available Key-value Store</title>
      <link>https://nryotaro.dev/posts/dynamo_amazons_highly_available_key_value_store/</link>
      <pubDate>Fri, 06 Nov 2020 17:06:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/dynamo_amazons_highly_available_key_value_store/</guid>
      <description>&lt;p&gt;Amazonで社内運用されている高可用性のKVS, Dynamoのアーキテクチャを解説している。
まぎらわしいが、Dynamoは、AWSサービスのDynamo DBとは違う&lt;a href=&#34;https://www.oreilly.co.jp/books/9784873118703/&#34;&gt;*&lt;/a&gt;。
Dynamoは、リーダーレスレプリケーションモデルで、Dynamo DBはシングルリーダレプリケーションモデルを採用している。
Dynamoは、高信頼性が必要なシステムの状態管理に使用される。
その用途から、トランザクション分離レベルのサポートは不要で、可用性を優先するために結果整合性を許容する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Zero-shot Word Sense Disambiguation using Sense Definition Embeddings</title>
      <link>https://nryotaro.dev/posts/zero_shot_word_sense_disambiguation_using_sense_definition_embeddings/</link>
      <pubDate>Fri, 30 Oct 2020 18:58:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/zero_shot_word_sense_disambiguation_using_sense_definition_embeddings/</guid>
      <description>&lt;p&gt;語義曖昧性解消のためのアーキテクチャ, Extended WSD Incorporating Sense Embeddings(EWISE)を発表した。
EWISEは単語の意味をアノテーションしあテキストと辞書を教師データにもちいる。
実験では、辞書にWordNetをつかい、概念同士の上下関係や関係を示す分散表現を獲得する。
学習であたえられていない意味を推定するために、離散値ではなく分散表現でラベルの意味を表現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Simple Testing Can Prevent Most Critical Failures</title>
      <link>https://nryotaro.dev/posts/simple_testing_can_prevent_most_critical_failures/</link>
      <pubDate>Thu, 29 Oct 2020 20:53:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/simple_testing_can_prevent_most_critical_failures/</guid>
      <description>&lt;p&gt;5つの分散システムのバグのうち198件を無作為に抽出、調査したところ、エラーハンドリングに対する単純なテストが有効であることが分かった。
198件のうちの48件は、論文でcatastrophic failuresと形容された、多くのユーザに影響を与える障害が占めた。
調査対象は、Cassandra, HBase, HDFS, Hadoop MapReduce, Redisの5つである。
catastrophic failuresの35%の原因は、エラーハンドラがログの出力だけしかしていない、過剰に上位の例外クラスが宣言されたcatch構文で例外を処理していること、例外に&lt;code&gt;FIXME&lt;/code&gt;, &lt;code&gt;TODO&lt;/code&gt;コメントがある、の3パターンに分類された。
Javaのバイトコードから以上の3パターンを検出するツールを実装し、9種類の分散システムに適用したことで、121件の未知のバグを特定することができた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ From Diversity by Numbers to Diversity as Process</title>
      <link>https://nryotaro.dev/posts/from_diversity_by_numbers_to_diversity_as_process/</link>
      <pubDate>Fri, 16 Oct 2020 23:58:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/from_diversity_by_numbers_to_diversity_as_process/</guid>
      <description>開発におけるブレーンストーミングが、マイノリティに属する開発者の満足度の向上に貢献することを実験的に示した。 ここでの開発は、ハッカソンのような短時間かつ集中が求められるものが想定されている。 満足度は、開発プロセスと成果物に対するもので分けて扱われ、どちらの観点でもブレーンストーミングは満足度に対してよい効果をもたらした。
 論文をこちらからダウンロードできます。  </description>
    </item>
    
    <item>
      <title>論文メモ End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF</title>
      <link>https://nryotaro.dev/posts/end_to_end_sequence_labeling_via_bi_directional_lstm_cnns_crf/</link>
      <pubDate>Fri, 16 Oct 2020 22:17:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_sequence_labeling_via_bi_directional_lstm_cnns_crf/</guid>
      <description>&lt;p&gt;タスク固有の特徴を使わないEnd to Endの系列ラベリングのためのネットワークアーキテクチャを発表した。
実験では、Penn Treebank WSJの品詞タグ付けで97.55%のaccuracy, CoNLL 2003の固有表現抽出で91.21%のF1値を発揮し、発表当時の先行研究を上まわる性能を示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Becoming Agile: A Grounded Theory of Agile Transitions in Practice</title>
      <link>https://nryotaro.dev/posts/becoming_agile/</link>
      <pubDate>Fri, 16 Oct 2020 17:34:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/becoming_agile/</guid>
      <description>&lt;p&gt;アジャイル開発に熟練する過程でチームに生じる変化をグラウンデッドセオリーで調査した。
調査のために、ニュージーランド、オーストラリア、アメリカ、インド、ポルトガルの5カ国から18のチームを選び、その中の31名に半構造化された約1時間の面接を実施した。
面接では、職歴、自己組織化の実践、仕事のわりあて方の3つを話してもらった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Software Development Waste</title>
      <link>https://nryotaro.dev/posts/software_development_waste/</link>
      <pubDate>Sun, 11 Oct 2020 15:02:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/software_development_waste/</guid>
      <description>&lt;p&gt;Pivotal Labs(Pivoital社の一部門、PivotalはSpring Frameworkを開発している会社。昨年VM Wareに買収された？)における8プロジェクトを、グラウンデットセオリーにしたがって参与観察し、ソフトウェア開発においる無駄を特定し、無駄を9つの区分に分類した。
論文では、無駄は「リソースを使っのに顧客にとっての価値を生みださなかった活動」と定義されている。
調査期間は2年5ヶ月で、調査結果は、ソフトウェア開発者、インタラクションデザイナ、プロダクトマネジャーからなる33名のステークホルダに面接した結果もふまえてある。
分類のほかに、無駄を生みだす二項対立や原因にも言及されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ End-to-end Neural Coreference Resolution</title>
      <link>https://nryotaro.dev/posts/end_to_end_neural_coreference_resolution/</link>
      <pubDate>Sat, 10 Oct 2020 00:12:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_neural_coreference_resolution/</guid>
      <description>&lt;p&gt;ニューラルネットワークによる共参照解析の手法で、End-to-Endとあるように、構文解析やルールベースの参照表現に頼らず、先行研究を上回る性能を発揮した。
文書中の全ての単語系列を参照表現の候補とみなし、ある単語系列の組が照応関係にある確率の分布を学習する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Build it yourself! Homegrown Tools in a Large Software Company</title>
      <link>https://nryotaro.dev/posts/build_it_yourself/</link>
      <pubDate>Fri, 02 Oct 2020 20:22:20 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/build_it_yourself/</guid>
      <description>&lt;p&gt;マイクロソフトにおいて、誰が(RQ1)、どんな(RQ2)自作ツールを、どのような動機(RQ3)で、いつ(RQ3)開発し、どのように普及するのか(RQ4)を調査した。
調査結果では、大多数の開発者はツールを自作し、そのほとんどは所属するチームの外までは普及せす、ツールの使用者と共同開発者は一人以上いることが多かった。
受容的な組織文化はツールの自作を促進し、また、自作ツールは組織に大きな影響をあたえる可能性があることを示唆している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Universal Sentence Encoder</title>
      <link>https://nryotaro.dev/posts/universal_sentence_encoder/</link>
      <pubDate>Fri, 02 Oct 2020 18:20:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/universal_sentence_encoder/</guid>
      <description>&lt;p&gt;転移学習のための文の分散表現を獲得するモデルを提案した。
提案されたモデルは2つで、両者には精度と計算量の間にトレードオフがある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ How much Up-Front? A Grounded Theory of Agile Architecture</title>
      <link>https://nryotaro.dev/posts/how_much_up-front/</link>
      <pubDate>Fri, 25 Sep 2020 20:40:50 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/how_much_up-front/</guid>
      <description>&lt;p&gt;「アジャイル開発において、実装前のアーキテクチャ設計にどれだけ工数を割くべきか？」という問いの回答指針を、44名のソフトウェア開発者に面接し、その結果からグラウンデッド・セオリーで提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Character-level Convolutional Networks for Text Classification</title>
      <link>https://nryotaro.dev/posts/character_level_convolutional_networks_for_text_classification/</link>
      <pubDate>Fri, 25 Sep 2020 18:10:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/character_level_convolutional_networks_for_text_classification/</guid>
      <description>&lt;p&gt;文字単位のCNNによる文書の分類を、ほかのモデルと比較して評価した。
先行研究より、CNNを訓練するときは大量の教師データが必要になると分かっている。
のため、比較のためのデータセットは大きく、訓練データの事例数は最低でも12万件におよぶ。
文字単位のCNNに大量の訓練データをあたえれば、別途単語の意味をモデルにあたえずとも性能を発揮することを示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ What Makes A Great Software Engineer?</title>
      <link>https://nryotaro.dev/posts/what_makes_a_great_software_engineer/</link>
      <pubDate>Fri, 18 Sep 2020 20:19:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/what_makes_a_great_software_engineer/</guid>
      <description>&lt;p&gt;優れたエンジニアの特徴を知るために、マイクロソフト社のアーキテクト59名と半構造化された面接をし、グラウンデッドセオリーで内容から特徴を抽出した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</title>
      <link>https://nryotaro.dev/posts/maml/</link>
      <pubDate>Fri, 18 Sep 2020 17:54:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/maml/</guid>
      <description>&lt;p&gt;表題の略称MAMLで知られるメタ学習であり、少ない教師データで新しいタスクに対応することを目的としている。
Model-Agnosticとあるように、MAMLの汎用性は高く、勾配法をもちいるモデルであえば適用可能である。
論文には、教師あり学習だけでなく強化学習の事例もある。
さまざまなタスクに適した初期パラメタを見つけ、データ件数の削減をねらう。
目的のパラメタを求めるためには、複数のタスクを用意し、これらの損失関数の合計値を最小にするように勾配法でパラメタの更新を繰り返す。
最後に更新されたパラメタをモデルの初期値に設定する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Truth in Advertising: The Hidden Cost of Mobile Ads for Software Developers</title>
      <link>https://nryotaro.dev/posts/truth_in_advertising/</link>
      <pubDate>Fri, 11 Sep 2020 20:01:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/truth_in_advertising/</guid>
      <description>&lt;p&gt;モバイルアプリを無料で提供し、アプリ内の広告で収益をえるビジネスが普及している。
このビジネスモデルでは、一見、ユーザには、画面に広告を表示されること以外のコストがないように思える。
表題の論文は、それ以外のコストを確かめるために、CPU, 電力, ネットワーク, 広告関連のためのリリース, アプリケーションへのユーザからの評価へ広告が及ぼす影響を調査した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Skip-Thought Vectors</title>
      <link>https://nryotaro.dev/posts/skip_thought_vectors/</link>
      <pubDate>Fri, 11 Sep 2020 16:09:15 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/skip_thought_vectors/</guid>
      <description>&lt;p&gt;様々なタスクで性能を発揮できる文の分散表現を生成するモデルSkip-Thougtを提案した。
表題のSkip-Tought Vectorsは、Skip-Toughtで生成されるベクトルである。
Skip-Thoughtは、文書を入力とする教師なし学習であり、与えられた文から隣接する左右の文を推定できるようにパラメタを学習する。
学習後は、語彙を増やすために、Word2Vecの単語のベクトルからSkip-Toughtのベクトルを推定するための正則化なしの回帰モデルを学習させる。
学習データにない単語のベクトルを回帰モデルの推定結果で代用し、未知の単語を含む文の分散表現もつくれるようにする。
Skip-Toughtを8タスクに適用し、汎用性を確かめた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Beyond Accuracy: Behavioral Testing of NLP Models with CHECKLIST</title>
      <link>https://nryotaro.dev/posts/beyond_accuracy/</link>
      <pubDate>Fri, 04 Sep 2020 21:54:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/beyond_accuracy/</guid>
      <description>&lt;p&gt;ホールドアウト法にかわる自然言語処理モデルの汎化性能を評価するための手法CHECKLISTを提案した。
テストデータと訓練データが同じ方法で集められたときなど、ホールドアウト法はモデルを過大評価することがある。
CHECKLISTは、ソフトウェア開発のブラックボックステストにならい、半自動生成したテストデータで汎化性能を評価する。
CHECKLISTの汎用性と性能を評価するために、感情分析、Quoraの重複質問検出、読解の3タスクについて、商用やSoTAに近いモデルを学習させ、CHECKLISTでモデルがあつかえない入力パターンをどれだけ生成できるか実験した。
感情分析の評価には、Microsoft, Google, AmazonのAPIとBERT, RoBERTaを使い、重複検出にはBERTとRoBERTa, 読解にはBERTを使用した。
CHECKLISTはOSSとして&lt;a href=&#34;https://github.com/marcotcr/checklist&#34;&gt;公開&lt;/a&gt;されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Why Good Developers Write Bad Code: An Observational Case Study of the Impacts of Organizational Factors on Software Quality</title>
      <link>https://nryotaro.dev/posts/why_good_developers_write_bad_code/</link>
      <pubDate>Fri, 04 Sep 2020 20:54:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/why_good_developers_write_bad_code/</guid>
      <description>&lt;p&gt;創立40年以上の電気通信系企業における内製システムのリプレースプロジェクトを観察し、コードに悪影響をおよぼす10の組織的な要因をまとめた。
表題には、&amp;rdquo;Good Developers&amp;rdquo;とあるが、開発者のスキルの高さは議論されていない。
列挙された要因は、包括的ではなく、また、あくまでコードの品質を悪化させるものであり、プロジェクトの失敗に直結するわけではない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Comparative Study of Programming Lanugages in Rosetta Code</title>
      <link>https://nryotaro.dev/posts/a_comparative_study_of_programming_languages_in_rosetta_code/</link>
      <pubDate>Fri, 28 Aug 2020 20:19:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_comparative_study_of_programming_languages_in_rosetta_code/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://rosettacode.org/wiki/Rosetta_Code&#34;&gt;Rosetta Code&lt;/a&gt;に投稿された実装で言語の性能を比較した。
比較した言語は、Ruby, F#, Java, C#, Go, C, Python, Haskellの8つである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ SQuAD: 100,000&#43; Questions for Machine Comprehension of Text</title>
      <link>https://nryotaro.dev/posts/squad/</link>
      <pubDate>Fri, 28 Aug 2020 19:36:42 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/squad/</guid>
      <description>&lt;p&gt;読解タスクのテストデータセットSQuADをつくり、ロジスティック回帰で難易度を評価した。
難易度は、ベースラインのF1スコアが20%, 強いモデルで51.0%, 人間で86.8%程度である。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Extensible Effects An Alternative to Monad Transformers</title>
      <link>https://nryotaro.dev/posts/extensible_effects/</link>
      <pubDate>Sun, 23 Aug 2020 13:34:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/extensible_effects/</guid>
      <description>&lt;p&gt;モナド変換子にかわるモナドの合成方法Extensible Effectsの実装を示す。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ When and Why Your Code Starts to Smell Bad</title>
      <link>https://nryotaro.dev/posts/when_and_why_your_code_starts_to_smell_bad/</link>
      <pubDate>Fri, 21 Aug 2020 18:03:14 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/when_and_why_your_code_starts_to_smell_bad/</guid>
      <description>&lt;p&gt;200件のAndroid, Apache, EclipseのOSSプロジェクトのコミット履歴を調査し、不吉な匂いが生じる原因と理由を調査した。
常識では、改修の繰返しによって匂いのない既存のコードに匂いが生じると考えられているが、これに反して、不吉な匂いのするコードのほとんどが作成時点で不吉な匂いを出していたことを明らかにした。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Extracting and Composing Robust Features with Denoising Autoencoders</title>
      <link>https://nryotaro.dev/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/</link>
      <pubDate>Fri, 21 Aug 2020 17:04:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/extracting_and_composing_robust_features_with_denoising_autoencoders/</guid>
      <description>&lt;p&gt;ノイズを含む入力からノイズのない入力を復元するように学習すると、次元圧縮の性能を向上できることを示した。
層の深いautoencoderを学習するには、良い初期値を与えなければらないことが知られていた。
&lt;a href=&#34;https://www.cs.toronto.edu/~hinton/science.pdf&#34;&gt;先行研究&lt;/a&gt;は、各中間層を個別に学習することで、良い初期値を求められることを示した。
具体的には、各中間層について、前の層の入力から次の層の出力を推定できるよう個別に学習させる。
一方で、何が良い初期値をなすのかは知られていなかった。
表題の論文は、その条件は入力に含まれるノイズに対して頑強であると仮説をおき、ノイズを除去できるように目的関数を設定することで、次元圧縮の性能が上がることを示し、仮説の正しさを確かめた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Statistical Errors in Software Engineering Experiments: A Preliminary Literature Review</title>
      <link>https://nryotaro.dev/posts/statistical_errors_in_software_engineering_experiments/</link>
      <pubDate>Fri, 14 Aug 2020 18:39:35 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/statistical_errors_in_software_engineering_experiments/</guid>
      <description>&lt;p&gt;ソフトウェア工学の実験において、統計をもちいた手法がどれだけ誤用されているかを調査した。
薬学や心理学の実験では、統計による手法が時に誤って使われていることが知られている。
一方で、ソフトウェア工学では、どの程度誤用がみられるのかは分かっていない。
著者らは、2006から2015年のソフトウェア工学のトップ会議ICSEで発表された論文770件から、実験や評価に統計的手法をもちいたものを選び、10の観点からなる判断基準で、手法の妥当性を評価した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Semi Supervised Learning with Ladder Networks</title>
      <link>https://nryotaro.dev/posts/semi-supervised_learning_with_ladder_networks/</link>
      <pubDate>Fri, 14 Aug 2020 17:01:02 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/semi-supervised_learning_with_ladder_networks/</guid>
      <description>&lt;p&gt;Ladder Networkを半教師あり学習に応用する。
Ladder Networkは、2015年に、著者の一人Valpolaによって教師なし学習のためのネットワークとして発表されている&lt;a href=&#34;https://arxiv.org/abs/1411.7783&#34;&gt;*&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ An Empirical Study On Program Failures On Deep Learning Jobs</title>
      <link>https://nryotaro.dev/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/</link>
      <pubDate>Fri, 07 Aug 2020 18:50:12 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/an_empirical_study_on_program_failures_on_deep_learning_jobs/</guid>
      <description>&lt;p&gt;Microsoftの社内では深層学習のプラットフォームPhillyが運用されており、そこで起きた4960件のジョブの失敗原因を調査した。
調査では、失敗の原因を20のカテゴリに分類し、カテゴリごとに失敗の件数を集計した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Improving Language Understanding by Generative Pre-Training</title>
      <link>https://nryotaro.dev/posts/improving_language_understanding_by_generative_pre_training/</link>
      <pubDate>Fri, 07 Aug 2020 16:45:55 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/improving_language_understanding_by_generative_pre_training/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;GPTの略称で知られる教師なしの事前学習である。
評価実験では、12の自然言語処理タスクのうち9つで、当時のSoTAを上まわる性能を発揮した。
ネットワークはTransformerであり、事前学習では言語モデルを学習する。
手法の独自性は、ファインチューニングでの入力データの作り方にある。
入力形式を工夫し、事前学習時のネットワーク構成を維持することで、効率的な転移学習を実現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Tale from the Trenches: Cognitive Biases and Software Development</title>
      <link>https://nryotaro.dev/posts/a_tale_from_the_trenches/</link>
      <pubDate>Fri, 31 Jul 2020 18:55:54 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_tale_from_the_trenches/</guid>
      <description>&lt;p&gt;エンジニア10人の普段の開発状況から、認知バイアスが開発者にあたえる影響やバイアスの頻度、対策方法について調査した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Factorization Machines</title>
      <link>https://nryotaro.dev/posts/factorization_machines/</link>
      <pubDate>Fri, 31 Jul 2020 16:50:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/factorization_machines/</guid>
      <description>&lt;p&gt;Factorization Machineは、Matrix factorizationのようなFactorization modelとSVMの両方の利点をもつ。
Matrix modelには疎な特徴を入力することができるが、予測のモデルに使うには汎用性に欠ける。
一方、SVMは、汎用的であるが、推薦システムで使われるような疎な特徴を扱うことができない。
Factorizatiom Machineは、両者の利点をそなえており、疎な任意の実数を要素にもつ特徴ベクトルを扱うことができる。
また、予測の計算量が線形であり、必要なパラメタの数も線形であるため、SVMのサポートベクタのように訓練データをモデルに持たせる必要がない。
そのために、大量の訓練データを使う学習も可能となる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exploration of Technical Debt in Start-ups</title>
      <link>https://nryotaro.dev/posts/exploration_of_technical_debt_in_start_ups/</link>
      <pubDate>Fri, 24 Jul 2020 15:26:42 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/exploration_of_technical_debt_in_start_ups/</guid>
      <description>&lt;p&gt;スタートアップ86社を調査し、スタートアップにおける技術的負債を招く要因(precedents)、負債を抱える側面(dimentions)、その影響(outcomes)について調査した。
チームの人数の多さと熟練度の低さが負債の要因を誘発し、負債はテストの不足によくみられた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Deep Learning Recommendation Model for Personalization and Recoomendation Systems</title>
      <link>https://nryotaro.dev/posts/deep_learning_recommendation_model_for_personalization_and_recommendation_systems/</link>
      <pubDate>Fri, 24 Jul 2020 13:53:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_learning_recommendation_model_for_personalization_and_recommendation_systems/</guid>
      <description>&lt;p&gt;協調フィルタリングのような推薦システムのためのネットワークアーキテクチャを提案した。
特徴の疎・密にかかわらず入力として与えることができる。
論文の例題では、個人の選好を示すアイテムとユーザからなる疎な行列を受け取り、ユーザがアイテムをクリックする確率を推定するタスクが使われている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Explaining Pair Programming Session Dynamics from Knowledge Gaps</title>
      <link>https://nryotaro.dev/posts/explaining_pair_programming_session_dynamics_from_knowledge_gaps/</link>
      <pubDate>Fri, 17 Jul 2020 19:20:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/explaining_pair_programming_session_dynamics_from_knowledge_gaps/</guid>
      <description>&lt;p&gt;ペアプログラミングによる知識移転の効果を知るために、9社の社員からなる26組のペアプログラミングを、グラウンデッド・セオリーで調査した。
従来は、熟練度合いで開発者を分けて、ペアプログラミングを分析・評価することが多い。
今回の調査では、システムの要件・仕様のようなシステム固有の知識と、言語、デザインパターン、開発ツールなどの開発全般の知識の2軸で、開発者と知識を分ける重要性を定性的に示した。
一方がシステム固有の知識に欠け、他方が開発全般の知識に欠けるときに、最も知識の伝達が活発だった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Bag of Tricks for Efficient Text Classification</title>
      <link>https://nryotaro.dev/posts/bag_of_trics_for_efficient_text_classification/</link>
      <pubDate>Fri, 17 Jul 2020 17:09:26 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bag_of_trics_for_efficient_text_classification/</guid>
      <description>&lt;p&gt;2016年における分類のSOTAと互角の精度でありながら、格段に高速に学習、推定可能なモデルを&lt;code&gt;fastText&lt;/code&gt;で構築できることを示した。
評価実験には、&lt;a href=&#34;http://projects.dfki.uni-kl.de/yfcc100m/&#34;&gt;YFCC100M&lt;/a&gt;のキャプションとタイトルからタグを予測するタスク、8つのデータセットによる感情分析が採用された。
タグの予測では、312116個のユニークなタグをつかい、大きなクラス数でもモデルがうまくはたらくことが確かめられた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Recognizing Developers&#39; Emotions while Programming</title>
      <link>https://nryotaro.dev/posts/recognizing_developers_emotions_while_programming/</link>
      <pubDate>Sat, 11 Jul 2020 12:45:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/recognizing_developers_emotions_while_programming/</guid>
      <description>&lt;p&gt;23人の被検者に30分間のプログラミングをさせ、その間5分ごとに進捗と感情を自己申告してもらい、その結果から感情と進捗の関係を調査した。
作業後にインタービューを実施し、感情が変化する要因と良くない感情への対処法をヒアリングした。
感情を測定するため最低限必要な非侵襲的器具を調べるために、被検者には、脳波、皮膚電位、脈波、心拍数を測定する器具を装着して開発してもらった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Pytorch: An Imperative Style, High-Performane Deep Learning Library</title>
      <link>https://nryotaro.dev/posts/pytorch_an_imperative_style_high_performance_deep_learning_library/</link>
      <pubDate>Sat, 11 Jul 2020 01:47:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/pytorch_an_imperative_style_high_performance_deep_learning_library/</guid>
      <description>&lt;p&gt;Pytorchの使い勝手と実行速度について解説した論文である。
ここでの使い勝手は、命令型かつPythonらしいコードでPytorchのAPIを呼びだせることを意味する。
Pytorchは、4つの設計原則として、PythonらしいAPI、機械学習の複雑な処理をPytorch内に隠蔽する、使い勝手のために過度にパフォーマンスを犠牲にしない、完璧な解決策よりも実装の単純さを重視する、をかかげる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Here We Go Again: Why Is It Difficult for Developers to Learn Another Programming Language?</title>
      <link>https://nryotaro.dev/posts/here_we_go_again/</link>
      <pubDate>Sat, 04 Jul 2020 13:55:02 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/here_we_go_again/</guid>
      <description>&lt;p&gt;既知のプログラミング言語の知識は新しい言語を覚える役に立つ。
一方で、新しい言語の学習の妨げにもなることをStack Overflowの質問とプログラマへのインタビューで明らかにした。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Automatic differentiation in Pytorch</title>
      <link>https://nryotaro.dev/posts/automatic_differentiation_in_pytorch/</link>
      <pubDate>Sat, 04 Jul 2020 12:06:25 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/automatic_differentiation_in_pytorch/</guid>
      <description>&lt;p&gt;Pytorchの自動微分を解説したプレプリントのショートペーパである。
Pytorchの自動微分特徴として、in-placeアルゴリズム、微分の導出に不要な計算を省く仕組みのあるテープ、C++による実装をあげている。
&lt;a href=&#34;https://pytorch.org/blog/pytorch-0_4_0-migration-guide/&#34;&gt;0.4.0での仕様変更&lt;/a&gt;によって&lt;code&gt;Tensors&lt;/code&gt;と&lt;code&gt;Variables&lt;/code&gt;がマージされたことや&lt;code&gt;volatile&lt;/code&gt;が非推奨になったことをふまえていない。
読むときは、以上の点をはじめとする現在のAPIとの差異に注意する必要がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ ROUGE: A Package for Automatic Evaluation of Summaries</title>
      <link>https://nryotaro.dev/posts/rouge/</link>
      <pubDate>Sat, 27 Jun 2020 12:55:45 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/rouge/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;生成された要約を機械的に評価するための指標, Recall-Oriented Understudy for Gisting Evaluation(ROUGE)を提案した論文である。
人が作成した複数の要約文書との再現率で要約文書を評価する。
ROUGEは、ROUGE-N, ROUGE-L, ROUGE-W, ROUGE-S, ROUGE-SUの5つの指標の総称である。
同じ要約へのROUGEスコアと人の評価の相関によって、ROUGEの指標としての有用性を評価した。
その結果、ROUGE-2, ROUGE-L, ROUGE-W, ROUGE-Sは、文書の要約の評価に向き、ROUGE-1, ROUGE-L, ROUGE-W, ROUGE-SU4, ROUGE-SU9はヘッドラインほどの短い要約文の評価に向いていることがわかった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Do Developers Discover New Tools On The Toilet?</title>
      <link>https://nryotaro.dev/posts/do_developers_discover_new_tools_on_the_toilet/</link>
      <pubDate>Sat, 20 Jun 2020 22:33:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/do_developers_discover_new_tools_on_the_toilet/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://mike-bland.com/2011/10/25/testing-on-the-toilet.html&#34;&gt;Testing on the Toilet&lt;/a&gt;の効果を&lt;a href=&#34;https://research.google/pubs/pub41854/&#34;&gt;CausalImpact&lt;/a&gt;で示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Neural Attention Model for Sentence Summarization</title>
      <link>https://nryotaro.dev/posts/a_neural_attention_model_for_sentence_summarization/</link>
      <pubDate>Sat, 20 Jun 2020 16:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_neural_attention_model_for_sentence_summarization/</guid>
      <description>&lt;p&gt;注意機構による深層学習で文を要約する手法である。
もとの文にない単語を含む要約文を生成できるが、生成前に文の長さを決めておかなければならない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ BLEU: a Method for Automatic Evaluation of Machine Translation</title>
      <link>https://nryotaro.dev/posts/bleu/</link>
      <pubDate>Sat, 13 Jun 2020 13:48:07 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bleu/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;自動翻訳を定量的に評価するための指標BLEUを提案した論文である。
指標は、専門家の翻訳に翻訳に高い評価をあたえるよう設計されている。
BLEUは、ひとつの候補訳に対する1つ以上の参照訳をあたえ、0から1の値をとるスコアを出力する。
スコアは高いほどよい。
BLEUは、参照訳にある単語を過剰に含むことや文の短さにペナルティをあたえ、適合率で候補訳を評価する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Sequence to Sequence Learning with Nueral Networks</title>
      <link>https://nryotaro.dev/posts/sequence_to_sequence_learning_with_neural_networks/</link>
      <pubDate>Sat, 06 Jun 2020 00:18:16 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/sequence_to_sequence_learning_with_neural_networks/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;Sequence to Sequenceの論文。
入出力が系列データを学習する場合、入力と出力の長さが等しかったり対応関係にある箇所が系列の方向に単調でなければならなかったりする。
これらの制約に対処するために、Sequence to Sequenceでは、入力全体を固定長のベクトルに一度変換し、そのベクトルをもとに出力を予測する。
2種類のLSTMをもち、入力を与えるLSTMの最終層の隠れ状態で、固定長ベクトルをつくる。
固定長のベクトルは、単調の制約を緩めるはたらきをする。
このベクトルは、もう一方のLSTMにあたえられ、その主力が最終的な出力になる。
実験では、入力系列を反転してあたえると、入力と出力の対応関係にある箇所の距離が近づき、予測性能が上がることが確認された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Google&#39;s Neural Machine Transltation System: Bridging the Gap between Human and Machine Translation</title>
      <link>https://nryotaro.dev/posts/google_neural_machine_translation_system/</link>
      <pubDate>Sat, 30 May 2020 16:09:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/google_neural_machine_translation_system/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ニューラルネットワークをもちいた機械翻訳システムの論文である。
解決したい問題として、学習と推論時の処理時間の長さ、低頻出の単語を翻訳する難しさ、入力文の一部が翻訳されないことをあげ、注意機構でつながれたEncoderとDecoderからなるアーキテクチャを提案した。
学習時間を短縮するために、Decoderの最初の層とEncodeerの出力層から注意をつくる注意機構を採用し、Decoderを並列に学習できるようにしている。
また、量子化によって推論時間を短縮をしている。
低頻出の単語でも翻訳できるようにwordpieceでエンコードされた入力をうけとる。
入力文の一部が翻訳されない問題に対しては、短い出力文に罰則を課すビームサーチで出力文の候補を探索する仕組みが導入されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Zero-Shot Learning with Semantic Output Codes</title>
      <link>https://nryotaro.dev/posts/zero_shot_learning_with_semantic_output_codes/</link>
      <pubDate>Sat, 23 May 2020 14:04:24 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/zero_shot_learning_with_semantic_output_codes/</guid>
      <description>&lt;p&gt;学習データにないラベルを推定する問題に対してzero-shot leanringと名づけ、ラベルを推定できる確率と条件を形式化した論文である。
形式化するモデルは、複数の二値分類器と1つの最近傍探索器からなる。
最近傍探索は、2値分類器の出力を要素とするベクトルをうけとり、最近傍のラベルに対応するベクトルを探す。
PACフレームワークにもとづく必要な学習データの件数を示し、そのデータで訓練されたモデルが学習データにないラベルを推定できる確率を示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING</title>
      <link>https://nryotaro.dev/posts/a_structured_self_attentivesentence_embedding/</link>
      <pubDate>Sat, 16 May 2020 14:05:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_structured_self_attentivesentence_embedding/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;自己注意機構をもちいて、可変長の文を埋め込み行列に変換するアーキテクチャを発表した論文である。
埋め込み行列の各行は、それぞれ文中の異なる箇所の意味を反映する。
アーキテクチャは2つの構成からなり、入力から出力にむかい双方向LSTMを、次に自己注意機構をもつ。
自己注意機構を導入した背景は、回帰結合型のネットワークでは、全ての時刻わたって入力の意味を保持することは難しく、また不要であるという著者らの仮説である。
3つの実験により、文の分散表現を獲得する先行研究と比較し、自己注意機構の効果が確認された。
注意機構は複数のベクトルのどれを重視するかを学習できるため、埋め込まれた文の箇所を可視化できることも示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Poincaré Embeddings for Learning Hierarchical Representations</title>
      <link>https://nryotaro.dev/posts/poincare_embeddings/</link>
      <pubDate>Sat, 09 May 2020 14:42:32 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/poincare_embeddings/</guid>
      <description>概要 単語のように上位下位関係のある記号を、ポアンカレ球体模型という双曲空間に埋め込む手法を発表した論文である。 ユークリッド空間よりも、記号間の類似度や上位下位関係が保たれていることを実験的に示した。 記号を木のノードとして配置し関係を表現するとき、ノード数は深さ\(l\)対して指数関数的に増加する。 双曲幾何学では、円板の面積や周は半径\(r\)に対して指数関数的に増大するため、木を2次元でモデル化できる。 たとえば、深さ\(l\)以下のノードを半径\(r \varpropto l \)の空間に配置することができる。 一方、2次元のユークリッド空間の場合、半径\(r\)に対する円周は線形、円の面積は2次関数的であるため、モデル化が難しい。 実験では、次元数が少ないほど、ポアンカレ球体模型とユークリッド空間の間で、上下関係や類似度の表現力に差があった。
損失関数 埋め込みたい上下関係\(\mathcal{D}=\{(u, v)\}\)を記号の数を\(n\)として入力すると、アルゴリズムは、埋め込みベクトルの集合\({\rm \Theta}=\{\boldsymbol{\theta}_i\}^n_{i=1}\)を出力する。 ただし、\(\boldsymbol{\theta}\in \mathcal{B}^d\), \(\mathcal{B}^d=\{\boldsymbol{x}\in \mathbb{R}^d\mid ||\boldsymbol{x}||&amp;lt;1\}\)とする。 学習では、次の損失関数\(\mathcal{L}(\Theta)\)をもちいる。
$$ \mathcal{L}(\Theta)=\sum_{(u, v)\in \mathcal{D}}\log\frac{e^{-d(\boldsymbol{u}, \boldsymbol{v})}}{\sum_{\boldsymbol{v}&amp;rsquo;\in \mathcal{N}(u)}e^{-d(\boldsymbol{u}, \boldsymbol{v}&amp;lsquo;)}} $$ \(\mathcal{N}(u)=\{v&amp;rsquo;\mid (u, v&amp;rsquo;)\notin \mathcal{D}\} \cup \{v\}\)は\(v\)を含んだ\(u\)に対する負例である。 実験では、正例に対して10の負例をサンプリングしていた。 \(d\)は、\(\boldsymbol{u}, \boldsymbol{v}\in \mathcal{B}^d\)の距離であり、次の式であたえらえる。
$$ d(\boldsymbol{u}, \boldsymbol{v}) = \mathrm{arccosh}\left(1+2\frac{||\boldsymbol{u}-\boldsymbol{v}||^2}{(1-||\boldsymbol{u}||^2)(1-||\boldsymbol{v}||^2)}\right) $$
最適化 RSGDやRSVRGで損失関数の値を最小化する埋め込みベクトルを探す。 ここでは、RSGDについて説明する。 RSGDでは、次のパラメタの更新式をとる。
$$ \boldsymbol{\theta}_{t+1} = \mathfrak{R}_{\theta_t}(-\eta_t\nabla_R\mathcal{L}(\boldsymbol{\theta}_t)) $$ \(\mathfrak{R}_{\theta_t}\)はレトラクションで、ここでは\(\mathfrak{R}_\theta(\boldsymbol{v})=\boldsymbol{\theta}+\boldsymbol{v}\)をもちいる。 \(\eta_t\)は時刻\(t\)の学習率をさす。 \(\nabla_R\)はリーマン多様体上の勾配であり、ユークリッド空間上の勾配\(\nabla_E\)とは
$$ \nabla_R = \frac{(1-||\boldsymbol{\theta_t}||^2)^2}{4}\nabla_E $$ の関係がある。 以上より、更新式は
$$ \mathrm{proj}(\boldsymbol{\theta})= \begin{cases} \boldsymbol{\theta}/||\boldsymbol{\theta}|| - \epsilon &amp;amp;\mathrm{if}\ ||\boldsymbol{\theta}||\ge 1 \</description>
    </item>
    
    <item>
      <title>論文 メモ Learning Joint Multilingual Sentence Representations with Neural Machine Translation</title>
      <link>https://nryotaro.dev/posts/learning_joint_multilingual_sentence_representations_with_neural_machine_translation/</link>
      <pubDate>Wed, 29 Apr 2020 14:40:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_joint_multilingual_sentence_representations_with_neural_machine_translation/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;多言語の文をあつかう分散表現モデルを発表した論文である。
異なる言語の文であっても、意味が同じであれば、同様の分散表現に変換される。
モデルのアーキテクチャにはseq2seqを、入力と出力には対訳コーパスをつかう。
ミニバッチごとに、入力または出力の言語をいれかえ、言語に依存しない文の意味の分散表現への変換方法を学習する。
本論文の成果は多言語に対応する分散表現のモデルのライブラリ&lt;a href=&#34;https://github.com/facebookresearch/LASER&#34;&gt;LASER&lt;/a&gt;に応用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ ALBERT: A LITE BERT FOR SELF-SUPERVISED LEARNING OF LANGUAGE REPRESENTATIONS</title>
      <link>https://nryotaro.dev/posts/albert/</link>
      <pubDate>Sat, 25 Apr 2020 13:12:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/albert/</guid>
      <description>&lt;p&gt;BERTのパラメタ数を削減し、学習時間の短縮と正則化による予測性能の向上を両立したモデルALBERTを提案し、GLUE, RACE, SQuADでSoTAを実現した。
BERT-largeと比べると、ALBERT-largeのパラメタ数は約5.3%の18Mであり、学習時間は1.7倍速い。
パラメタを削減するために、単語のOne-hotベクトルをあたえられる単語埋め込み行列の次元を減らし、隠れ層の順伝播ネットワークや注意機構のパラメタを層の間で共有した。
また、Next Sentence Prediction(NSP)による学習を、与えられた2文の前後関係を判定する学習Sentence Order Prediction(SOP)におきかえ、主タスクの予測性能を向上をはかった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Random Walks in recommender Systems: Exact Computation and Simulations</title>
      <link>https://nryotaro.dev/posts/random_walks_in_recommender_systems/</link>
      <pubDate>Sat, 18 Apr 2020 01:25:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/random_walks_in_recommender_systems/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/4072747&#34;&gt;F. Foussら&lt;/a&gt;や&lt;a href=&#34;https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-444.pdf&#34;&gt;M. Goriら&lt;/a&gt;のランダムウォークによる推薦システムの先行研究を、質や計算量について比較した論文である。
比較対象には、著者らの用意したも含まれる。
実験には、MovieLensのデータセットが使われた。
F. Foussらの実験で使われた評価指標や上位kの推薦結果のヒット数で評価したところ、著者らの用意した単純な手法\(P^s\)やその拡張\(P_\alpha^s\)が質と計算量の両方で最も優れた結果を残した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Domain Adversarial Training of Neural Networks</title>
      <link>https://nryotaro.dev/posts/domain_adversarial_training_of_neural_networks/</link>
      <pubDate>Sat, 11 Apr 2020 15:07:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/domain_adversarial_training_of_neural_networks/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ニューラルネットワークをもちいたドメイン適用の論文である。
ソースドメインのラベルつきデータと目標ドメインのラベルのないデータでモデルを訓練し、目標ドメインに対する分類性能を引きあげる。
目的関数は、ソースドメインの分類器の目的関数とデータのドメインを判定する識別器の目的関数からなる。
後者は、前者の正則化項としてはたらく。
これにより、ドメイン間に共通する特徴からソースドメインのデータのラベルを高い性能で予測できるようになる。
目標関数から、ドメイン間のデータの分布が近いほど、目標ドメインのデータでも高い分類性能を発揮する。
先行研究との違いは、できるだけ共通するする特徴で分類するという着想を、通常の分類と同じく、確率的勾配降下法で実現したところにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Character-Aware Neural Language Models</title>
      <link>https://nryotaro.dev/posts/character_aware_neural_language_models/</link>
      <pubDate>Sat, 04 Apr 2020 16:46:56 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/character_aware_neural_language_models/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;文字単位の入力から次に出現する単語を予測するニューラル言語モデルの論文である。
アーキテクチャは入力から近い順にCNN, highway network, LSTMからなる。
実験データにPenn Treebankを、評価指標にPerplexityを採用してモデルを評価したところ、
論文が発表された2016年時点での&lt;a href=&#34;https://arxiv.org/abs/1409.2329&#34;&gt;SOTA&lt;/a&gt;の60%程度のパラメタしかないモデルでありながら、これに匹敵する性能を発揮した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Deep contextualized word representations</title>
      <link>https://nryotaro.dev/posts/deep_contextualized_word_representations/</link>
      <pubDate>Tue, 24 Mar 2020 01:59:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_contextualized_word_representations/</guid>
      <description>&lt;p&gt;文脈をふまえた単語の分散表現を生成する手法を提案し、教師あり学習に応用することで評価した論文である。
文字単位の学習済み双方向LSTM言語モデルへの入力と各層の出力から分散表現をつくる。
言語モデルの入力やどの層をどれだけ重視するかは、教師あり学習のときに更新するパラメタのひとつになる。
実験では、構文にかかわるタスクであれば入力層に近い層が、意味にかかわるものであれば出力層に近い層が、重視された。
モデルは、Embeddings from Language Modelsにちなみ、ELMoと名付けられた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ The Seven Sins: Security Smells in Infrastructure as Code Scripts</title>
      <link>https://nryotaro.dev/posts/the_seven_sins/</link>
      <pubDate>Fri, 20 Mar 2020 15:14:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_seven_sins/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;OSSの調査にもとづき、Infrastrucure as Code(IaC)スクリプトに潜む主要なセキュリティ上の不吉な匂い(Security Smells)を7つ列挙し、これらを検出するツールを実装した論文である。
論文のねらいは、開発者がIaCスクリプトに不吉な匂いを混ぜないようにすることにある。
著者らは、本論文で、ICSE2019のDistinguished Paper Awardを受賞した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Semi-supervised Sequence Learning</title>
      <link>https://nryotaro.dev/posts/semi_supervised_sequence_learning/</link>
      <pubDate>Sat, 14 Mar 2020 23:46:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/semi_supervised_sequence_learning/</guid>
      <description>&lt;p&gt;系列データの教師あり学習において、ラベルのないデータを学習した言語モデルやオートエンコーダーの重みでLSTMを初期化することの有用性を実験的に示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ In Search of an Understandable Consensus Algorithm</title>
      <link>https://nryotaro.dev/posts/raft/</link>
      <pubDate>Mon, 09 Mar 2020 02:17:22 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/raft/</guid>
      <description>&lt;p&gt;Raftとよばれるコンセンサスアルゴリズムを提案した論文である。
Raftは、Multi Paxosと同様の実行結果をもたらす。
実行するコマンドのログをサーバ間で交換することで、状態を同期し、サーバの一部が落ちてもシステムを継続することができる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing</title>
      <link>https://nryotaro.dev/posts/sentence_piece/</link>
      <pubDate>Sat, 29 Feb 2020 21:15:17 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/sentence_piece/</guid>
      <description>&lt;p&gt;SentencePieceは、深層学習向けのトークナイザ・脱トークナイザである。
特定の言語を意識した処理がないため、あらゆるテキストに利用できる。
本論文では、C++やPythonによる&lt;a href=&#34;https://github.com/google/sentencepiece&#34;&gt;実装&lt;/a&gt;と翻訳への適用実験について書かれている。
アルゴリズムの解説は、&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162.pdf&#34;&gt;Sennrich et al.&lt;/a&gt;や&lt;a href=&#34;https://arxiv.org/pdf/1804.10959.pdf&#34;&gt;Kudo.&lt;/a&gt;にゆずられている。
これらの論文について2019年7月13日の&lt;a href=&#34;../neural_machine_translation_of_rate_words/&#34;&gt;記事&lt;/a&gt;と2019年7月17日の&lt;a href=&#34;./subword_regularization/&#34;&gt;記事&lt;/a&gt;で解説している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Latent Dirichlet Allocation</title>
      <link>https://nryotaro.dev/posts/latent_dirichlet_allocation/</link>
      <pubDate>Sun, 23 Feb 2020 21:54:59 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/latent_dirichlet_allocation/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;トピックモデルの潜在的ディリクレ配分法(LDA)の原論文である。
LDAは、テキストコーパスのような離散データの確率的生成モデルである。
意味のあるデータのまとまりに対する端的な説明を与える情報を見つけることを目的としている。
3つの階層からなる階層ベイズモデルである。
、データの要素は、各トピックを表すモデルの混合モデルから生成される。
トピックもまた混合モデルから確率的に生成される。
推論にはベイズ変分法を、パラメタの推定にはEMアルゴリズムをもちいらる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Unsupervised Pretraining for Sequence to Sequence Learning</title>
      <link>https://nryotaro.dev/posts/unsupervised_pretraining_for_sequence_to_sequence_learning/</link>
      <pubDate>Sun, 16 Feb 2020 14:21:55 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/unsupervised_pretraining_for_sequence_to_sequence_learning/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;事前学習とファインチューニングにより&lt;a href=&#34;https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf&#34;&gt;seq2seq&lt;/a&gt;の汎化性能を改善する手法を提案した論文である。
encoderの重みを学習済み言語モデルの重みで初期化する。
decoderについても、encoderと別の言語モデルを用意し、その重みで初期化する。
ただし、工夫のないファインチューニングをすると&lt;a href=&#34;https://arxiv.org/pdf/1312.6211.pdf&#34;&gt;破滅的忘却&lt;/a&gt;が生じてしまう。
そこで、ファインチューニングでは言語モデルとseq2seqの目的関数の両方を学習につかうことで、過学習をさけ、汎化性能を確保する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Playing Atari with Deep Reinforcement Learning</title>
      <link>https://nryotaro.dev/posts/playing_atari_with_deep_reinforcement_learning/</link>
      <pubDate>Sun, 09 Feb 2020 17:05:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/playing_atari_with_deep_reinforcement_learning/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;深層強化学習をAtari2600の7つのゲームに応用し、うち6つについて先行手法の性能を超えたDeep Q-Networks(DQN)を提案した論文である。
ピクセルデータを直接入力として与え、深層学習で方策を学習する手法としては初めて提案された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ context2vec: Learning Generic Context Embedding with Bidirectional LSTM</title>
      <link>https://nryotaro.dev/posts/context2vec/</link>
      <pubDate>Sun, 02 Feb 2020 19:19:46 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/context2vec/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;文書の文脈の分散表現を獲得するニューラルネットワークのアーキテクチャ*context2vec*を提案、評価した論文である。
アーキテクチャの基本構造は&lt;a href=&#34;https://arxiv.org/pdf/1301.3781.pdf&#34;&gt;CBOW&lt;/a&gt;と同様で、周辺の単語から中心の単語を当てられるようにコーパスをもとにモデルを訓練する。
CBOWとの違いは、文脈の算出方法にある。
CBOWは、ウィンドウ内のベクトルの平均値で文脈の分散表現を求める。
一方、*context2vec*では、双方向LSTMの出力をもとに算出する。
&lt;!-- 分散表現を汎用的に利用できることを想定しており、獲得した分散表現をsentence comp --&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE</title>
      <link>https://nryotaro.dev/posts/neural_machine_translation_by_jointly_learning_to_align_and_translate/</link>
      <pubDate>Sat, 01 Feb 2020 17:21:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/neural_machine_translation_by_jointly_learning_to_align_and_translate/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;Decoderに注意機構を採用したencoder-decoderモデルを提案した論文である。
ICLR2015で発表された。
論文の発表当時、encoder-decoderモデルによる翻訳の多くは、encoderが入力文を固定長ベクトルに変換し、固定長ベクトルから翻訳された文を出力していた。
著者らは、固定長ベクトルへの変換が長い文の翻訳性能を下げていると考え、固定長ベクトルを注意機構におきかえたencoder-decoderモデルを提案する。
モデルは、翻訳に加え、生成する単語と入力文の箇所の関係を学習する。
推定時には、まず、次に生成する単語に関係する入力文の箇所を推定する。
次に、推定された箇所と生成済の単語列をもとに、単語を生成する。
特に長い文書の翻訳において、固定長ベクトルをつかうモデルよりも、提案手法が優れていることを実験的に示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ &#34;Why Should I Trust You?&#34; Explaining the Predictions of Any Classifier</title>
      <link>https://nryotaro.dev/posts/why_should_i_trust_you/</link>
      <pubDate>Sun, 26 Jan 2020 01:38:57 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/why_should_i_trust_you/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;モデルの予測に説明をあたえる手法、Local Interpretable Model-agnostic Explanations (LIME)を提案する。
モデルが回帰や分類器であれば、アルゴリズムによらずLIMEを適用できる。
説明を与えたい事例近くにある事例を解釈可能なモデルに学習させ、解釈可能なモデルで予測を説明する。
また、個別の予測ではなく、モデル自体をよく説明する事例を集める手法Submodullar Pick (SP)-LIMEを提案する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Active Learning for Ranking through Expected Loss Optimization</title>
      <link>https://nryotaro.dev/posts/active_learning_for_ranking_through_expected_loss_optimization/</link>
      <pubDate>Sun, 19 Jan 2020 18:23:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/active_learning_for_ranking_through_expected_loss_optimization/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;Yahoo! Labsで開発されたランキングのための能動学習の論文である。
提案手法は、Yahoo!検索エンジンでの&lt;a href=&#34;https://www.kdd.org/kdd2016/papers/files/adf0361-yinA.pdf&#34;&gt;採用実績&lt;/a&gt;がある。
手法は、Expected Loss Optimization(ELO)とよばれ、ベイズ決定則によって識別したときの損失の期待値が最大になるデータを選ぶ。
ELOに用いる損失関数にDCGを採用したExpected DCG Loss Optimization(ELO-DCG)を提案し、実験で評価した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>AtCoderに提出したコードをテストするためのDockerイメージ</title>
      <link>https://nryotaro.dev/posts/docker-cmake-clang/</link>
      <pubDate>Tue, 14 Jan 2020 00:29:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/docker-cmake-clang/</guid>
      <description>AtCoderに提出したコードをテストするためのDockerイメージを実装した。 イメージのDockerfileはこちらにある。 AtCoderで提出したコードをgithubで管理していて、これをテストするために作った。</description>
    </item>
    
    <item>
      <title>論文メモ Unsupervised Models for Named Entity Classification</title>
      <link>https://nryotaro.dev/posts/unsupervised_models_for_named_entity_classification/</link>
      <pubDate>Mon, 13 Jan 2020 19:54:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/unsupervised_models_for_named_entity_classification/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;1999年に発表された教師なしの固有表現抽出の手法である。
発表時期が古いことに注意してほしい。
2つの手法が提案されている。
ひとつは、DL-CoTrainと呼ばれるルールベースの手法であり、教師なしデータに既存のルールを適用、適用結果から導出したルールを既存のルールに追加、をくりかえしてルールを増やす。
もう一方は、AdaBoostを応用したCoBoostとよばれる手法である。
ルールベースの手法のほうがCoBoostよりもよい実験結果であったので、前者のみを説明する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Multilabel Classification with Label Correlations and Missing Labels</title>
      <link>https://nryotaro.dev/posts/multilabel_classification_with_label_correlations_and_missing_labels/</link>
      <pubDate>Mon, 06 Jan 2020 22:27:05 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/multilabel_classification_with_label_correlations_and_missing_labels/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ラベルの相関関係を学習し推論に利用するマルチラベルの線形モデルを提案した論文である。
相関関係のあるラベル集合を相関関係のないラベル集合に変換し、ラベルごとに分けて学習する手法、Label transformationを応用する。
分類器は、相関関係だけなく、学習データに与えられていないラベルを推定するように拡張できる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Learning Deep Structured Semantic Models for Web Search using Clickthrough Data</title>
      <link>https://nryotaro.dev/posts/learning_deep_structured_semantics_models_for_web_search_using_clickthrough_data/</link>
      <pubDate>Sat, 04 Jan 2020 23:25:20 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_deep_structured_semantics_models_for_web_search_using_clickthrough_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;クエリと文書を同じ低次元の空間に射影する深層学習のモデルを提案した論文である。
クエリと文書は、適合度合いが高いほど、近くに配置される。
教師データは、クエリと文書の組からなる教師データである。
実験では、商用検索エンジンから抽出した16510件のクエリと対応するWeサイトのタイトルがつかわれる。
Web文書の大量の語彙をあつかうために、語彙の増加に対して次元数を抑えるbag-of-wordsの手法、word hasingも提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Classification in the Presence of Label Noise: a Survey</title>
      <link>https://nryotaro.dev/posts/classification_in_the_presence_of_label_noise/</link>
      <pubDate>Mon, 30 Dec 2019 16:07:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/classification_in_the_presence_of_label_noise/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ノイズのある教師データによるクラス分類の&lt;a href=&#34;https://romisatriawahono.net/lecture/rm/survey/machine%20learning/Frenay%20-%20Classification%20in%20the%20Presence%20of%20Label%20Noise%20-%202014.pdf&#34;&gt;サーベイ論文&lt;/a&gt;である。発表時期は、&lt;a href=&#34;https://ieeexplore.ieee.org/document/6685834&#34;&gt;2013年の12月&lt;/a&gt;である。
主な内容は、ノイズの分類、ノイズが分類に及ぼす影響、ノイズへの対策である。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Distributed Representations of Sentences and Documents</title>
      <link>https://nryotaro.dev/posts/distributed_representations_of_sentences_and_documents/</link>
      <pubDate>Sat, 28 Dec 2019 00:56:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/distributed_representations_of_sentences_and_documents/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://radimrehurek.com/gensim/models/doc2vec.html&#34;&gt;Doc2Vec&lt;/a&gt;のアルゴリズムとして採用されたニューラル言語モデルParagraph Vectorを提案した論文である。
bag of wordsは、文書の単語順を記憶せず、また、似た意味の単語ベクトルと無関係なベクトルを単語にわりあてる。
Paragraph Vectorは、文脈中の単語と抽出元のパラグラフから文脈の中心の単語をあてられるように学習することで、可変長文字列から固定長の文書埋め込みベクトルを生成できるようになる。
これにより、単語順と単語の意味を記憶したベクトルの生成を実現する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ GloVe: Global Vectors for Word Representation</title>
      <link>https://nryotaro.dev/posts/glove_vectors_for_word_representation/</link>
      <pubDate>Sat, 21 Dec 2019 23:53:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/glove_vectors_for_word_representation/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.aclweb.org/anthology/D14-1162.pdf&#34;&gt;GloVe&lt;/a&gt;は,コーパスに出現する単語の共起回数を学習するニューラル言語モデルである。
既存手法を単語の出現頻度の統計値つかう手法と対数双線形モデルに分類し、両者の長所を備え短所を補う手法として、GloVeを提案する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ BERT: Pre-training of Deep Bidirectional Transformers for Lnaguages Understaing</title>
      <link>https://nryotaro.dev/posts/bert/</link>
      <pubDate>Sat, 14 Dec 2019 17:39:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bert/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;BERTは&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;Attention Is All You Need&lt;/a&gt;にあるTransformerをアーキテクチャに導入した分散表現のモデルであり、本稿は、事前学習済みのBERTにファインチューニングを適用しQAタスクや自然言語推論のベンチマークにおいて既存研究を上回る結果を示している。
なお、アーキテクチャに関する説明は少なく、子細に知りたい場合は&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;Attention Is All You Need&lt;/a&gt;や&lt;a href=&#34;http://nlp.seas.harvard.edu/2018/04/03/attention.html&#34;&gt;The Annotated Transformer&lt;/a&gt;を参照するように案内されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ 150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com</title>
      <link>https://nryotaro.dev/posts/150_successfuly_machine_learning_modes/</link>
      <pubDate>Sat, 14 Dec 2019 13:25:04 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/150_successfuly_machine_learning_modes/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;宿泊予約サービス&lt;a href=&#34;http://booking.com/&#34;&gt;Booking.com&lt;/a&gt;におけるモデルの開発運用でえられた教訓を6つにまとめたKDD2019の論文である。
教訓の主眼を収益におき、6つの教訓を通して、実運用環境における仮説と実験を反復する重要性を強調する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Ranking Relevance In Yahoo Search</title>
      <link>https://nryotaro.dev/posts/ranking_relevance_in_yahoo_search/</link>
      <pubDate>Sat, 07 Dec 2019 15:10:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/ranking_relevance_in_yahoo_search/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;Yahooの検索エンジンを解説するKDD16の論文である。
論文におけるランキングの課題は、クエリと文書の語彙がことなること、ほとんどのクエリは滅多に入力されないこと、クエリの意味の解釈が難しいことである。
これらの課題に対する手法として、ランキングのモデル、特徴のつくりかた、クエリを文書によせる翻訳モデルを解説する。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ A Dual Embedding Space Model for Document Ranking</title>
      <link>https://nryotaro.dev/posts/a_dual_embedding_space_model_for_document_ranking/</link>
      <pubDate>Sat, 30 Nov 2019 08:18:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_dual_embedding_space_model_for_document_ranking/</guid>
      <description>&lt;p&gt;Dual Embedding Space Model(DESM)は、word2vecで単語埋め込みベクトルにしたクエリと文書のランキング関数である。
実験における比較対象のBM25は、クエリの単語の文書での出現頻度をもとに順序をつける。
DESMは、クエリの単語に関係する単語をもとに判断する。
単語埋め込みベクトルの作りに特徴があり、入力側のone-hotベクトル表現にわりあてる単語埋め込みベクトルでクエリを、出力側でベクトルで文書を分散表現にする。
実験から、DESMだけで順位づけをすると偽陽性が高くなるが、DESMとBM25の加重平均をとるとBM25よりも高いNDCG値になることが分かった。
アルゴリズムを実装したライブラリへのリンクは&lt;a href=&#34;https://github.com/nryotaro/desm&#34;&gt;こちら&lt;/a&gt;。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ On Calibration of Modern Neural Networks</title>
      <link>https://nryotaro.dev/posts/on_calibration_of_modern_neural_networks/</link>
      <pubDate>Sat, 23 Nov 2019 14:37:30 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/on_calibration_of_modern_neural_networks/</guid>
      <description>&lt;p&gt;ネットワークの複雑化、バッチ正則化、重み減衰を使わない、負の対数尤度の過学習が汎化精度を上げるが、予測確率と精度のズレを大きくすることを実験的に示した。
予測確率を補正する6つの手法を19種類のクラス分類のデータセットに適用した結果、
最も補正できたものは、温度つきソフトマックスの出力を予測確率にする場合であった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Trinary-Projection Trees for Approximate Nerest Neighbor Search</title>
      <link>https://nryotaro.dev/posts/trinary_projection_trees/</link>
      <pubDate>Sat, 16 Nov 2019 13:12:52 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/trinary_projection_trees/</guid>
      <description>&lt;p&gt;Trinary-Projection Trees(TP trees)は、kd木のように、ユークリッド空間の分割を二分木で表現できるデータ構造である。
超平面は1または-1の重みのついた少数の座標軸で定義される。
これにより、探索時の分岐にかかる計算が、加算と減算だけからなる\(O(1)\)となる。
また、射影されたデータの分散の大きい超平面を探し、同じ分割にある点同士の距離を小さくすることで、精度を向上させている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>論文メモ Get Another Label? Improving Data Quality and Data Mining Using Multiple, Noisy Labelers</title>
      <link>https://nryotaro.dev/posts/get_another_label/</link>
      <pubDate>Sat, 09 Nov 2019 21:46:12 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/get_another_label/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ある確率でデータに誤ったラベルをふるlabelerでデータにラベルをふるときに、
既にラベルのあるデータに重ねてラベルをふるべきか調査した。
12種類のラベルつきデータセットを使い、
正解ラベルを誤ったラベルに置換する割合や同一のデータのもつラベルの数を変化させ、モデルの精度の違いを観察した。
加えて、ラベルをふるべきデータを推定する手法も提案している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ ActiveClean: Interactive Data Cleaning For Statistical Modeling</title>
      <link>https://nryotaro.dev/posts/active_clean/</link>
      <pubDate>Sat, 09 Nov 2019 15:37:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/active_clean/</guid>
      <description>&lt;p&gt;ActiveCleanは、教師データの誤りを修正し、モデルの精度を改善する手法である。
優先して修正すべきデータを推定し、データが修正されたら修正されたデータでモデルを学習する。
この修正と学習を条件を満たすまでくりかえす。
反復的な学習で大域的最適解をえられるモデルであれば、最適解への収束が保証される。
データの修正件数が等しい場合に、先行研究と比べて最大2.5倍の精度改善を達成した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ WebTables: Exploring the Power of Tables on the Web</title>
      <link>https://nryotaro.dev/posts/web_tables/</link>
      <pubDate>Thu, 31 Oct 2019 21:09:38 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/web_tables/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題の論文は、Web上の表から抽出した大量の関係モデルを対象にした検索を提案・評価した
。検索の他にも、一部の属性を入力とするスキーマの補完、入力した属性ないしスキーマに類似のものを推定するアルゴリズムの議論もある。
ここのスキーマは属性のリストである。論文の著者らは研究時にGoogleに在籍しており、論文で使われたコーパスはグーグルの汎用ウェブクローラで集めた141億のHTMLの表から抽出した高精度な154百万の関係モデルである。
コーパスに使うものはHTML形式の表から抽出した関係モデルのみである。
手法の新規性は、1億以上もの大量のテーブルを対象にしていることにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ A Survey on Data Collection for Machine Learning</title>
      <link>https://nryotaro.dev/posts/a_survey_on_data_collection_for_machine_learning/</link>
      <pubDate>Sat, 26 Oct 2019 14:27:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_survey_on_data_collection_for_machine_learning/</guid>
      <description>&lt;p&gt;表題の論文は、文字通り、機械学習に使う教師データに関するサーベイ論文であり、
機械学習や自然言語処理などのデータの応用分野だけでなく、データの管理にまつわる分野の調査も含まれているところに特徴がある。
データの管理に着目している理由は、深層学習の発展によって必要な教師データが増えたことで、データの管理の課題が顕在化してきたことである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Structure estimation for discrete graphical models: Generalized covariance matrices and their inverses</title>
      <link>https://nryotaro.dev/posts/structure_estimation_for_dscrete_graphical_models/</link>
      <pubDate>Sat, 19 Oct 2019 16:21:31 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/structure_estimation_for_dscrete_graphical_models/</guid>
      <description>&lt;p&gt;表題の論文は、マルコフ確率場をなす無向グラフとグラフの構造を反映した逆共分散行列の間の対応関係を証明し、
観測した確率変数の値からグラフの構造を復元する実験を通じて、対応関係を確認した。
この手法は&lt;a href=&#34;https://arxiv.org/pdf/1810.02840.pdf&#34;&gt;Snorkel&lt;/a&gt;というWeak supervisionの手法において、
正解データのない環境で、ノイズつきの教師データを生成する異なるソース間の相関関係を推定するために応用された。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Feature Selection for Text Categorization on Imbalanced Data</title>
      <link>https://nryotaro.dev/posts/feature_selection_for_text_categorization_on_imbalance_data/</link>
      <pubDate>Sat, 12 Oct 2019 15:59:09 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/feature_selection_for_text_categorization_on_imbalance_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題の論文は、特徴選択において、正例に顕著な特徴から選ぶ割合を明示的に決めることで、正例と負例それぞれに顕著な特徴の割合を調整することが、不均衡な文書分類における予測性能の向上に役立つことを示した。
情報利得やオッズ比など単変量統計にもとづく特徴選択において、統計量の値によって暗黙的に決められた割合と異なる割合の場合の方が予測性能が高いことを実験的に示した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Snorkel DryBell: A Case Study in Deploying Weak Supervision at Industrial Scale</title>
      <link>https://nryotaro.dev/posts/snorkel_drybell_case_study/</link>
      <pubDate>Sat, 05 Oct 2019 00:45:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/snorkel_drybell_case_study/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題の論文では、&lt;a href=&#34;https://www.snorkel.org&#34;&gt;Snorkel&lt;/a&gt;というWeak Supervisionの手法をGoogleで適用した結果の考察と評価がなされている。
Weak Supervisionは、人手よりも効率良くノイズ交じりの教師データを生成する手法である。
Snorkelは、引数にサンプルを返り値にラベルを返す複数の関数をラベルなしデータに適用し、結果から関数の精度を予測し、個々の関数よりも高い精度でデータにラベルを与える。この関数をラベリング関数という。Snorkel DryBellは、Snorkelのアルゴリズムをスケールさせるために、MapReduceに適用できるように修正されたものをさす。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Training Complex Models with Multi-Task Weak Supervision</title>
      <link>https://nryotaro.dev/posts/training_complex_models_with_multi_task_weak_supervision/</link>
      <pubDate>Sat, 28 Sep 2019 14:53:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/training_complex_models_with_multi_task_weak_supervision/</guid>
      <description>&lt;p&gt;論文の表題は、ソース間の粒度や精度が揃っていることを前提とせず、&lt;a href=&#34;https://arxiv.org/pdf/1212.0478.pdf&#34;&gt;LohとWainwrightらの手法&lt;/a&gt;でソースの精度を推定し、ソースのラベルよりも精度が高いラベルをデータに与えるWeak supervsionの手法である。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Snorkel: Rapid Traning Data Creation with Weak Supervision</title>
      <link>https://nryotaro.dev/posts/snorkel_rapid_training_data_creation_with_weak_supervision/</link>
      <pubDate>Sat, 21 Sep 2019 12:01:51 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/snorkel_rapid_training_data_creation_with_weak_supervision/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題の論文は、Weak supervisionの一種であるSnorkelを学習データの収集効率と予測性能についての既存手法や教師あり学習と比べた評価をまとめてる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Software Engineerng for Machine Learning: A Case Study</title>
      <link>https://nryotaro.dev/posts/software_engineering_for_machine_learning/</link>
      <pubDate>Sat, 14 Sep 2019 11:26:41 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/software_engineering_for_machine_learning/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題の論文は、マイクロソフトでのAIを応用したアプリケーションの開発についての調査結果をまとている。
著者らは、9人中の8名がMicrosoft Researchに所属し、本論文で2019年のICSEのSoftware Engineering in Practiceの分野でBest Paper Awardを受賞した。
主な貢献は、各チームにおける開発フローを9のステージに分けて解説したこと、機械学習を応用するアプリケーションやプラットフォームの開発におけるベストプラクティスを示したこと、機械学習を応用するアプリケーションの開発に固有の課題にまつわる論考の3つである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Class Imbalance, Redux</title>
      <link>https://nryotaro.dev/posts/class_imbalance_redux/</link>
      <pubDate>Sat, 07 Sep 2019 15:34:06 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/class_imbalance_redux/</guid>
      <description>&lt;p&gt;表題の論文は、不均衡データの特徴が二値分類の予測性能に及ぼす影響を理論づける論文である。
理論と実験を通じて、多くのケースにおいて、アンダーサンプリングによる均衡データのバギングで予測性能があがったことを示している。
バギングは、アンダーサンプリングによる偏りを抑えて予測性能を安定させるために使われる。
論文で扱うモデルは、SVMなどの学習で経験損失を最小化するモデルに限定されている。発表学会は2011年のICDMである。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Learning on the Border: Active Learning in Imbalanced Data Classification</title>
      <link>https://nryotaro.dev/posts/learning_on_border/</link>
      <pubDate>Sat, 31 Aug 2019 02:05:53 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_on_border/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、不均衡データの二値分類についての予測性能を能動学習で改善する手法を提案している。
着想は、学習器のマージン付近では正例と負例がよりバランスしていると仮定し、
マージン付近にあるデータを集めることで、均衡のとれたデータセットを用意することにある。
具体的には、ラベルづけしたデータでSVMをオンライン学習し、無作為に抽出されたラベルのないデータの中で最も超平面に近いデータにラベルをつける手順をマージンの中にあるデータ数が変わらなくなるまで繰り返す。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Distilling the Knowledge in a Neural Network</title>
      <link>https://nryotaro.dev/posts/distilling_the_knowledge_in_a_neural_network/</link>
      <pubDate>Sat, 24 Aug 2019 23:04:39 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/distilling_the_knowledge_in_a_neural_network/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にあるニューラルネットワークの蒸留についての論文を紹介する。
蒸留は、既存のモデルを使い、できるだけ予測性能を落とさずに、より小さいモデルを作るための学習手法である。
既存のモデルとして想定されているのは、複数のモデルからなるモデルや正則化された大きなモデルのように予測性能は高いが計算コストが高いものであり、
蒸留の目的は本番の運用に耐えられるデプロイ可能なモデル作ることにある。
本論文は、出力層の活性化関数に温度つきソフトマックスを使った多クラス分類のモデルを蒸留する手法を提案し、実験により手法を評価している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ FastXML: A Fast, Accurate and Stable Tree-classifier for eXtreme Multi-label Learning</title>
      <link>https://nryotaro.dev/posts/fastxml/</link>
      <pubDate>Sat, 24 Aug 2019 15:45:40 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/fastxml/</guid>
      <description>&lt;p&gt;表題にあるExtreme multi-label classificationの手法を紹介する。
Extreme multi-label classificationの目的は、大量のラベルの候補から与えられたデータに関連する複数のラベルを推定する学習器を構築することにある。
FastXMLは、弱学習器に決定木を使うアンサンブル学習であり、ノードの分割の評価関数にnDCGを採用することで、学習にかかる時間と予測精度の向上を意図している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Advantages and Disadvantages of a Monolithic Repository</title>
      <link>https://nryotaro.dev/posts/advantages_and_disadvantages_of_a_monolithic_repository/</link>
      <pubDate>Sat, 17 Aug 2019 14:49:48 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/advantages_and_disadvantages_of_a_monolithic_repository/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、マルチリポジトリと比べたときのモノリシックリポジトリの長所と短所の調べた論文のタイトルである。
論文は2018年のICSEでGoogleから発表された。
調査方法はGoogle社のエンジニアへのアンケートとエンジニアの行動ログの分析が採用されている。
Googleではモノリシックリポジトリが採用されており、エンジニアがこれまで経験したマルチリポジトリが比較対象となっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ CatBoost: unbaiased boosting with categorical features</title>
      <link>https://nryotaro.dev/posts/cat_boost/</link>
      <pubDate>Sat, 10 Aug 2019 23:27:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/cat_boost/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題はNeurIPS 2018で発表されたCatBoostという勾配ブースティングの手法を論文にちなむ。
Target Statisticsというカテゴリカル特徴量の前処理と勾配ブースティングの学習時に生じる一種のleakageが起きることを示し、leakageをさけて前処理と学習をする手法を示した。
CatBoostは二進木の決定木を弱識別器に用いる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Are We Really Making Much Progress? A Worring Analysis of Recent Neural Recomendation Approaches</title>
      <link>https://nryotaro.dev/posts/are_we_really_making_much_progress/</link>
      <pubDate>Sat, 10 Aug 2019 14:39:11 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/are_we_really_making_much_progress/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、ニューラルネットワークを用いた推薦システムを提案、評価した論文における実験の再現性と予測性能の再評価した論文のタイトルにあたる。
発表学会は、2019年のRecSys。著者らは、以下の2つのRQに回答するためにトップ会議で発表された18の論文を調査した。その結果、実験を再現できた論文は7稿であり、その中でも単純な手法を上回る性能が認められたのは1稿だけだった。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RQ1: ニューラルネットワークを用いた推薦システムの研究の再現性はどの程度か&lt;/li&gt;
&lt;li&gt;RQ2: 最近発表されたアルゴリズムは、ハイパーパラメタチューニングされた単純な手法と比べてどの程度性能がいいか&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>メモ Gaussian Processes for Regression</title>
      <link>https://nryotaro.dev/posts/gaussian_processes_for_regression/</link>
      <pubDate>Sat, 03 Aug 2019 21:54:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/gaussian_processes_for_regression/</guid>
      <description>&lt;p&gt;表題はガウス過程の回帰問題への応用を提案した論文。著者らは、scikit-learnの&lt;a href=&#34;https://scikit-learn.org/stable/modules/gaussian_process.html#gaussian-process&#34;&gt;ガウス過程回帰&lt;/a&gt;の
元になっている&lt;a href=&#34;http://www.gaussianprocess.org/gpml/chapters/RW.pdf&#34;&gt;Gaussian Processes for Machine Learning&lt;/a&gt;の著者と同じ。
論文の構成は、ガウス過程回帰の予測分布の式、ハイパーパラメタ推定方法、実験による評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Google Vizier: A Service for Black-Box Optimization</title>
      <link>https://nryotaro.dev/posts/google_vizier/</link>
      <pubDate>Sat, 03 Aug 2019 17:18:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/google_vizier/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にあるVizierはGoogleにおいてデファクトになっているブラックボックス最適化のためのサービスであり、
論文は、Vizierのシステムアーキテクチャの構成とアルゴリズムの説明とその評価からなる。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Learning Active Learning from Data</title>
      <link>https://nryotaro.dev/posts/learning_active_learning_from_data/</link>
      <pubDate>Sat, 27 Jul 2019 16:40:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/learning_active_learning_from_data/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、次にラベルを与えるべきデータが何かという能動学習における問題を、
あるサンプルを教師データに追加したときの損失関数の減少値を予測する回帰の問題としてとらえる。
能動学習の目的は最小限データで最大の予測性能をもつモデルを構築することであり、次にアノテーションすべきデータが何かを正しく予測することが課題になる。
論文は、アノテーションすべきサンプルを予測する回帰モデルを学習するアルゴリズムを提案、評価する。アルゴリズムは2値分類の分類器を対象としている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 TextRank: Bringing Order into Texts</title>
      <link>https://nryotaro.dev/posts/textrank/</link>
      <pubDate>Sat, 20 Jul 2019 17:49:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/textrank/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題にある論文は、ドキュメントからキーワードとキーセンテンスを抽出するためのグラフベースのアルゴリズムTextRankを提案、評価した。
TextRankは、名前から推測できるようにPageRankを応用した手法であり、頂点の重要度を、頂点の内容のような局所的な情報ではなく、他の頂点との辺の接続関係を含むグラフ全体の大域的な情報から決定する。PageRankとTextRankのアルゴリズムの違いは、TextRankの場合は辺ごとに重みが設定できるところにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates</title>
      <link>https://nryotaro.dev/posts/subword_regularization/</link>
      <pubDate>Wed, 17 Jul 2019 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/subword_regularization/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題は、過去に&lt;a href=&#34;../neural_machine_translation_of_rate_words/&#34;&gt;紹介&lt;/a&gt;した&lt;a href=&#34;https://www.aclweb.org/anthology/P16-1162&#34;&gt;論文&lt;/a&gt;と同様、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）の元になった論文にあたる。
ノイズに対する頑強さのために、単語のサブワード（部分文字列）を生成するユニグラム言語モデルの学習方法と、モデルから生成されたサブワード列を入力とする機械翻訳モデルの学習方法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Neural Machine Trasnslation of Rare Words with Subword Units</title>
      <link>https://nryotaro.dev/posts/neural_machine_translation_of_rate_words/</link>
      <pubDate>Sat, 13 Jul 2019 17:19:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/neural_machine_translation_of_rate_words/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;内容は、sentencepiece（ニューラルネットワークを用いた言語処理向けのトークナイザ・脱トークナイザ）のトークナイズで使われるアルゴリズムになっている。単語をサブワード（単語の部分文字列）に分割し、サブワードを組み合わせて珍しい単語や未知語を表現することで、これらの出現頻度の低い単語の翻訳上げるというもの。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Embedding Logical Queries on Knowledge Graphs</title>
      <link>https://nryotaro.dev/posts/embedding_logical_queries_on_knowledge_graphs/</link>
      <pubDate>Sun, 17 Feb 2019 17:03:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/embedding_logical_queries_on_knowledge_graphs/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;一階述語論理式で表現されたクエリを満たすノードを、分散表現に変換し、ナレッジグラフの中から計算時間上効率よく見つけるアルゴリズムを提案した。
クエリに現れるエッジの数に対して計算時間が線形であることが特徴。
ただし、クエリには、存在量化と連接を使えるが、全称量化、選択、否定を使うことができない制約がある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Regularizing and Optimizing LSTM Language Models</title>
      <link>https://nryotaro.dev/posts/regularizing_and_optimizing_lstm_language_models/</link>
      <pubDate>Fri, 23 Nov 2018 19:27:00 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/regularizing_and_optimizing_lstm_language_models/</guid>
      <description>&lt;p&gt;本稿は、LSTMを用いた言語モデルに対して正規化と最適化を適用し、実験を通して既存の先行研究とperplexityの観点で予測性能を評価した。本稿の手法の利点は、LSTMの実装に変更を加えずに適用できるために、NVIDIA cuDNNなどの高速でブラックボックスなライブラリで実装できることにある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Deep Joint Entity Disambiguation with Local Neural Attention</title>
      <link>https://nryotaro.dev/posts/deep_joint_entity_disambiguation/</link>
      <pubDate>Fri, 09 Nov 2018 21:11:50 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deep_joint_entity_disambiguation/</guid>
      <description>&lt;p&gt;本稿は、当ページで紹介した&lt;a href=&#34;https://aclweb.org/anthology/K18-1050&#34;&gt;End-to-End Neural Entity Linking&lt;/a&gt;(End-to-End) の著者らの先行研究にあたる。
End-to-EndがEntity LinkingのMention Detection(MD)とEntity Disambiguation(ED)の両方をアプローチの対象にしているのに対し、本稿ではEDのみが対象となっている。
したがって、文章からmention（参照表現）が抽出されていることが前提にあり、提案の中心は、参照表現に対応するエンティティを候補の中から正しく求める手法にある。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ End-to-end Neural Entity Linking</title>
      <link>https://nryotaro.dev/posts/end_to_end_neural_entity_linking/</link>
      <pubDate>Fri, 02 Nov 2018 16:59:14 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/end_to_end_neural_entity_linking/</guid>
      <description>&lt;h3 id=&#34;背景&#34;&gt;背景&lt;/h3&gt;

&lt;p&gt;本稿は、End to EndなEntity Linkingモデルのアーキテクチャを提案し、予測性能の評価実験で有用性を評価した。
実験のデータセットには、Entity annotationの評価に使える様々なデータセットを集めた&lt;a href=&#34;https://github.com/dice-group/gerbil/wiki&#34;&gt;Gerbil Platform&lt;/a&gt;が使われている。そのうちの&lt;a href=&#34;https://natural-language-understanding.fandom.com/wiki/AIDA-CoNLL&#34;&gt;AIDA/CoNLL&lt;/a&gt;データセットにおいて、提案手法は既存手法を超える予測性能を発揮した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>DeepType: Multilingual Entity Linking by Neural Type System Evolution(2018)</title>
      <link>https://nryotaro.dev/posts/deeptype/</link>
      <pubDate>Fri, 26 Oct 2018 20:53:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/deeptype/</guid>
      <description>&lt;p&gt;本稿は、既存のオントロジから型システムを構築するアルゴリズムと型システムによるEntity Linking(EL)を提案した。実験を通じて既存手法と比較し、精度の向上を確認した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
      <link>https://nryotaro.dev/posts/conditional_random_fields_probabilistic_models_for_segmenting_and_labeling_sequence/</link>
      <pubDate>Fri, 12 Oct 2018 18:39:08 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/conditional_random_fields_probabilistic_models_for_segmenting_and_labeling_sequence/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;本稿は、条件付き確率場（Conditional Random Fields, CRF）を提案し、品詞タグづけにおけるerror rateをもとに評価した。
評価の比較対象には、Maximum entropy Markov models(MEMMs)が採用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Bidirectional LSTM-CRF Models for Sequence Tagging</title>
      <link>https://nryotaro.dev/posts/bidirectional_lstm_crf_models_for_sequence_tagging/</link>
      <pubDate>Fri, 05 Oct 2018 18:46:36 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/bidirectional_lstm_crf_models_for_sequence_tagging/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;本稿では、NLPにおける系列ラベリングためのニューラルネットワークアーキテクチャの提案と評価がなされている。
このアーキテクチャは、当ページで以前紹介した&lt;a href=&#34;https://aclweb.org/anthology/papers/C/C18/C18-1139/&#34;&gt;Contextual String Embeddings for Sequence Labeling&lt;/a&gt;で応用されている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Contextual String Embeddings for Sequence Labeling</title>
      <link>https://nryotaro.dev/posts/context_string_embeddings_for_sequence_labeling/</link>
      <pubDate>Fri, 28 Sep 2018 16:29:46 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/context_string_embeddings_for_sequence_labeling/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;表題の論文は、ライブラリflairのアルゴリズムを提案、評価したもの。&lt;/p&gt;

&lt;p&gt;論文は、テキストの系列ラベリングに向いた単語の分散表現モデルを提案し、
提案手法が予測性能において既存手法より優れいたことを実験的に示した。
本手法における単語の分散表現は、単語の字面だけでなく、文中における単語の出現位置によって決まる。
いいかえると、同じ単語であっても、文中における出現位置が異なれば、単語は異なる分散表現に変換される。
著者らは、分散表現に文脈の情報を含められることを強調して、提案手法をContextual String Embeddingsと名付けた。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ Universal Language Model Fine-tuning for Text Classification</title>
      <link>https://nryotaro.dev/posts/universal_language_model_fine_tuning_for_text_classification/</link>
      <pubDate>Fri, 14 Sep 2018 16:33:43 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/universal_language_model_fine_tuning_for_text_classification/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;UMLFiTという、様々なNLPの問題に適用可能なファインチューニングの手法を提案、評価した。
評価手段として、6種のテキスト分類のタスクにおける既存手法とのエラー率の比較が採られている。
主要な評価として、100件のラベル付きデータだけでその100倍のデータを要した事前学習を用いない手法と同等の予測性能が出たことを報告している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ metapath2vec: Scalable Representation Learning for Heterogeneous Networks</title>
      <link>https://nryotaro.dev/posts/metapath2vec/</link>
      <pubDate>Fri, 07 Sep 2018 18:31:47 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/metapath2vec/</guid>
      <description>&lt;p&gt;異種混合ネットワークから、ノード数x次元数の分散表現を獲得するための手法。
異種混合とは、企業、業界、ニュースなど複数の種類の概念がグラフのノードとして扱われていることを意味する。
獲得した分散表現を訓練データとして分類、クラスタリング、検索に応用し、既存手法と比較している。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Applying Deep Learning To Airbnb Search</title>
      <link>https://nryotaro.dev/posts/applying_deep_learning_to_airbnb_search/</link>
      <pubDate>Fri, 31 Aug 2018 19:21:10 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/applying_deep_learning_to_airbnb_search/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;論文では、Airbnbが深層学習を宿泊先検索に適用した時の試行錯誤と結果を紹介している。
採用したモデルのアルゴリズムと特徴量エンジニアリングの説明が本稿の大部分を占める。
深層学習を試す以前はGBDTを採用おり、以下の順にアルゴリズムを変えていった。
当初は、アルゴリズムを段階的に高度にしていくつもりはなく、1.以前には複雑なアルゴリズムをいきなり試したが、失敗に終わっている。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>メモ The Relationship Between Precision-Recall and ROC Curve</title>
      <link>https://nryotaro.dev/posts/the_relationship_between_precision_recall_and_roc_curve/</link>
      <pubDate>Sat, 25 Aug 2018 00:56:13 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/the_relationship_between_precision_recall_and_roc_curve/</guid>
      <description>ROCとPrecision Recallの関係を示した論文。
 1 Recallが0でなければ、ROC曲線には一対一に対応するPR曲線がある。 2 PR曲線AがPR曲線Bに対して常に優位であることとは、ROC曲線においてAがBより常に優位であることの必要十分条件。 3 1,2よりROC空間上の凸包に対応するPR曲線は、他の妥当なPR曲線よりも優位な曲線になる。 4 線形補間でROC曲線を描くことは妥当。一方で、Recallの分母は固定値であるが、Precisionの分母の値はRecallが上がると増える。そのため、PR曲線を線形補間でプロットすると、評価の甘い曲線になる。  論文はこちらからダウンロードできます。</description>
    </item>
    
    <item>
      <title>メモ Enriching Word Vectors with Subword Information</title>
      <link>https://nryotaro.dev/posts/enriching_word_vectors_with_subword_information/</link>
      <pubDate>Fri, 10 Aug 2018 17:29:44 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/enriching_word_vectors_with_subword_information/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;Fasttextを提案、評価した論文。
Character n-gramsを入力としてskip-gramのモデルを作る方法を提案、評価している。
単語の部分文字列（subword）を使わない手法や形態素解析に頼る手法よりも提案手法が優れていることを実験で示した。
部分文字列のベクトルの和が単語のベクトルとなる。
実験の考察では、そのために、未知語の部分文字列が学習データにあれば、未知語に対しても妥当な分散表現を与えることができるとあった。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 When Do Chagnes Induce Fixes?</title>
      <link>https://nryotaro.dev/posts/when_do_changes_induce_fixes/</link>
      <pubDate>Fri, 03 Aug 2018 21:47:03 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/when_do_changes_induce_fixes/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;ざっくり言うと、バージョン管理ツールとバグチケット管理ツールを導入しているプロジェクトにおいて、
バージョン管理ツールで追跡されている変更とバグチケット管理ツールで追跡されているバグを紐付ける手法を提案した。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 A Simple Semi-supervised Algorithm For Named Entity Recognition</title>
      <link>https://nryotaro.dev/posts/a_simple_semi_supervised_for_ner/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/a_simple_semi_supervised_for_ner/</guid>
      <description>&lt;h3 id=&#34;概要&#34;&gt;概要&lt;/h3&gt;

&lt;p&gt;CRFに入力する学習データを集めるための半教師学習の手法を提案と評価した論文。
本手法はCRFに与える学習データを集めるための手法であり、CRFのアルゴリズム自体に変更を加えることはない。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>要約 Applying Conditional Random Fields to Japanese Morphological Analysis</title>
      <link>https://nryotaro.dev/posts/applying_crf_to_japanese_morph_analysis/</link>
      <pubDate>Tue, 17 Jul 2018 12:51:29 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/applying_crf_to_japanese_morph_analysis/</guid>
      <description>&lt;p&gt;Mecabの中の人の&lt;a href=&#34;http://chasen.naist.jp/chaki/t/2009-09-30/doc/mecab-cabocha-nlp-seminar-2009.pdf&#34;&gt;資料&lt;/a&gt;で紹介でされている、Mecabのアルゴリズムを提案・評価した論文。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>概要 Text Classification from Labeled and Unlabeled Documents using EM</title>
      <link>https://nryotaro.dev/posts/text_cls_from_lbl_and_unlbl_doc_em/</link>
      <pubDate>Sun, 08 Jul 2018 01:23:49 +0900</pubDate>
      
      <guid>https://nryotaro.dev/posts/text_cls_from_lbl_and_unlbl_doc_em/</guid>
      <description>&lt;h3 id=&#34;アルゴリズム&#34;&gt;アルゴリズム&lt;/h3&gt;

&lt;p&gt;提案手法は、Naive BayesとEMアルゴリズムを組み合わせたもの。
ラベル付きデータが\(D^l\)でラベルなしデータが\(D^u\)で表されるとき、対数尤度\(\log P(D^l)P(D^u)\)を最大化する問題を解く。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>