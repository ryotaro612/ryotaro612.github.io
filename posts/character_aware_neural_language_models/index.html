<!DOCTYPE html>
<html>
  <head>
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://nryotaro.dev/scss/base.min.87b8f4076c47000c129b0c8b240a71216448e3aedd7144174c55776680a783b0.css">
    

<link rel="stylesheet" href="https://nryotaro.dev/scss/single.min.78272bdd99a3c4f03ee4c826bbe3a970cda497ed85b5da23b0af6dbaf9f30522.css">

<link rel="stylesheet" href="https://nryotaro.dev/scss/posts/single.min.c8bed992e3e72febf0bd227ae4d39d51e4a5a169e0a19ca4cef950e3ab79cfe0.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    <title>論文メモ Character-Aware Neural Language Models</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="/about">About me</a></li>
          <li><a href="/posts">Posts</a></li>
          <li><a href="/tags">Tags</a></li>
        </ul>
      </nav>
    </header>
    
<main>
  <h1>論文メモ Character-Aware Neural Language Models</h1>
  <ul class="tags">
    
  </ul>  
  <span class="date">April 4, 2020</span>    
  <div>
    <h3 id="概要">概要</h3>
<p>文字単位の入力から次に出現する単語を予測するニューラル言語モデルの論文である。
アーキテクチャは入力から近い順にCNN, highway network, LSTMからなる。
実験データにPenn Treebankを、評価指標にPerplexityを採用してモデルを評価したところ、
論文が発表された2016年時点での<a href="https://arxiv.org/abs/1409.2329">SOTA</a>の60%程度のパラメタしかないモデルでありながら、これに匹敵する性能を発揮した。</p>
<h3 id="アーキテクチャ">アーキテクチャ</h3>
<p>モデルは、文字列を単位とする入力をうけつける。
モデルのアーキテクチャを図に示す。
入力に近い層から順にCNN, highway network, LSTMの順に説明していく。
<img src="/character_aware_neural_language_models.png" alt="img"></p>
<h4 id="cnn">CNN</h4>
<p>\(d\)を文字の分散表現の次元として、長さ\(l\)の単語\(k\)は\({\rm C}^{d\times l}\in \mathbb{R}^{d \times l}\)の分散表現としてモデルに入力される。
入力された分散表現に幅\(w\)のフィルタ\(\boldsymbol{\rm H}\in \mathbb{R}^{d \times w}\)を適用しnarrow conlovutionによって、特徴マップ\(\boldsymbol{\rm f}^k\in \mathbb{R}^{l-w+1}\)を求める。
\(\boldsymbol{\rm C}^k[*, i:i+w-1]\)を単語\(k\)の分散表現\(\boldsymbol{\rm C}^k\)の\(i\)から\(i+w-1\)までの列とすると、\(i\)番目の要素は次の式で計算される。</p>
<p>$$
\boldsymbol{\rm f}^k[i] = \tanh (\text{Tr}(\boldsymbol{\rm C}^k[*, i:i+w-1] \boldsymbol{\rm H}^T) + b)
$$</p>
<p>MAXプーリングにより各フィルタからスカラー値\(y^k\)を求める。アーキテクチャ全体ではフィルタを\([100, 1000]\)の範囲の複数のフィルタ\(\boldsymbol{\rm H}_1 ,\dots \boldsymbol{\rm H}_h\)をつかう。
このとき、単語\(k\)に対して\(\boldsymbol{y}^k=[y_1^k , \dots y_h^k]\)がhighway networkにわたされる。</p>
<p>$$
y^k=\max_i \boldsymbol{\rm f}^k[i]
$$</p>
<h4 id="highway-network">Highway Network</h4>
<p>CNNの出力をhighway networkに入力し、次の\(\boldsymbol{\rm z}\)を計算する。
$$
\boldsymbol{\rm z}=\boldsymbol{\rm t}\odot g(\boldsymbol{\rm W}_H \boldsymbol{\rm y} + \boldsymbol{\rm b}_H) + (\boldsymbol{1} - \boldsymbol{\rm t}\odot \boldsymbol{\rm y})
$$
ただし、\(\boldsymbol{\rm t}=\sigma (\boldsymbol{\rm W}_T\boldsymbol{\rm y} + \boldsymbol{\rm b}_T)\)であり、これをtransform gateという。
\(\boldsymbol{1}-\boldsymbol{\rm t}\)はcarry gateとよばれ、LSTMのメモリセルと同じく、入力を適応的にそのまま出力するはたらきがある。</p>
<h4 id="lstm">LSTM</h4>
<p>時刻\(t\)のhighway networkの出力\(\boldsymbol{\rm z}_t\in \mathbb{R}^n\)はLSTMに入力され、LSTMは次の計算により\(\boldsymbol{\rm h}_t\in \mathbb{R}^m\)を出力する。
複数のLSTMを重ねるときは、\(\boldsymbol{\rm h}_t\)を次のLSTMにわたす。</p>
<p>$$
\begin{align}
\boldsymbol{\rm i}_t &amp;= \sigma(\boldsymbol{\rm W}^i\boldsymbol{\rm z}_t + \boldsymbol{\rm U}^i\boldsymbol{\rm h}_{t-1}+\boldsymbol{\rm b}^i)\\
\boldsymbol{\rm f}_t &amp;= \sigma(\boldsymbol{\rm W}^f\boldsymbol{\rm z}_t + \boldsymbol{\rm U}^f\boldsymbol{\rm h}_{t-1}+\boldsymbol{\rm b}^f)\\
\boldsymbol{\rm o}_t &amp;= \sigma(\boldsymbol{\rm W}^o\boldsymbol{\rm z}_t + \boldsymbol{\rm U}^o\boldsymbol{\rm h}_{t-1}+\boldsymbol{\rm b}^o)\\
\boldsymbol{\rm g}_t &amp;= \tanh(\boldsymbol{\rm W}^g\boldsymbol{\rm z}_t + \boldsymbol{\rm U}^g\boldsymbol{\rm h}_{t-1}+\boldsymbol{\rm b}^g)\\
\boldsymbol{\rm c}_t &amp;= \boldsymbol{\rm f}_t \odot \boldsymbol{\rm c}_{t-1} + \boldsymbol{\rm i}_t \odot \boldsymbol{\rm g}_t \\
\boldsymbol{\rm h}_t &amp;= \boldsymbol{\rm o}_t \odot \tanh (\boldsymbol{\rm c}_t)
\end{align}
$$</p>
<h4 id="出力層">出力層</h4>
<p>LSTMの出力\(\boldsymbol{\rm h}_t\)を全結合層とソフトマックス関数に入力し、単語列\(w_{1:t}=[w_1, \dots w_t]\)から次の単語\(w_{t+1}\)を予測する。</p>
<p>$$
\text{Pr}(w_{t+1}=j\mid w_{1:t}) = \frac{\exp (\boldsymbol{\rm h}_t \cdot \boldsymbol{\rm p}^j + q^j)}{\sum_{j'\in \mathcal{V}}\exp (\boldsymbol{\rm h}_t \cdot \boldsymbol{\rm p}^{j'}+ q^{j'})}
$$</p>
<p>\(\mathcal{V}\)は単語の集合をさす。
単語数\(\mid\mathcal{V}\mid\)が多い場合、階層的ソフトマックスをもちいる。
\(\mathcal{V}\)を\(c=\lceil\sqrt{\mid\mathcal{V}\mid} \rceil\)として\(\mathcal{V}_1,\dots \mathcal{V}_c\)に分割し、次のように予測する。</p>
<p>$$
\begin{align}
\text{Pr}(w_{t+1} = j\mid w_{1:t}) &amp;= \frac{\exp (\boldsymbol{\rm h}_t\cdot \boldsymbol{\rm s}^r + t^r)}{\sum^c_{r'=1}\exp (\boldsymbol{\rm h}_t \cdot \boldsymbol{\rm s}^{r'}+ t^{r'})} \\
&amp;\times \frac{\exp (\boldsymbol{\rm h}_t\cdot \boldsymbol{\rm p}_r^j + q_r^j)}{\sum_{j'\in\mathcal{V}_r}\exp (\boldsymbol{\rm h}_t \cdot \boldsymbol{\rm p}_r^{j'}+ q_r^{j'})}
\end{align}
$$</p>
<h4 id="損失関数">損失関数</h4>
<p>損失関数にはnegative log-likelihood(NLL)をもちいる。</p>
<p>$$
NLL = - \sum_{t=1}^T \log \text{Pr}(w_t\mid w_{1:t-1})
$$</p>
<h3 id="備考">備考</h3>
<p>提案された言語モデルは、<a href="https://arxiv.org/abs/1802.05365">ELMo</a>で応用された。
以前、<a href="./deep_contextualized_word_representations/">こちら</a>にELMoの内容をまとめた。</p>
<h3 id="感想">感想</h3>
<p>初学者が勉強のために読むにはいい論文だと思った。
LSTM, CNN, 階層的ソフトマックス, Perplexityなどの広く応用されている手法を多く導入しているだけでなく、数式を含めた説明が十分にある。</p>
<hr>
<ul>
<li>論文は<a href="https://arxiv.org/abs/1508.06615">こちら</a>からダウンロードできます。</li>
<li>画像はすべて論文から引用されています。</li>
</ul>
  </div>
</main>

    
<ul class="pagination">
    
    <li>
      <a href="/posts/deep_contextualized_word_representations/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/posts/domain_adversarial_training_of_neural_networks/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    
</ul>


    <footer>
      <ul>
        
        <li>
          <a href="https://github.com/nryotaro">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
        
      </ul>
      <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
