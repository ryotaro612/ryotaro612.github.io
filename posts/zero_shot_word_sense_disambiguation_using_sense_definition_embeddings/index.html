<!DOCTYPE html>
<html>
  <head>
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://nryotaro.dev/scss/base.min.87b8f4076c47000c129b0c8b240a71216448e3aedd7144174c55776680a783b0.css">
    

<link rel="stylesheet" href="https://nryotaro.dev/scss/single.min.78272bdd99a3c4f03ee4c826bbe3a970cda497ed85b5da23b0af6dbaf9f30522.css">

<link rel="stylesheet" href="https://nryotaro.dev/scss/posts/single.min.c8bed992e3e72febf0bd227ae4d39d51e4a5a169e0a19ca4cef950e3ab79cfe0.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>    
    
    <title>論文メモ Zero-shot Word Sense Disambiguation using Sense Definition Embeddings</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="/about">About me</a></li>
          <li><a href="/posts">Posts</a></li>
          <li><a href="/tags">Tags</a></li>
        </ul>
      </nav>
    </header>
    
<main>
  <h1>論文メモ Zero-shot Word Sense Disambiguation using Sense Definition Embeddings</h1>
  <ul class="tags">
    
  </ul>  
  <span class="date">October 30, 2020</span>    
  <div>
    <p>語義曖昧性解消のためのアーキテクチャ, Extended WSD Incorporating Sense Embeddings(EWISE)を発表した。
EWISEは単語の意味をアノテーションしあテキストと辞書を教師データにもちいる。
実験では、辞書にWordNetをつかい、概念同士の上下関係や関係を示す分散表現を獲得する。
学習であたえられていない意味を推定するために、離散値ではなく分散表現でラベルの意味を表現する。</p>
<h3 id="アーキテクチャ">アーキテクチャ</h3>
<p><img src="/ewise.png" alt="img"></p>
<h4 id="atentive-context-encoder">Atentive Context Encoder</h4>
<p>Attentive Context Encoderは、入力文を、意味の分散表現のある空間のベクトルに写像する。
はじめに、入力文\(&lt;x^1 \dots x^T&gt;\)を2層の双方向LSTMと注意機構にあたえて文脈依存の分散表現をつくる。
双方向LSTMの順方向の出力を\(h^i_f\)逆方向の出力を\(h^i_b\)とすると注意機構を出力は次の\(r^i\)になる。
\(d_k\)は\(W_qu^i\)や\(W_ku^t\)の次元数をしめす。</p>
<p>$$
u^i=[h^i_f,h^i_b]
$$</p>
<p>$$
\begin{align}
e^i_t&amp;=\text{dot}(W_qu^i,W_ku^t);t\in [1, T]\\\
a^i&amp;=\text{softmax}\left(\frac{e^i}{\sqrt{d_k}}\right)\\\
c^i&amp;=\sum_{t\in [1,T]}a^i_tW_vu^t\\\
r^i&amp;=[u^i, c^i]
\end{align}
$$</p>
<p>\(r^i\)を意味の分散表現に射影する全結合層にあたえ、意味の分散表現\(v^i\)をえる。</p>
<p>$$
v^i=W_lr^i
$$</p>
<h4 id="definition-encoder">Definition Encoder</h4>
<p>単語の定義を2層の双方向LSTMにあたえ、その出力にMax Poolingを適用し、単語の定義をしめす固定長の分散表現を獲得する。
Max PoolingではLSTMの出力について、各次元の最大値を選択する。
以降、Encoderを\(q(\cdot)\)と表記する。</p>
<h4 id="knowledge-graph-embedding">Knowledge Graph Embedding</h4>
<p>ナレッジグラフは上位概念\(h\)と下位概念\(t\)の間に関係\(l\)を定義し、学習ではこの3つを示す分散表現\(e_h\), \(e_l\), \(e_t\)を獲得する。
\(f(x)\)を正規化線形関数\(f(x)=\max (0, x)\)、\(\bar{q(h)}\), \(\bar{e_l}\)をそれぞれベクトルを行列に変換、\(\text{vec}\)を行列からベクトルに変換する操作として、次の損失関数\(L_C\)で\(e_{\{h,l,t\}}\)学習する。</p>
<p>$$
\begin{align}
\psi_l(e_h, e_t)&amp;=f(\text{vec}(f([\bar{q(h)};\bar{e_l}]*w))W)e_t\\\
p&amp;=\sigma(\psi_l(e_h,e_t))\\\
L_C&amp;=-\frac{1}{N}\sum_i(t_i\log(p_i) + (1-t_i)\log(1-p_i))
\end{align}
$$</p>
<p>ただし、\(t_i\)は\(h, l, t\)が定義されているときのみ\(1\)、それ以外では\(0\)になる。</p>
<h4 id="wsd">WSD</h4>
<p>Knowledge graphの学習で獲得した概念の集合を\(S\), \(b\)をパラメタとして、単語の意味上の空間に写像された入力文に対して、ナレッジグラフ上の単語の概念を推定できるように学習する。
ただし、\(z^i\)は\(S\)上の意味を示すone-hotベクトルである。</p>
<p>$$
\begin{align}
\hat{p}_j^i&amp;=\text{softmax}(\text{dot}(v^i,\rho_j)+\text{dot}(b,\rho_j));\rho\in S\\\
L^i_{wsd}&amp;=-\sum_j(z^i_j\log(\hat{p}^i_j))
\end{align}
$$</p>
<p>推定時は次の式をもちいる。
推定する\(\hat{y}^i\)は\(S\)の要素である。</p>
<p>$$
\hat{y}^i=\underset{j}{\operatorname{argmax}}(\text{dot}(v^i, \rho_j)+\text{dot}(b,\rho_j)); \rho_j \in S_{x^i}
$$</p>
<hr>
<ul>
<li>論文を<a href="https://www.aclweb.org/anthology/P19-1568.pdf">こちら</a>からダウンロードできます。</li>
</ul>
  </div>
</main>

    
<ul class="pagination">
    
    <li>
      <a href="/posts/simple_testing_can_prevent_most_critical_failures/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/posts/dynamo_amazons_highly_available_key_value_store/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    
</ul>


    <footer>
      <ul>
        
        <li>
          <a href="https://github.com/nryotaro">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
        
      </ul>
      <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
