<!DOCTYPE html>
<html>

<head>
	<meta name="generator" content="Hugo 0.68.3" />
    
<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-W5TDG76');</script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
        integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
        crossorigin="anonymous" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="/css/base.css">
    
    <link rel="stylesheet" href="/css/articles.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://kit.fontawesome.com/4e0e0c0a41.js" crossorigin="anonymous"></script>
    <title>Blanket</title>
</head>

<body>
    
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

    <header class="navigation">
        <h2><a href="/">Blanket</a></h2>
        <nav>
            <ul>
                <li><a href="/about">About me</a></li>
                <li><a href="/posts">Posts</a></li>
                <li><a href="/gallery">Gallery</a></li>
            </ul>
        </nav>
    </header>
    
<main>
    <h1>Posts</h1>

    
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/pegasos/">Pegasos: Primal Estimated sub-GrAdient SOlver for SVM</a></h3>
        <div class="summary"><p>Pegasosは、SVMの学習のための反復的なアルゴリズムであり、2022年3月現在、scikit-learnの<a href="https://scikit-learn.org/stable/modules/sgd.html#implementation-details">SGDClassifier</a>で学習率を更新に採用されている。
Pegasosは、目的関数の最小値の近似値をもとめる。
求める最小値との誤差を\(\epsilon\), SVMの正則化パラメタを\(\lambda\), 各サンプルの説明変数の0でない要素数の上限を\(d\)とすると、線形カーネルをつかうSVMの時間計算量は、\(\tilde{O}(d/\lambda \epsilon)\)になる。
訓練データの数が計算量に影響しないので、教師データの数に対してスケールする。</p></div>
        <div class="article-footer">
            <span class="date">March 12, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/an_interior_point_method_for_large_scale_l1_regularized_least_squares/">An Interior-Point Method for Large-Scale L1-Regularized Least Squares</a></h3>
        <div class="summary"><p>前処理付共役勾配法により、スパースな説明変数をもつリッジ回帰の学習を高速化する。
リッジ回帰の目的関数は、凸関数だが微分可能ではない。
また、リッジ回帰の係数はスパースになりやすい。
そこで、目的関数を最小化する係数の探索を、線形不等式制約つきの凸二次計画問題とらえ、前処理付共役勾配法をつかった内点法で係数の更新方向を探索する。</p></div>
        <div class="article-footer">
            <span class="date">March 5, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/regularization_paths_for_generalized_liner_models_via_coordinate_descent/">Regularization Paths for Generalized Linear Models via Coordinate Descent</a></h3>
        <div class="summary"><p>ラッソ、リッジ、またはその両方をくみあわせたelastictnetを正則化項にもつ一般化線形モデルの学習を高速化する座標降下法である。
座標降下法を単純に実装すると、スパースで次元数の多い特徴だと学習に時間がかかる。
表題の手法は、その単純なパラメタの更新式の一部を、説明変数の内積におきかえ、学習データの数や次元数に対して学習時間を短縮する。</p></div>
        <div class="article-footer">
            <span class="date">February 19, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/using_tfidf_to_determine_word_relevance_in_document_queries/">Using TF-IDF to Determine Word Relevance in Document Queries(2003)</a></h3>
        <div class="summary"><p>自然言語のクエリで文書を検索する問題に、TF-IDFをベースラインにつかう利点と欠点を調べた。
クエリにある各単語のTF-IDF値の総和が最大化の文書を最も関連する文書とみなす。
実験では、TFのみで検索する手法よりも予測性能がよかったが、類義語同士の同一判定をできない問題があった。</p></div>
        <div class="article-footer">
            <span class="date">February 19, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/an_algorithm_for_suffix_stripping/">An algorithm for suffix stripping (1980)</a></h3>
        <div class="summary"><p>Poterのステミングで知られる。
アルゴリズムが単純で、辞書を必要としないところに特徴がある。
単語の接尾辞を規則にしたがい段階的に変換し、変換後の文字列を語幹とみなす。</p></div>
        <div class="article-footer">
            <span class="date">February 11, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/bringing_gnu_emacs_to_native_code/">Bringing GNU Emacs to Native Code</a></h3>
        <div class="summary"><p>Emacs 28から利用できる<a href="https://gcc.gnu.org/onlinedocs/jit/">libgccjit</a>によるネイティブコンパイルの解説である。
パッケージアーカイブELPAにあるelisp-benchmarksによる比較ではバイトコンパイルよりも2.3倍から42倍の高速化を実現した。
ネイティブコンパイル時は、はじめに、Emacs Lispのコードをバイトコンパイラで、Emacs VM(Lisp Assembly Program, LAP)の中間表現に変換する。
つぎに、LAPをS式で静的単一代入形式の中間表現LIMPLEに変換する。
LIMPLEは、GCCの中間表現GIMPLEに由来し、ネイティブコンパイルの中核技術にあたる。
さいごに、LIMPLEをlibgccjitの中間表現に変換し、GCCでネイティブに実行可能なプログラムにコンパイルする。</p></div>
        <div class="article-footer">
            <span class="date">January 30, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/data_structure_for_text_sequence/">Data Structure for Text Sequences</a></h3>
        <div class="summary"><p>テキストエディタのためのデータ構造として、array, gap, list, line pointers, fixed size buffers, piece tablesを評価する。
とくに、Piece tablesを評価し詳しく解説する。
Piece tableはテキストを2つのバッファに記録する。
2つのバッファはfile buffer, add bufferで、file bufferは初期状態のテキストを保存し、add bufferはあらたに挿入された文字列を保存する追記のみのバッファである。
なまえのpieceはバッファの連続する部分文字列を意味する。
そして、pieceへのポインタのシーケンスがpiece tableである。
ポインタは、どちらのバッファか、参照する部分文字列の開始位置、長さの3つの情報からなる。</p></div>
        <div class="article-footer">
            <span class="date">January 29, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/semi_supervised_classification_with_graph_convolutional_networks/">SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS</a></h3>
        <div class="summary"><p>文書の特徴を点、引用などの関係を辺でしめしたグラフ構造に畳込みニューラルネットワークを適用する半教師あり学習で、ラベルのない文書は近くにある文書とおなじラベルになると仮定する。
<a href="https://mlg.eng.cam.ac.uk/zoubin/papers/zgl.pdf">Zhu et al.</a>にみられる先行研究は、辺の情報をニューラルネットワークにあたず、文書の特徴のみを入力していた。
表題の手法では、文書の特徴にくわえて隣接行列で表現した辺の情報もニューラルネットワークにあたえる。
グラフの辺の数に対して線形にスケールし、隠れ層でグラフの分散表現を獲得できる。</p></div>
        <div class="article-footer">
            <span class="date">January 21, 2022</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/dynamic_routing_between_capsules/">Dynamic Routing Between Capsules (2017)</a></h3>
        <div class="summary"><p>カプセルはおなじ層にあるニューロン(ユニット)をグループであり、カプセルの出力するベクトルは入力にある特定のエンティティの分散表現になる。
表題のdynamic routingは、カプセルの出力ベクトルを1つ上の層のどのカプセルに渡すべきかを学習する手法である。
これにより、プーリング層で失われるエンティティの空間上の位置情報をカプセルの出力するベクトルで表現できる。
実験では、2層の畳み込み層と1層の全結合層からなる浅いニューラルネットワークをMNISTに適用し、長さでエンティティが存在する確率を、向きでエンティティの特徴を表現できるベクトルを学習できることを示した。</p></div>
        <div class="article-footer">
            <span class="date">December 26, 2021</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://nryotaro.dev/posts/hierarchical_attention_networks_for_document_classification/">Hierarchical Attention Networks for Document Classification (2016)</a></h3>
        <div class="summary"><p>Hierarchical Attention Network(HAN)は、単語は文から文書は文からなりたつ文書の構造をアーキテクチャに反映し、単語の注意から文の注意を、文の注意から文書の注意を計算する。
順方向と逆方向の2つのGRUでエンコードした単語の分散表現から注意を計算し、文ごとに、単語の注意の重みつき和を計算し文の分散表現とする。
さらに、文の分散表現を別の順、逆方向GRUにあたえ、単語とおなじように各文の注意を計算し、その重みつき和を文書の分散表現としてあつかう。
最後に、文書の分散表現を全結合層に入力し、ソフトマックス関数で文書のクラスを推定する。
単語の文の注意を推定できるため、単語と文の2つの粒度で文書の重要な箇所を可視化することができる。</p></div>
        <div class="article-footer">
            <span class="date">December 26, 2021</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">
    
    
    <li>
        <a href="/page/2/"><span class="material-icons">chevron_right</span></a>
    </li>
    <li>
        <a href="/page/21/"><span class="material-icons">last_page</span></a>
    </li>
    
</ul>

    <footer>
        <ul>
            
            <li>
                <a href="https://github.com/nryotaro">
                    <i class="fab fa-github"></i>
                </a>
            </li>
            
            
            <li>
                <a href="https://www.linkedin.com/in/nakamura-ryotaro/">
                    <i class="fab fa-linkedin-in"></i>
                </a>
            </li>
            
            <li><a href="/index.xml"><i class="fas fa-rss"></i></a></li>
            
        </ul>
        <small>© Nakamura, Ryotaro. All Rights Reserved.</small>
    </footer>
</body>

</html>
