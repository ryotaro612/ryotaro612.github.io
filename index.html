<!DOCTYPE html>
<html lang="ja">

<head>
	<meta name="generator" content="Hugo 0.153.4">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.ja.min.66816a64bc4ce50ec1c4b76199ca9d69163fc8a69f7abc6ea758d1968d8618b0.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
<link
  rel="stylesheet"
  href="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css"
  integrity="sha384-WcoG4HRXMzYzfCgiyfrySxx90XSl2rxY5mnVY5TwtWE6KLrArNKn0T/mOgNL0Mmi"
  crossorigin="anonymous"
>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.js"
  integrity="sha384-J+9dG2KMoiR9hqcFao0IBLwxt6zpcyN68IgwzsCSkbreXUjmNVRhPFTssqdSGjwQ"
  crossorigin="anonymous">
</script>
<script
  defer
  src="https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/contrib/auto-render.min.js"
  integrity="sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh"
  crossorigin="anonymous"
  onload="renderMathInElement(document.body);">
</script>
<script>
  document.addEventListener("DOMContentLoaded", function() {
    renderMathInElement(document.body, {
      delimiters: [
        {left: '\\[', right: '\\]', display: true},  
        {left: '$$', right: '$$', display: true},    
        {left: '\\(', right: '\\)', display: false},  
        {left: '$', right: '$', display: false}  
      ],
      throwOnError : false
    });
  });
</script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/about">About</a></li>
        <li><a href="https://ryotaro.dev/posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/en/">en</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
  <h1>Posts</h1>
  
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/improving_language_understanding_by_generative_pre_training/">Improving Language Understanding by Generative Pre-Training (2018)</a></h3>
    <div class="summary"><p><a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a>は教師なしの事前学習であり、GPTシリーズの最初のモデルにあたる。
12の自然言語処理タスクのうち9つについて、事前学習したモデルの出力を1層の全結合層に入力するファインチューニングで、当時のSoTAを上まわる性能を発揮した。</p>
<p>ネットワークは、<a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">transformer</a>のデコーダーであり、<a href="https://arxiv.org/pdf/1706.03762">Attention Is All You Need</a>のエンコーダーは含まれない。
ファインチューニングでは、特徴の入力を事前学習のデータ形式に揃えることで、事前学習とファインチューニングの差異を埋める。
推論タスクであれば前提や仮定、テキストの類似性判定であれば比較する2つのテキストといった異種の特徴をデリミタで連結した系列を作り、モデルに入力する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/gpt/">
            #GPT
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        November 16, 2025 (Originally posted on August 7, 2020)</p>
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/deep-neural-networks-for-youtube-recommendations/">Deep Neural Networks for Youtube Recommendations (2016)</a></h3>
    <div class="summary"><p><a href="https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/45530.pdf">Deep Neural Networks for YouTube Recommendations</a>は2016年頃のYouTubeの推薦システムの解説であり、パラメタ数が10億の深層学習のモデルが使われている。
この数千億の学習データで訓練されたモデルはcandidate generationとrankingの2つのネットワークからなる。
candidate generationは、ユーザーのYoutube上の行動履歴から数百の推薦候補の動画を協調フィルタリングで選び出す。
協調フィルタリングは、視聴した動画のIDや検索クエリのトークンが要素のスパースなベクトルを連結し、ユーザーの埋め込みベクトルを作る。
rankingはcandidate generationで選ばれた動画の試聴時間を推定する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/recommendation/">
            #Recommendation
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 23, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/kademlia-a-peer-to-peer-information-system-based-on-the-xor-metric/">Kademlia: A Peer to Peer Information System Based on the Xor Metric (2002)</a></h3>
    <div class="summary"><p>peer-to-peerのファイル共有アプリケーション BitTorrentの分散ハッシュテーブル<a href="https://www.cs.helsinki.fi/u/lxwang/publications/P2P2013_13.pdf">Mainline DHT</a>は<a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">Kademlia</a>をもとに実装されている。
Kademilaのノードやキーには160ビットのIDが割り当てられ、2つのIDの排他的論理和を両者の距離とみなす。
ノードは、ノード内に保存されたIDに近い宛先に再帰的にRPCを送り、IDを検索する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/peer-to-peer/">
            #Peer-to-Peer
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 13, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/multi-probe-consistent-hashing/">Multi-probe consistent hashing (2015)</a></h3>
    <div class="summary"><p>Karger et al.による原典の<a href="https://www.cs.princeton.edu/courses/archive/fall09/cos518/papers/chash.pdf">Consistent Hashing</a>は、CDNやKVSのノードの負荷を分散するために、ノードとキーを単位区間のハッシュ値に写像し、ハッシュ値で比べたときの最近傍のノードにキーを割り当てる。
ノードの追加と削除を繰り返してもキーの保存数が均等になるように、1つのノードに複数のハッシュ値を割りあてる。
キーと最も近いハッシュ値のノードにキーを保存する。
ノードの負荷をノードに保存するキーの数とすると、最大の負荷と平均の負荷の比率を高確率(\(1-\frac{1}{n^{\Omega(1)}}\))で\(1+\epsilon\)に抑えるには、\(\Theta(\frac{\ln n}{\epsilon^2})\)のハッシュ値を各ノードに割り当てなければならず、空間計算量はノードの数より大きくなる。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/consistent-hashing/">
            #Consistent Hashing
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 6, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/infinispan/">Infinispanの分散キャッシュ</a></h3>
    <div class="summary"><p><a href="https://infinispan.org/">Inifinispan</a>は有償インメモリーデータベース<a href="https://www.redhat.com/en/technologies/jboss-middleware/data-grid">Red Hat Data Grid</a>のOSSとして提供されており、OIDCによるSSOの機能を提供するKeyCloakでキャッシュサーバとして<a href="https://www.keycloak.org/server/caching">利用できる</a>。
Red HatはKeyCloakの開発も支援している。</p>
<p>Infinispanの用途は、InifinispanはRESPプロトコルを<a href="https://infinispan.org/docs/stable/titles/resp/resp-endpoint.html">実装している</a>など、RedisやMemcachedと近い。
<a href="https://infinispan.org/use-cases/">公式ドキュメント</a>でRedisやmemcachedを置きかえるユースケースを紹介されている。
Inifinispanは、Javaで実装されており、Javaのクライアントと<a href="https://github.com/jsr107/jsr107spec">JSR107</a>のJCache APIで通信できる。
たとえば、クライアントは、<a href="https://www.javadoc.io/doc/javax.cache/cache-api/latest/index.html">CacheManager</a>でハッシュマップ構造の<a href="https://www.javadoc.io/doc/javax.cache/cache-api/latest/index.html">Cache</a>を取得し、エントリを操作できる。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/infinispan/">
            #Infinispan
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/consistent-hashing/">
            #Consistent Hashing
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 23, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/amazon.com-recommendations-item-to-item-collaborative-filtering/">Amazon.com Recommendations Item to Item Collaborative Filtering (2003)</a></h3>
    <div class="summary"><p>IEEE Internet Computingは、創刊20周年を記念し、時の試練を越えた論文に<a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf">Amazon.com Recommendations Item to Item Collaborative Filtering</a>を<a href="https://www.amazon.science/the-history-of-amazons-recommendation-algorithm">選んだ</a>。
文献では、古典的な協調フィルタリングを、アイテム数次元\(N\)のベクトルでユーザーを表現し、類似するユーザーが選んだアイテムのうち、ユーザーが未選択のアイテムを推薦対象に選ぶ手法とみなされている。
提案されたItem to Item Collaborative Filteringは、アイテム同士の類似度を示す\(N\)x\(N\)次元の行列をオフラインで構築し、\(N\)や全ユーザー数に依存しないオンラインの計算量で、ユーザーが過去に選んだアイテムに類似するアイテムを推薦できる。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 16, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/outrageously-large-neural-networks-the-sparsely-gated-mixture-of-expert-layer/">OUTRAGEOUSLY LARGE NEURAL NETWORKS THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER (2017)</a></h3>
    <div class="summary"><p>パラメタ数を増やせば多くの情報をモデルに学習させられるが、計算量も増える。
<a href="https://arxiv.org/pdf/1701.06538">OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER</a> (MoE) は、ゲートと数千規模の全結合層からなる層であり、ゲートの後に全結合層を並列に配置する。
ゲートは、サンプルごとに疎なベクトルを出力する。
各サンプルの推論において、ベクトルの0でない要素に対応する全結合層だけを計算対象に限定し、パラメタ数の増加と計算量の抑制を両立する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/mixture-of-experts/">
            #Mixture-of-Experts
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 1, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/training-language-models-to-follow-instructions-with-human-feedback/">Training Language Models to Follow Instructions With Human Feedback (2022)</a></h3>
    <div class="summary"><p>LLMはウェブページ上の次のトークンを予測できるように訓練される。
指示に応じた出力になるようにLLMを訓練していないため、パラメタ数を増やしても、プロンプトに忠実で安全で便利な出力にできるとは限らない。
<a href="https://arxiv.org/pdf/2203.02155">Training language models to follow instructions with human feedback</a>は、人間のフィードバックによる強化学習 (RLHF) により、プロンプトに対する望ましい順に順序づけられた出力で報酬モデルを訓練し、報酬モデルと<a href="https://arxiv.org/pdf/1707.06347">PPO</a>でGPT-3の方策を最適化した。
RLHFで訓練したパラメタ数1.3BのGPT-3 (InsturctGPT) の出力は、175BのGPT-3よりも人にとって望ましかった。</p>
<p>InstructGPTに採用したRLHFも、先行手法の<a href="https://arxiv.org/pdf/1706.03741">Deep Reinforcement Learning from Human Preferences</a>のように、報酬関数のモデルを訓練する。
なお、先行手法についても過去に<a href="/posts/deep_reinforcement_learning_from_human_preferences/">記事</a>にした。
InstructGPTのRLHFには、報酬関数のモデルを生成する前に、GPT3をファインチューニングする手順がある。
このファインチューニングのための訓練データは、主にOpen AI APIで集めたプロンプトに40名の請負業者が適切な出力を書いて作成された。
報酬モデルの学習データを集めるときは、ファインチューニングされたモデルにプロンプトを入力し、プロンプトに対する複数の出力を収集し、業者に良い順に出力を順序づけてもらった。
プロンプトと順序つき出力を訓練データとして、スカラ値の報酬を出力する報酬モデルを訓練し、最後に、PPOで報酬モデルの出力に方策モデルを最適化した。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/reinforcement-learning-from-human-feedback/">
            #Reinforcement Learning From Human Feedback
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 24, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/react-synergizing-reasoning-and-acting-in-language-models/">REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS (2023)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2210.03629">ReAct (Synergizing <em>Re</em>asoning + <em>Act</em>ing)</a> は、推論 (Chain of Thought) と行動 (Action) を織り混ぜた出力を促すプロンプトをLLMに与え、推論と行動両方の出力を改善する。
推論は行動の立案に使える情報を提供し、行動はLLM外部の情報を推論に提供することで互いを補完する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/prompt-engineering/">
            #Prompt Engineering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 11, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/denoising-diffusion-probabilistic-models/">Denoising Diffusion Probabilistic Models (2020)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion Probabilistic Models</a>は、高品質な画像の生成することで、デノイジング確率拡散モデル（拡散モデル）の効果を示した。
拡散モデルは、観測データにノイズを徐々に加えるマルコフ過程を遡行する。
言いかえればノイズから観測データを生成するマルコフ過程である。
モデルにノイズを加える過程は拡散過程、遡行する過程は逆拡散過程とよばれる。
ノイズが徐々に除かれるデータの各時刻の状態を潜在変数、ノイズを除いたデータを観測変数とすれば、拡散モデルを潜在変数モデルとみなせる。
観測変数の尤度を現実的な計算量で求めるために、最尤推定に変分下限を応用する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/diffusion-model/">
            #Diffusion Model
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 15, 2025
        
      </span>
    </div>
  </article>
  
</main>

  

<ul class="pagination">
  
  
  <li>
    <a href="/page/2/">
      <i class="fa-solid fa-xl fa-angle-right"></i>
    </a>
  </li>
  <li>
    <a href="/page/34/">
      <i class="fa-solid fa-xl fa-angles-right"></i>
    </a>
  </li>
  
</ul>

  <footer>
    <small>© Ryotaro Nakamura. All Rights Reserved.</small>
  </footer>
</body>


</html>
