<!DOCTYPE html>
<html lang="ja">

<head>
	<meta name="generator" content="Hugo 0.147.7">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.ja.min.66816a64bc4ce50ec1c4b76199ca9d69163fc8a69f7abc6ea758d1968d8618b0.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/about">About</a></li>
        <li><a href="https://ryotaro.dev/posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/en/">en</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
  <h1>Posts</h1>
  
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/multi-probe-consistent-hashing/">Multi-probe consistent hashing (2015)</a></h3>
    <div class="summary"><p>Karger et al.による原典の<a href="https://www.cs.princeton.edu/courses/archive/fall09/cos518/papers/chash.pdf">Consistent Hashing</a>は、CDNやKVSのノードの負荷を分散するために、ノードとキーを単位区間のハッシュ値に写像し、ハッシュ値で比べたときの最近傍のノードにキーを割り当てる。
ノードの追加と削除を繰り返してもキーの保存数が均等になるように、1つのノードに複数のハッシュ値を割りあてる。
キーと最も近いハッシュ値のノードにキーを保存する。
ノードの負荷をノードに保存するキーの数とすると、最大の負荷と平均の負荷の比率を高確率(\(1-\frac{1}{n^{\Omega(1)}}\))で\(1+\epsilon\)に抑えるには、\(\Theta(\frac{\ln n}{\epsilon^2})\)のハッシュ値を各ノードに割り当てなければならず、空間計算量はノードの数より大きくなる。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/consistent-hashing/">
            #Consistent Hashing
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 6, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/infinispan/">Infinispanの分散キャッシュ</a></h3>
    <div class="summary"><p><a href="https://infinispan.org/">Inifinispan</a>は有償インメモリーデータベース<a href="https://www.redhat.com/en/technologies/jboss-middleware/data-grid">Red Hat Data Grid</a>のOSSとして提供されており、OIDCによるSSOの機能を提供するKeyCloakでキャッシュサーバとして<a href="https://www.keycloak.org/server/caching">利用できる</a>。
Red HatはKeyCloakの開発も支援している。</p>
<p>Infinispanの用途は、InifinispanはRESPプロトコルを<a href="https://infinispan.org/docs/stable/titles/resp/resp-endpoint.html">実装している</a>など、RedisやMemcachedと近い。
<a href="https://infinispan.org/use-cases/">公式ドキュメント</a>でRedisやmemcachedを置きかえるユースケースを紹介されている。
Inifinispanは、Javaで実装されており、Javaのクライアントと<a href="https://github.com/jsr107/jsr107spec">JSR107</a>のJCache APIで通信できる。
たとえば、クライアントは、<a href="https://www.javadoc.io/doc/javax.cache/cache-api/latest/index.html">CacheManager</a>でハッシュマップ構造の<a href="https://www.javadoc.io/doc/javax.cache/cache-api/latest/index.html">Cache</a>を取得し、エントリを操作できる。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/infinispan/">
            #Infinispan
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/consistent-hashing/">
            #Consistent Hashing
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 23, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/amazon.com-recommendations-item-to-item-collaborative-filtering/">Amazon.com Recommendations Item to Item Collaborative Filtering (2003)</a></h3>
    <div class="summary"><p>IEEE Internet Computingは、創刊20周年を記念し、時の試練を越えた論文に<a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf">Amazon.com Recommendations Item to Item Collaborative Filtering</a>を<a href="https://www.amazon.science/the-history-of-amazons-recommendation-algorithm">選んだ</a>。
文献では、古典的な協調フィルタリングを、アイテム数次元\(N\)のベクトルでユーザーを表現し、類似するユーザーが選んだアイテムのうち、ユーザーが未選択のアイテムを推薦対象に選ぶ手法とみなされている。
提案されたItem to Item Collaborative Filteringは、アイテム同士の類似度を示す\(N\)x\(N\)次元の行列をオフラインで構築し、\(N\)や全ユーザー数に依存しないオンラインの計算量で、ユーザーが過去に選んだアイテムに類似するアイテムを推薦できる。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 16, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/outrageously-large-neural-networks-the-sparsely-gated-mixture-of-expert-layer/">OUTRAGEOUSLY LARGE NEURAL NETWORKS THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER (2017)</a></h3>
    <div class="summary"><p>パラメタ数を増やせば多くの情報をモデルに学習させられるが、計算量も増える。
<a href="https://arxiv.org/pdf/1701.06538">OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER</a> (MoE) は、ゲートと数千規模の全結合層からなる層であり、ゲートの後に全結合層を並列に配置する。
ゲートは、サンプルごとに疎なベクトルを出力する。
各サンプルの推論において、ベクトルの0でない要素に対応する全結合層だけを計算対象に限定し、パラメタ数の増加と計算量の抑制を両立する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/mixture-of-experts/">
            #Mixture-of-Experts
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 1, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/training-language-models-to-follow-instructions-with-human-feedback/">Training Language Models to Follow Instructions With Human Feedback (2022)</a></h3>
    <div class="summary"><p>LLMはウェブページ上の次のトークンを予測できるように訓練される。
指示に応じた出力になるようにLLMを訓練していないため、パラメタ数を増やしても、プロンプトに忠実で安全で便利な出力にできるとは限らない。
<a href="https://arxiv.org/pdf/2203.02155">Training language models to follow instructions with human feedback</a>は、人間のフィードバックによる強化学習 (RLHF) により、プロンプトに対する望ましい順に順序づけられた出力で報酬モデルを訓練し、報酬モデルと<a href="https://arxiv.org/pdf/1707.06347">PPO</a>でGPT-3の方策を最適化した。
RLHFで訓練したパラメタ数1.3BのGPT-3 (InsturctGPT) の出力は、175BのGPT-3よりも人にとって望ましかった。</p>
<p>InstructGPTに採用したRLHFも、先行手法の<a href="https://arxiv.org/pdf/1706.03741">Deep Reinforcement Learning from Human Preferences</a>のように、報酬関数のモデルを訓練する。
なお、先行手法についても過去に<a href="/posts/deep_reinforcement_learning_from_human_preferences/">記事</a>にした。
InstructGPTのRLHFには、報酬関数のモデルを生成する前に、GPT3をファインチューニングする手順がある。
このファインチューニングのための訓練データは、主にOpen AI APIで集めたプロンプトに40名の請負業者が適切な出力を書いて作成された。
報酬モデルの学習データを集めるときは、ファインチューニングされたモデルにプロンプトを入力し、プロンプトに対する複数の出力を収集し、業者に良い順に出力を順序づけてもらった。
プロンプトと順序つき出力を訓練データとして、スカラ値の報酬を出力する報酬モデルを訓練し、最後に、PPOで報酬モデルの出力に方策モデルを最適化した。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/reinforcement-learning-from-human-feedback/">
            #Reinforcement Learning From Human Feedback
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 24, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/react-synergizing-reasoning-and-acting-in-language-models/">REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS (2023)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2210.03629">ReAct (Synergizing <em>Re</em>asoning + <em>Act</em>ing)</a> は、推論 (Chain of Thought) と行動 (Action) を織り混ぜた出力を促すプロンプトをLLMに与え、推論と行動両方の出力を改善する。
推論は行動の立案に使える情報を提供し、行動はLLM外部の情報を推論に提供することで互いを補完する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/prompt-engineering/">
            #Prompt Engineering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 11, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/denoising-diffusion-probabilistic-models/">Denoising Diffusion Probabilistic Models (2020)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion Probabilistic Models</a>は、高品質な画像の生成することで、デノイジング確率拡散モデル（拡散モデル）の効果を示した。
拡散モデルは、観測データにノイズを徐々に加えるマルコフ過程を遡行する。
言いかえればノイズから観測データを生成するマルコフ過程である。
モデルにノイズを加える過程は拡散過程、遡行する過程は逆拡散過程とよばれる。
ノイズが徐々に除かれるデータの各時刻の状態を潜在変数、ノイズを除いたデータを観測変数とすれば、拡散モデルを潜在変数モデルとみなせる。
観測変数の尤度を現実的な計算量で求めるために、最尤推定に変分下限を応用する。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/diffusion-model/">
            #Diffusion Model
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 15, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/lora-low-rank-adaptation-of-large-language-models/">LoRA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS (2021)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/1804.08838.pdf">Li et al. (2018)</a>と<a href="https://arxiv.org/pdf/2012.13255.pdf">Aghajanyan et al. (2020)</a>は、Large Language Models (LLM) のファインチューニングにおいて、下流タスクに必要なパラメータ数はLLMのパラメタ数よりもはるかに少ないと主張する。
<a href="https://arxiv.org/pdf/2106.09685.pdf">LoRA</a>は、この仮説を支持し、ファインチューニングを避け、LLMの全結合層と線形結合するための2つの小さい行列を導入する。
LLMの重みを\(W_0\in\mathbb{R}^{d\times k}\) とすると、\(W_0+BA\ (B\in\mathbb{R}^{d\times r}, A\in\mathbb{R}^{r\times k}, r \ll\min (d, k))\)が下流タスクに最適な重みに近づくように、ファインチューニングにかわって\(W_0\)を更新せず\(B,\ A\)のみを更新する。
\(r\)が\(d, k\)よりも小さいので、\(W_0\)を更新するファインチューニングよりも学習時間は短い。
また、複数の下流タスクを入力に適用する場合、\(W_0x\)を共有できるので、推論に必要な計算も\(W_0\)を更新するファインチューニングより少ない。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-model/">
            #Large Language Model
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/transformer/">
            #Transformer
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 7, 2025 (Originally posted on November 18, 2023)</p>
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data/">Supervised Learning of Universal Sentence Representations From Natural Language Inference Data (2017)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/1705.02364">Supervised Learning of Universal Sentence Representations From Natural Language Inference Data</a>は自然言語推論のデータセットであるStanford Natural Language Inference (SNLI) を使った文の埋め込みベクトルを生成モデルを教師あり学習を提案した。
7種類のネットワークアーキテクチャを12種類のタスクで評価したところ、双方向LSTMと最大値プーリングを採用したアーキテクチャが最も高い性能を発揮した。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/sentence-embedding/">
            #Sentence Embedding
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        May 30, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/posts/scaling-instruction-finetuned-language-models/">Scaling Instruction Finetuned Language Models (2022)</a></h3>
    <div class="summary"><p>Instruction Finetuningは訓練データにない種類のタスクのゼロショットを改善するファインチューニングの一種で、<a href="https://arxiv.org/pdf/2109.01652">Finetuned Language Models Are Zero-Shot Learners</a>で知られるようになった。
もとの文献ではInstruction tuningと呼ばれている。
<a href="https://arxiv.org/pdf/2210.11416">Scaling Instruction-Finetuned Language Models</a>は、学習データ、モデルのパラメタの数、chain-of-thoughtのデータを増やすと、instruction tuningで学習したモデルの性能を向上できることを示した。</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/tags/instruction-finetuning/">
            #Instruction Finetuning
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        May 7, 2025
        
      </span>
    </div>
  </article>
  
</main>

  

<ul class="pagination">
  
  
  <li>
    <a href="/page/2/">
      <i class="fa-solid fa-xl fa-angle-right"></i>
    </a>
  </li>
  <li>
    <a href="/page/34/">
      <i class="fa-solid fa-xl fa-angles-right"></i>
    </a>
  </li>
  
</ul>

  <footer>
    <small>© Ryotaro Nakamura. All Rights Reserved.</small>
  </footer>
</body>


</html>
