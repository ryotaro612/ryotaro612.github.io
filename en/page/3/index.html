<!DOCTYPE html>
<html lang="en">

<head>
	<meta name="generator" content="Hugo 0.131.0">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.en.min.fabf7968ffbe5ff626ec9a346f0d38e91d0078974112f713b9d25782380a5073.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/en/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/en/%20about">About</a></li>
        <li><a href="https://ryotaro.dev/en/%20posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/en/%20tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/">ja</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/en/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
    <h1>Posts</h1>
    
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/poly-encoders-architectures-and-pre-training-strategies-for-fast-and-accurate-multi-sentence-scoring/">Poly-Encoders: Architectures and Pre-Training Strategies for Fast and Accurate Multi-Sentence Scoring (2019)</a></h3>
        <div class="summary"><p>For tasks matching input sequences with labels, current state-of-the-art approaches focus on using <a href="https://arxiv.org/abs/1810.04805">BERT</a> models for pre-training.
Two common encoding approaches are Cross-encoders (<a href="https://arxiv.org/abs/1901.08149">Wolf et al.</a>), which concatenate input sequences and candidate labels into a single vector, and produce candidate-sensitive embeddings, and Bi-encoders (<a href="https://arxiv.org/abs/1809.01984">Mazaré et al.</a>), which encode input sequences and candidate labels separately.
In Bi-encoders, the score is the dot-product of the two embeddings.
While Cross-encoders are more accurate than Bi-encoders, Bi-encoders are faster.</p>
<!-- For the tasks that match an input sequence with a corresponding label, current state-of-the-art approaches focuse on using [BERT](https://arxiv.org/abs/1810.04805) models for pre-training, and two encoding approaches are common: Cross-encoders ([Wolf et al.](https://arxiv.org/abs/1901.08149)) and Bi-encoders ([Mazaré et al.](https://arxiv.org/abs/1809.01984)). -->
<!-- Cross-encoders concatenate an input seqeuence and a candidate label into a single vector, and produce a candidate-sensitive input embedding from the vector. -->
<!-- Bi-encoders encde an input sequence and a candidate label separately. -->
<!-- The score is  the dot-product of the two embeddings. -->
<!-- While Cross-encoders are more accurate than Bi-encoders, Bi-encoders are faster than the other. --></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">February 24, 2024</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/the-design-of-postgres/">THE DESIGN OF POSTGRES (1986)</a></h3>
        <div class="summary"><p>The preliminary design of POSTGRES was presented in <a href="https://dsf.berkeley.edu/papers/ERL-M85-95.pdf">The Design of Postgres</a>.
According to <a href="https://www.postgresql.jp/document/8.3/html/history.html">Brief History of Postgres</a>, the data model, rules, and storage system were separately described in different papers: <a href="https://apps.dtic.mil/sti/tr/pdf/ADA184251.pdf">The Postgres Data Model</a>, <a href="https://apps.dtic.mil/sti/tr/pdf/ADA179161.pdf">The Design of the Postgres Rule System</a>, and <a href="https://dsf.berkeley.edu/papers/ERL-M87-06.pdf">The Design of the Postgres Storage System</a>.</p>
<p>POSTGRES is the successor to the INGRES relational database system.
The main design goals of POSTGRES were to support complex objects, simplify the DBMS code for crash recovery, and utilize optical disks while making as few changes as possible to the relational model.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/rdbms/">
		#RDBMS
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/postgresql/">
		#PostgreSQL
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">February 17, 2024</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks/">Retrieval Augmented Generation for Knowledge Intensive NLP Tasks (2021)</a></h3>
        <div class="summary"><p>While large pre-trained language models (LLMs) can implicitly store factual knowledge in their parameters, their ability to access explicit encyclopedic and commonsense is knowledge still limited.
Retrieval Augmented Generation (RAG) is a method to improve language generation by providing external explicit knowledge to LLMs.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/retrieval-augmented-generation/">
		#Retrieval Augmented Generation
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">January 27, 2024</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/sorting-networks-and-their-applications/">Sorting networks and their applications (1968)</a></h3>
        <div class="summary"><p>A sorting network is a network of comparison elements with 2 indegree and 2 outdegree that sorts a list in ascending or descending order.
A comparison element receives two numbers and outputs the smaller one to one output and the larger one to the other output.
Odd-even merging networks and Bitonic sorters are sorting networks proposed in <a href="https://www.cs.kent.edu/~batcher/sort.pdf">Sorting networks and their applications</a>.
They can sort \(2^p\) elements with \(\ln (\frac{1}{2})p(p+1)\) steps.
Their processing is independent of the values and is easy to run on the GPU because it does not change the output location in memory based on input data values.</p>
<!-- https://developer.nvidia.com/gpugems/gpugems2/part-vi-simulation-and-numerical-algorithms/chapter-46-improved-gpu-sorting --></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/sorting-algorithm/">
		#Sorting Algorithm
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">January 14, 2024</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/billion-scale-similarity-search-with-gpus/">Billion Scale Similarity Search With GPUs (2017)</a></h3>
        <div class="summary"><p>The paper <a href="https://arxiv.org/abs/1702.08734">Billion-scale-similarity search with GPUs</a> presents an approximate nearest-neighbor search method that uses GPUs and combines the <a href="https://inria.hal.science/inria-00514462v2/document">IVFADC</a> indexing structure with <a href="https://www.cs.kent.edu/~batcher/sort.pdf">Batcher&rsquo;s bitonic sorting network</a>.
The authors have implemented this method in a library called <a href="https://github.com/facebookresearch/faiss">faiss</a>.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/approximate-nearest-neighbors/">
		#Approximate Nearest Neighbors
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">January 1, 2024</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/conflict-free-replicated-data-types/">Conflict-free Replicated Data Types (2011)</a></h3>
        <div class="summary">In a distributed system with replicated objects distributed across processes interconnected by an asynchronous network, updating a replica without synchronization can lead to conflicts when the update is sent to other replicas. Conflict-free Replicated Data Types (CRDTs) are data structures whose states form a join semilattice and monotonically non-decreasing across updates. The replicas of CRDTs that have delivered the same updates eventually reach the same state if clents stop submitting updates.</div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/conflict-free-replicated-data-types/">
		#Conflict-Free Replicated Data Types
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">December 31, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/dense-passage-retrieval-for-open-domain-question-answering/">Dense Passage Retrieval for Open-Domain Question Answering (2020)</a></h3>
        <div class="summary"><p>Open-domain question answering (QA) involves answering fact-based questions using documents.
An open-domain QA system can be divided into two components: one that retrieves relevant passages and another that extracts the answer spans from those passages <a href="https://arxiv.org/abs/1704.00051">(Chen et al., 2017)</a>.
While traditional approaches use sparse vector space models like BM25 for the retrieval step, <a href="https://aclanthology.org/2020.emnlp-main.550/">Dense Passage Retrieval for Open-Domain Question Answering</a> shows that dense representations can also be practically implemented using dense representations.</p>
<!-- Open-domain question answering (QA) is a task that answers factorid questions using documents. -->
<!-- If the answers are spans appearing in passages of the documents, an open-domain QA system can be decomposed into 2 components. -->
<!-- The first component retrieves a small set of passages relevant to the question, and the second one extract the span from the filter set [(Chen et al., 2017)](https://arxiv.org/abs/1704.00051). -->
<!-- While traditional approaches use sparse vector space models such as BM25 for the first module, [Dense Passage Retrieval for Open-Domain Question Answering](https://aclanthology.org/2020.emnlp-main.550/) demonstrates that the first retrieval step can be implemented using dense representations. -->
<p>The embeddings are learned from the training dataset, optimizing for maximizing inner products between question and relevant passage vectors.
The training is essentially metric learning, and each question needs irrelvant passages.
In experiments, it was found that utilizing both the top passages returned by BM25, excluding the answer, and positive passages paired with other questions as negatives yielded best performance.</p>
<!-- The embeddings are learned from the questions and passages in a training dataset, and optimized for maximizing inner products of the question and relevant passage vectors. -->
<!-- The training is essentially metric learning, and each question needs irrelvant passages. -->
<!-- Using both the top passages returned by BM25 except the answer and positive passages paired with other questions as negatives outperformed in experiments. --></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/question-answering/">
		#Question Answering
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">December 30, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/cap-twelve-years-later-how-the-rules-have-changed/">CAP Twelve Years Later: How the &#34;Rules&#34; Have Changed (2012)</a></h3>
        <div class="summary">The CAP theorem, coined by Eric Brewer, states that in a shared-data system, you can have either Consistency (C), Availability (A), or Parition tolerance (P), but not all three simultaneously. However, Martin Kleppmann challenges the CAP theorem and discusses its limitations in Designing Data-Intensive Applications, and A Critique of the CAP Theorem. In CAP Twelve Years Later: How the “Rules” Have Changed, Brewer clarifies that the notion of &ldquo;2 of 3&rdquo; is misleading.</div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/cap-theorem/">
		#CAP Theorem
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">December 23, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/wide-and-deep-learning-for-recommender-systems/">Wide and Deep Learning for Recommender Systems (2016)</a></h3>
        <div class="summary"><p>Generalized linear models are widely used for large-scale regression and classification problems with sparse inputs because they are simple, scale and interpretable.
One limitation of interactions or cross-prodcution transformations in generalized linear models is that they do not generalize to query-item feature pairs that have not appeared in the training data.
Compared with generalized linear models, deep neural networks can improve the diversity of the recommendations.
Howerver it is difficult to learn effective low-dimentional dense embedding vectors.
<a href="https://arxiv.org/abs/1606.07792">Wide &amp; Deep Learning for Recommender Systems</a> jointly trains a generalized linear model and a feed-forward neural network (FFN) to combines their benefits.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/recommendation/">
		#Recommendation
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">December 16, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/a_protocol_for_packet_network_intercommunication/">A Protocol for Packet Network Intercommunication (1974)</a></h3>
        <div class="summary"><p>Vinton Cerf and Robert Kahn presented a protocol that supports packet communication between hosts in different packet switching networks in <a href="https://www.cs.princeton.edu/courses/archive/fall06/cos561/papers/cerf74.pdf">A Protocol for Packet Network Intercommunication</a>.
The protocol assumes that a Transmission Control Program (TCP) in a host handles the transmission and acceptance of messages on behalf of processes.
Later, the program was divided into the Transmission Control Protocol (TCP) and the Internet Protocol (IP).
At that time, several protocols that supported exchanging packets between computers were developed, but they assumed the computers were on the same network.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/tcp/">
		#TCP
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">December 9, 2023</span>
        </div>
    </article>
    
</main>

  

<ul class="pagination">  
    
    <li>
      <a href="/en/">
	<i class="fa-solid fa-xl fa-angles-left"></i>
      </a>
    </li>
    <li>
      <a href="/en/page/2/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
    <li>
      <a href="/en/page/4/">
	<i class="fa-solid fa-xl fa-angle-right"></i>
      </a>
    </li>
    <li>
      <a href="/en/page/5/">
	<i class="fa-solid fa-xl fa-angles-right"></i>
      </a>
    </li>
    
</ul>

  <footer>
    <small>© Ryotaro. All Rights Reserved.</small>
  </footer>
</body>


</html>
