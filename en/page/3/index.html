<!DOCTYPE html>
<html lang="en">

<head>
	<meta name="generator" content="Hugo 0.147.7">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.en.min.fabf7968ffbe5ff626ec9a346f0d38e91d0078974112f713b9d25782380a5073.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/en/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/en/about">About</a></li>
        <li><a href="https://ryotaro.dev/en/posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/en/tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/">ja</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/en/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
  <h1>Posts</h1>
  
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/realm-retrieval-augmented-language-model-pre-training/">REALM Retrieval Augmented Language Model Pre Training (2020)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/abs/2002.08909">REALM</a> is a language model for open-domain question answering.
REALM is composed of two components: the neural knowledge retriever and the knowledge-augmented encoder.
The neural knowledge retriever finds documents related to the input.
The knowledge-augmented encoder generates responses from the found documents and the input.
In pre-training, the REALM employs masked language modeling, and it is trained to predict the original tokens that are maked in the given sentences.
In fine-tuning, the model is trained to produce the answer of the given input.
The authors experimented the model with Open-domain QA tasks under the assumption that the answer can be found as a contiguous sequence of tokens in some documents.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/retrieval-augmented-generation/">
            #Retrieval Augmented Generation
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        May 27, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/distributed-graphlab-a-framework-for-machine-learning-and-data-mining-in-the-cloud/">Distributed GraphLab: a Framework for Machine Learning and Data Mining in the Cloud (2012)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/1408.2041">GraphLab</a> is a programming model for machine learning and data mining.
GraphLab takes a direct graph, a set of vertices, and update functions as input.
Every update function accepts a vertex and returns a set of vertices.
GraphLab selects a vertex from the set, applies a function to it, and adds the resulting set of vertices back intothe set, repeating this process until the set is empty.
GraphLab supports parallel execution of update functions on multi-processor machines.
<a href="https://arxiv.org/pdf/1408.2041">Distributed GraphLab</a> extends GraphLab by distributing parts of a graph across machines that are memory, utilizing <a href="https://lamport.azurewebsites.net/pubs/chandy.pdf">Chandy-Lamport</a>&rsquo;s snapshot algorithm for fault tolerance.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/distributed-system/">
            #Distributed System
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        May 7, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/policy-gradient-methods-for-reinforcement-learning-with-function-approximation/">Policy Gradient Methods for Reinforcement Learning With Function Approximation (1999)</a></h3>
    <div class="summary"><p>Policy gradient methods approximate stochastic policies using function approximators, which are independent of value functions.
They update the policies according to the gradient of expected reward with respect to the policy parameters.
<a href="https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf">Policy Gradient Methods for Reinforcement Learning With Function Approximation</a> shows that a form of policy iteration with function approximation converges to a locally optimal policy.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/policy-gradient-method/">
            #Policy Gradient Method
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/reinforcement-learning/">
            #Reinforcement Learning
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        April 27, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/spark-sql-relational-data-processing-in-spark/">Spark SQL: Relational Data Processing in Spark (2015)</a></h3>
    <div class="summary"><p><a href="https://dl.acm.org/doi/10.1145/2723372.2742797">Spark SQL</a> provides a DataFrame API, an abstract data type equivalent to a table in a relational database. The DataFrame objects can be manipulated in a manner consistent with relational algebra. For example, the API includes various relational operators such as <code>where</code> and <code>group by</code>, similar to data frames in R and Python. The DataFrame objects are evaluated lazily, meaning they are not evaluated until certain output operations, like <code>count</code>, are performed. Catalyst, an optimizer written in Scala, optimizes these lazy queries and then compiles them into Java bytecode.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/sql/">
            #SQL
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/spark/">
            #Spark
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        April 14, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/neural-collaborative-filtering/">Neural Collaborative Filtering (2017)</a></h3>
    <div class="summary"><p>In collaborative filtering, Matrix Factorization (MF) approximates the user-item interaction matrix by multiplying the latent matrices for users and items.
An estimated iteraction is the inner product of the latent vectors for the user and the item.
<a href="https://arxiv.org/pdf/1708.05031.pdf">Neural Collaborative Filtering (NCF)</a> replaces the inner product with a neural neural network to capture the complex structure of user interaction data.
There are three instances of NFC: Generalized Matrix Factorization (GMF), Multi-Layer Perceptron (MLP), Neural Matrix Factoriation (NeuMF).</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        March 25, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/telegraphcq-continuous-dataflow-processing-for-an-uncertain-world/">TelegraphCQ: Continuous Dataflow Processing for an Uncertain World (2003)</a></h3>
    <div class="summary"><p>Stonebraker and Çetintemel presented <a href="https://cs.brown.edu/~ugur/fits_all.pdf">&ldquo;One Size Fits All&rdquo;</a> in 2005.
The phrase refers to the fact that various data-centric applications use traditional DMBMS architectures to store data regardless of the characteristics and requirements of the data.
In the paper, they argued that this approach was no longer applicable, with examples of streaing processing.
<a href="https://cs.brown.edu/courses/cs227/archives/2015/papers/ss-telegraphcq.pdf">TelegraphCQ</a>, presented in 2003, is the first generation of databases for streamingffff data from the early 2000s.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/streaming-data/">
            #Streaming Data
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/postgresql/">
            #PostgreSQL
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        March 22, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/llama-open-and-efficient-foundation-language-models/">LLaMA Open and Efficient Foundation Language Models (2023)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2001.08361.pdf">Scaling Laws for Neural Language Models</a> refers to empirical observations that model test performance has a power-law relationship with each of the three scale factors: the number of model parameters, the dataset size in tokens, and the amount of compute used for training, when not bottlenecked by the other two.
<a href="https://arxiv.org/abs/2203.15556">Hoffmann et al. (2022)</a> investigated the bottleneck and found that, given a fixed FLOPs budget, the number of model parameters and the training tokens should be scaled equally to minimize pre-training loss.
They trained a predicted compute-optimal model, Chinchilla, with 80B parameters, at the same compute budget as Gopher (280B) and with 4 times more data.
Chinchilla outperformed Gopher and GPT-3 (175B) on a large range of downstream evaluation tasks.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-model/">
            #Large Language Model
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        March 14, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/apache-calcite-a-foundational-framework-for-optimized-query-processing-over-heterogeneous-data-sources/">Apache Calcite a Foundational Framework for Optimized Query Processing Over Heterogeneous Data Sources</a></h3>
    <div class="summary"><p>Michael StonebrakerとUğur Çetintemel presented <a href="https://cs.brown.edu/~ugur/fits_all.pdf">One Size Fits All</a> in 2005.
The title refers to the fact that traditional RDBMS had been used to implement a variety of data-centric applications.
Tn the paper, they argued that the phrase was no longer applicable and predicted the rise of domain-specific database engines.
Indeed, organizations leverage various domain-specific database engines such as column stores and text search engines today.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/apache-calcite/">
            #Apache Calcite
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        March 10, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/mining-association-rules-between-sets-of-items-in-large-databases/">Mining Association Rules Between Sets of Items in Large Databases (1993)</a></h3>
    <div class="summary"><p><a href="https://dl.acm.org/doi/10.1145/170036.170072">Mining Association Rules between Sets of Items in Large Databases</a> presents one of the earliest approaches for association rules mining.
An association rule is an implication of the form \(X \Rightarrow I_j\) where \(X\) is a set of some items, and \(I_j\) is an item that is not in \(X\).
For instance, if transactions buying bread and butter also buy milk, that forms an association rule.
The paper introduces a method to find association rules and measure confidence and support factors from transactions.
The confidence factor measures how many transactions that satisfy \(X\) also satisfy \(I_j\).
The support factor of an association rule is defined to be the fraction of transactions that contain the union of items in the rule.
The support factor implies statistical significance of the association rule.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/association-rule-mining/">
            #Association Rule Mining
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        March 2, 2024
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/poly-encoders-architectures-and-pre-training-strategies-for-fast-and-accurate-multi-sentence-scoring/">Poly-Encoders: Architectures and Pre-Training Strategies for Fast and Accurate Multi-Sentence Scoring (2019)</a></h3>
    <div class="summary"><p>For tasks matching input sequences with labels, current state-of-the-art approaches focus on using <a href="https://arxiv.org/abs/1810.04805">BERT</a> models for pre-training.
Two common encoding approaches are Cross-encoders (<a href="https://arxiv.org/abs/1901.08149">Wolf et al.</a>), which concatenate input sequences and candidate labels into a single vector, and produce candidate-sensitive embeddings, and Bi-encoders (<a href="https://arxiv.org/abs/1809.01984">Mazaré et al.</a>), which encode input sequences and candidate labels separately.
In Bi-encoders, the score is the dot-product of the two embeddings.
While Cross-encoders are more accurate than Bi-encoders, Bi-encoders are faster.</p>
<!-- For the tasks that match an input sequence with a corresponding label, current state-of-the-art approaches focuse on using [BERT](https://arxiv.org/abs/1810.04805) models for pre-training, and two encoding approaches are common: Cross-encoders ([Wolf et al.](https://arxiv.org/abs/1901.08149)) and Bi-encoders ([Mazaré et al.](https://arxiv.org/abs/1809.01984)). -->
<!-- Cross-encoders concatenate an input seqeuence and a candidate label into a single vector, and produce a candidate-sensitive input embedding from the vector. -->
<!-- Bi-encoders encde an input sequence and a candidate label separately. -->
<!-- The score is  the dot-product of the two embeddings. -->
<!-- While Cross-encoders are more accurate than Bi-encoders, Bi-encoders are faster than the other. --></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/transformer/">
            #Transformer
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        February 24, 2024
        
      </span>
    </div>
  </article>
  
</main>

  

<ul class="pagination">
  
  <li>
    <a href="/en/">
      <i class="fa-solid fa-xl fa-angles-left"></i>
    </a>
  </li>
  <li>
    <a href="/en/page/2/">
      <i class="fa-solid fa-xl fa-angle-left"></i>
    </a>
  </li>
  
  
  <li>
    <a href="/en/page/4/">
      <i class="fa-solid fa-xl fa-angle-right"></i>
    </a>
  </li>
  <li>
    <a href="/en/page/6/">
      <i class="fa-solid fa-xl fa-angles-right"></i>
    </a>
  </li>
  
</ul>

  <footer>
    <small>© Ryotaro Nakamura. All Rights Reserved.</small>
  </footer>
</body>


</html>
