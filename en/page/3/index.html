<!DOCTYPE html>
<html>
  <head>
	<meta name="generator" content="Hugo 0.121.2">
    
        
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
       new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
       j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
		    })(window,document,'script','dataLayer','GTM-W5TDG76');
    </script>
        
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=300,initial-scale=1">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
          integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
          crossorigin="anonymous" />
    
    <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.87b8f4076c47000c129b0c8b240a71216448e3aedd7144174c55776680a783b0.css">
    
    <link rel="stylesheet" href="https://ryotaro.dev/scss/base.en.min.fabf7968ffbe5ff626ec9a346f0d38e91d0078974112f713b9d25782380a5073.css">
    

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.ad090cad4f6d9fadf06a509c7ea790bd1fc13b24802f351ad71342659fdebf9f.css">

    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css" integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js" integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4" crossorigin="anonymous"></script>
    
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
    <title>Blanket</title>
  </head>

  <body>
        
    
    <noscript>
      <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0" style="display:none;visibility:hidden"/>
    </noscript>
    
        
    <header class="navigation">
      <h2><a href="https://ryotaro.dev/en/">Blanket</a></h2>
      <nav>
        <ul>
          <li><a href="https://ryotaro.dev/en/about">About</a></li>
          <li><a href="https://ryotaro.dev/en/posts">Posts</a></li>
          <li><a href="https://ryotaro.dev/en/tags">Tags</a></li>
	  
	  <li><a href="https://ryotaro.dev/">ja</a></li>
	  
        </ul>
      </nav>
    </header>
    
<main>
    <h1>Posts</h1>
    
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/roberta/">RoBERTa: A Robustly Optimized BERT Pretraining Approach(2019)</a></h3>
        <div class="summary"><p><a href="https://arxiv.org/pdf/1907.11692.pdf">RoBERTa</a>(Robusty optimized BERT approach) is an improved recipe for training <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT</a> models.
BERT uses two objectives, masked language modeling and next sequence prediction (NSP), during pretraining.
RoBERTa uses masked language modeling only.
The authors increased the batch size and Byte-Pair Encoding (BPE) vocabulary size.
RobERTa is trained with byte-level BPE, which uses bytes instead of unicode characters as the base subword units.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/bert/">
		#BERT
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/byte-pair-encoding/">
		#Byte Pair Encoding
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">August 27, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/go_to_statement_considered_harmful/">Go To Statement Considered Harmful (1968)</a></h3>
        <div class="summary"><p>Edgar Djkstra criticized the excessive use of the go to statement in <a href="https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf">Go To Statement Considered Harmful</a>.
While the source code is static, the process taking place under the control of the source code is dynamic.
The programmers should aim to shorten the conceptual gap between the source code and its process to describe the progress.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/early-programming/">
		#Early Programming
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">August 26, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/self_attention_with_relative_position_representations/">Self-Attention with Relative Position Representations(2018)</a></h3>
        <div class="summary"><p>The authors of <a href="https://arxiv.org/pdf/1803.02155.pdf">Self-Attention with Relative Position Representations</a> presented a way of injecting relative position representations in the self-attention mechanism of the <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Transformer</a>.
In contrast to recurrent and convolutional neural networks, Transformer does not explicitly model position information in its structure.
<a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">The original position encoding</a> employs sine and cosine functions of different frequencies.
The authors of Transformer hypothesized that sinusoidal position encodings would help Transformer to generalize to sequence lengths unseen during training.
Positional encodings are added to the input embeddings at the bottoms of the encoder and decoder stacks of Transformer.
This hypothesis was shared by the relative position representations.
In contrast to absolute position representations, the relative position representations are invariant to the total sequence length.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/attention/">
		#Attention
	      </a>
	    </li>
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">August 19, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/self_adjusting_binary_search_trees/">Self-Adjusting Binary Search Trees(1985)</a></h3>
        <div class="summary"><p><a href="https://www.cs.cmu.edu/~sleator/papers/self-adjusting.pdf">The splay tree</a>, a self-adjusting form of a binary search tree, is a binary search tree that moves an accessed node to the root after each access.
On an \(n\)-node splay tree, accessing, inserting and deleting have an amortized time bound of \(O(\log n)\) per operation.
In addition, for sufficiently long access sequences, splay trees are as efficient, to within a constant factor, as static optimum search trees.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/splay-tree/">
		#Splay tree
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">August 12, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/exploring_the_limits_of_transfer_learning_with_a_unified_text-to-text_transformer/">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer(2020)</a></h3>
        <div class="summary">The authors of Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer performed experiments with Text-to-Text Transfer Transformer(T5), a unified framework for NLP. The basic idea underlying T5 is to treat various NLP problems as taking text as input and producing new text as output. Their goal is to explore general language learning abilities instead of providing new methods. They are interested in exploring the limits of transfer learning for NLP by scaling up models and data sets beyond what has previously been considered.</div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/transformer/">
		#Transformer
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">August 5, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/catalan_number/">Catalan Numbers(2016)</a></h3>
        <div class="summary">The Catalan numbers are a sequence of natural numbers that occur in various problems in combinatorial mathematics. For example, the number of expressions containing \(n\) valid pairs of parentheses is the \(n\)th Catalan number. Suppose you have a grid of \(n \times n\) squares, the \(n\)th Catalan number represents the number of paths with a length of \(2n\) that lead from the upper left corner to the lower right corner without intersecting the diagonal dotted line running from the upper left to the lower right.</div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/catalan-numbers/">
		#Catalan numbers
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">July 29, 2023</span>
        </div>
    </article>
    
    <article>
        <h3><a href="https://ryotaro.dev/en/posts/an_incremental_approach_to_compiler_construction/">An Incremental Approach to Compiler Construction (2006)</a></h3>
        <div class="summary"><p><a href="http://scheme2006.cs.uchicago.edu/11-ghuloum.pdf">An Incremental Approach to Compiler Construction</a> shows an incremental approach to build a compiler that accepts a large subset of the Scheme programming language.
The compiler produces assembly code for the Intel-X86 architecture.
Because real-life compilers are too complex to serve as an educational tool, the gap between real-life compilers and the educational toy compilers is too wide.</p>
<p>The goal of the paper is to break the barrier.
The development of the compiler is broken down into 24 incremental steps.
Every step yields a fully working compiler for progressively expanding a subset of Scheme.</p></div>
        <div class="article-footer">
	  	  
	  <ul class="tags">
	    
            <li class="tag">
	      <a href="https://ryotaro.dev/en/tags/compiler/">
		#Compiler
	      </a>
	    </li>
	    
	  </ul>
	  
          <span class="date">January 1, 0001</span>
        </div>
    </article>
    
</main>

    

<ul class="pagination">  
    
    <li>
      <a href="/en/">
	<i class="fa-solid fa-xl fa-angles-left"></i>
      </a>
    </li>
    <li>
      <a href="/en/page/2/">
	<i class="fa-solid fa-xl fa-angle-left"></i>
      </a>
    </li>
    
    
</ul>

    <footer>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        <li><a href="https://ryotaro.dev/en/index.xml"><i class="fas fa-rss"></i></a></li>
        
      </ul>
      <small>© Ryotaro. All Rights Reserved.</small>
    </footer>
  </body>

</html>
