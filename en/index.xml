<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blanket</title>
    <link>https://nryotaro.dev/en/</link>
    <description>Recent content on Blanket</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 12 Aug 2023 13:49:56 -0400</lastBuildDate><atom:link href="https://nryotaro.dev/en/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Self-Adjusting Binary Search Trees(1985)</title>
      <link>https://nryotaro.dev/en/posts/self_adjusting_binary_search_trees/</link>
      <pubDate>Sat, 12 Aug 2023 13:49:56 -0400</pubDate>
      
      <guid>https://nryotaro.dev/en/posts/self_adjusting_binary_search_trees/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~sleator/papers/self-adjusting.pdf&#34;&gt;The splay tree&lt;/a&gt;, a self-adjusting form of a binary search tree, is a binary search tree that moves an accessed node to the root after each access.
On an \(n\)-node splay tree, accessing, inserting and deleting have an amortized time bound of \(O(\log n)\) per operation.
In addition, for sufficiently long access sequences, splay trees are as efficient, to within a constant factor, as static optimum search trees.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer(2020)</title>
      <link>https://nryotaro.dev/en/posts/exploring_the_limits_of_transfer_learning_with_a_unified_text-to-text_transformer/</link>
      <pubDate>Sat, 05 Aug 2023 13:27:09 -0400</pubDate>
      
      <guid>https://nryotaro.dev/en/posts/exploring_the_limits_of_transfer_learning_with_a_unified_text-to-text_transformer/</guid>
      <description>The authors of Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer performed experiments with Text-to-Text Transfer Transformer(T5), a unified framework for NLP. The basic idea underlying T5 is to treat various NLP problems as taking text as input and producing new text as output. Their goal is to explore general language learning abilities instead of providing new methods. They are interested in exploring the limits of transfer learning for NLP by scaling up models and data sets beyond what has previously been considered.</description>
    </item>
    
    <item>
      <title>Catalan Numbers(2016)</title>
      <link>https://nryotaro.dev/en/posts/catalan_number/</link>
      <pubDate>Sat, 29 Jul 2023 15:24:15 -0400</pubDate>
      
      <guid>https://nryotaro.dev/en/posts/catalan_number/</guid>
      <description>The Catalan numbers are a sequence of natural numbers that occur in various problems in combinatorial mathematics. For example, the number of expressions containing \(n\) valid pairs of parentheses is the \(n\)th Catalan number. Suppose you have a grid of \(n \times n\) squares, the \(n\)th Catalan number represents the number of paths with a length of \(2n\) that lead from the upper left corner to the lower right corner without intersecting the diagonal dotted line running from the upper left to the lower right.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://nryotaro.dev/en/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://nryotaro.dev/en/about/</guid>
      <description>Disclaimer All the information on this website is published in good faith and for general information purpose only. This website does not make any warranties about the completeness, reliability and accuracy of this information. Any action you take upon the information you find on this website, is strictly at your own risk. Ryotaro Nakamura will not be liable for any losses and/or damages in connection with the use of this website.</description>
    </item>
    
  </channel>
</rss>
