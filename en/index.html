<!DOCTYPE html>
<html lang="en">

<head>
	<meta name="generator" content="Hugo 0.152.2">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.en.min.fabf7968ffbe5ff626ec9a346f0d38e91d0078974112f713b9d25782380a5073.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/en/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/en/about">About</a></li>
        <li><a href="https://ryotaro.dev/en/posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/en/tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/">ja</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/en/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
  <h1>Posts</h1>
  
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/deep-neural-networks-for-youtube-recommendations/">Deep Neural Networks for Youtube Recommendations (2016)</a></h3>
    <div class="summary"><p><a href="https://static.googleusercontent.com/media/research.google.com/ja//pubs/archive/45530.pdf">Deep Neural Networks for YouTube Recommendations</a>, published in 2016, describes YouTube’s large-scale recommendation system.<br>
The system consists of two feed-forward neural networks: a candidate generation model and a ranking model, together containing approximately one billion parameters.</p>
<p>The candidate generation network suggests hundreds of videos using collaborative filtering.
A user’s representation includes coarse features such as the IDs of watched videos and tokens from search queries.
The ranking network predicts the expected watch time of the videos suggested by the candidate generation network.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/recommendation/">
            #Recommendation
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 23, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/kademlia-a-peer-to-peer-information-system-based-on-the-xor-metric/">Kademlia: A Peer-to-Peer Information System Based on the XOR Metric (2002)</a></h3>
    <div class="summary"><p><a href="https://www.cs.helsinki.fi/u/lxwang/publications/P2P2013_13.pdf">Mainline DHT</a>, the distributed hash table used by BitTorrent, is based on <a href="https://pdos.csail.mit.edu/~petar/papers/maymounkov-kademlia-lncs.pdf">Kademlia</a>.
In Kademlia, both nodes and keys are identified by 160-bit identifiers. The distance between two identifiers is defined as their bitwise XOR interpreted as an integer. To locate other nodes or values, a node repeatedly sends RPC requests to peers whose addresses it knows and that appear closer to the target according to the XOR metric.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/peer-to-peer/">
            #Peer-to-Peer
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 13, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/multi-probe-consistent-hashing/">Multi-probe consistent hashing (2015)</a></h3>
    <div class="summary"><p>Karger et al&rsquo;s <a href="https://www.cs.princeton.edu/courses/archive/fall09/cos518/papers/chash.pdf">Consistent hashing</a> is widely used for load balancing in content delivery networks and key-value store databases.
Consistent hashing maps both keys and nodes to values in the unit interval, and assigns each key to its closest node.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/consistent-hashing/">
            #Consistent Hashing
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        September 6, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/infinispan/">Distributed Caches in Infinispan</a></h3>
    <div class="summary"><p><a href="https://infinispan.org/">Infinispan</a> is an open-source in-memory data grid and forms the core of <a href="https://www.redhat.com/en/technologies/jboss-middleware/data-grid">Red Hat Data Grid</a>.
It can also serve as a <a href="https://www.keycloak.org/">cache server</a> for <a href="https://www.keycloak.org/">KeyCloak</a>, which provides single sign-on and identity brokering.</p>
<p>The official documentation describes Infinispan as a <a href="https://infinispan.org/use-cases/">drop-in replacement for Redis or Memcached</a>.
It also implements <a href="https://github.com/jsr107/jsr107spec">JSR107</a>, which allows Java clients to interact with an Infinispan cluster via the JCache API.
For example, a client can use a <a href="https://www.javadoc.io/doc/javax.cache/cache-api/latest/index.html">CacheManager</a> to obtain a <a href="https://www.javadoc.io/doc/javax.cache/cache-api/latest/index.html">Cache</a>—a map-like data structure—and perform updates or lookups.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/infinispan/">
            #Infinispan
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/consistent-hashing/">
            #Consistent Hashing
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 23, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/amazon.com-recommendations-item-to-item-collaborative-filtering/">Amazon.com Recommendations Item to Item Collaborative Filtering (2003)</a></h3>
    <div class="summary"><p>When the journal IEEE Internet Computing was celebrating its 20th anniversary in 2017, its editorial board selected <a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf">Amazon.com Recommendations: Item-to-Item Collaborative Filtering</a>, published in 2003, as the paper that best stood the test of time.
The paper views traditional collaborative filtering as the approach of finding users similar to the target user and recommending items those users have selected but the user has not.
Let \(N\) be the number of the items. In the traditional approach, each user is represented as an \(N\)-dimensional vector to measure the similarity between users, the item to item collaborative filtering constructs an \(N\) x \(N\) matrix, where each component represents the similarity between two items.
By computing the item to item matrix offline, the proposed approach can recommend similar items in time independent of both \(N\) and the number of users \(M\).</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 16, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/outrageously-large-neural-networks-the-sparsely-gated-mixture-of-expert-layer/">OUTRAGEOUSLY LARGE NEURAL NETWORKS THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER (2017)</a></h3>
    <div class="summary"><p>Increasing a model’s number of parameters enhances its capacity to learn complex patterns, but it also raises computational costs.
<a href="https://arxiv.org/pdf/1701.06538">OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER</a> (MoE)  introduces a method to scale model capacity efficiently by using a gating network that dynamically selects a sparse subset of feed-forward networks (called experts) for each input, while skipping computation for the others.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/mixture-of-experts/">
            #Mixture-of-Experts
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 1, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/training-language-models-to-follow-instructions-with-human-feedback/">Training Language Models to Follow Instructions With Human Feedback (2022)</a></h3>
    <div class="summary"><p>Increasing the number of parameters does not inherently improve a model’s ability to follow users&rsquo; intent. Large Language Models (LLMs) are typically trained to predict the next token in large-scale internet text corpora, but this objective does not explicitly encourage models to follow user instructions in a helpful and safe manner. [Training Language Models to Follow Instructions with Human Feedback](<a href="https://arxiv.org/pdf/2203.02155">https://arxiv.org/pdf/2203.02155</a>  introduces a method for aligning models with human intent using Reinforcement Learning from Human Feedback (RLHF).</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/reinforcement-learning-from-human-feedback/">
            #Reinforcement Learning From Human Feedback
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 24, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/react-synergizing-reasoning-and-acting-in-language-models/">REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS (2023)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2210.03629">ReAct (Synergizing <em>Re</em>asoning + <em>Act</em>ing)</a> is a prompting strategy that enables large language models (LLMs) to generate reasoning traces and actions in an interleaved manner, allowing them to more effectively combine thought and actions.
ReAct provides LLMs with reasoning traces that guide their actions.
Additionally, it allows models to incorporate external knowledge obtained through actions into their reasoning process.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/prompt-engineering/">
            #Prompt Engineering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 11, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/denoising-diffusion-probabilistic-models/">Denoising Diffusion Probabilistic Models (2020)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion Probabilistic Models</a> generate high-quality images by learning to reverse a gradual noising process.
The forward process is a fixed Markov chain that incrementally corrupts the data by adding Gaussian noise.
The reverse process is a parameterized Markov chain, trained to denoise the corrupted inputs and generate samples.
The authors demonstrate that training the model to predict the added noise minimizes a variational upper bound on the negative log-likelihood.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/diffusion-model/">
            #Diffusion Model
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 15, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/lora-low-rank-adaptation-of-large-language-models/">LoRA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS (2021)</a></h3>
    <div class="summary"><p>LoRA is motivated by the findings of <a href="https://arxiv.org/pdf/1804.08838.pdf">Li et al. (2018)</a> and <a href="https://arxiv.org/pdf/2012.13255.pdf">Aghajanyan et al. (2020)</a>, which show that overparameterized models tend to converge to solutions that lie within a low-dimensional intrinsic subspace.</p>
<p>The intrinsic dimension refers to the minimum number of trainable parameters needed to reach satisfactory performance on a given task.</p>
<p>LoRA introduces low-rank adaptation by decomposing the weight matrices in dense layers. Instead of fine-tuning all parameters of a pre-trained model, LoRA freezes the original weights and learns two low-rank matrices during training.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-model/">
            #Large Language Model
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/transformer/">
            #Transformer
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 7, 2025 (Originally posted on November 18, 2023)</p>
        
      </span>
    </div>
  </article>
  
</main>

  

<ul class="pagination">
  
  
  <li>
    <a href="/en/page/2/">
      <i class="fa-solid fa-xl fa-angle-right"></i>
    </a>
  </li>
  <li>
    <a href="/en/page/7/">
      <i class="fa-solid fa-xl fa-angles-right"></i>
    </a>
  </li>
  
</ul>

  <footer>
    <small>© Ryotaro Nakamura. All Rights Reserved.</small>
  </footer>
</body>


</html>
