<!DOCTYPE html>
<html lang="en">

<head>
	<meta name="generator" content="Hugo 0.147.7">
  
  
  <script>(function (w, d, s, l, i) {
      w[l] = w[l] || []; w[l].push({
        'gtm.start':
          new Date().getTime(), event: 'gtm.js'
      }); var f = d.getElementsByTagName(s)[0],
        j = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; j.src =
          'https://www.googletagmanager.com/gtm.js?id=' + i + dl; f.parentNode.insertBefore(j, f);
    })(window, document, 'script', 'dataLayer', 'GTM-W5TDG76');
  </script>
  
  
  <meta charset="utf-8">
  <meta name="viewport" content="width=300,initial-scale=1">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/meyer-reset/2.0/reset.min.css"
    integrity="sha512-NmLkDIU1C/C88wi324HBc+S2kLhi08PN5GDeUVVVC/BVt/9Izdsc9SVeVfA1UZbY3sHUlDSyRXhCzHfr6hmPPw=="
    crossorigin="anonymous" />
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.min.d5f9c6d3a478082690f838fa06a179ccee4dea5bd3f0cb3f4a357e2803c48d33.css">
  
  <link rel="stylesheet" href="https://ryotaro.dev/scss/base.en.min.fabf7968ffbe5ff626ec9a346f0d38e91d0078974112f713b9d25782380a5073.css">
  

<link rel="stylesheet" href="https://ryotaro.dev/scss/articles.min.3ceb81a62f07e7057aa63e938b7f0479d4643c093f1c72984a82a68278ddbba3.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://kit.fontawesome.com/e48a1b5aa5.js" crossorigin="anonymous"></script>
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.css"
    integrity="sha384-vKruj+a13U8yHIkAyGgK1J3ArTLzrFGBbBc0tDp4ad/EyewESeXE/Iv67Aj8gKZ0" crossorigin="anonymous">
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/katex.min.js"
    integrity="sha384-PwRUT/YqbnEjkZO0zZxNqcxACrXe+j766U2amXcgMg5457rve2Y7I6ZJSm2A0mS4"
    crossorigin="anonymous"></script>
  
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/auto-render.min.js"
    integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
  <title>Blanket</title>
</head>

<body>
  
  
  <noscript>
    <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-W5TDG76" height="0" width="0"
      style="display:none;visibility:hidden" />
  </noscript>
  
  
  <header class="navigation">
    <h2><a href="https://ryotaro.dev/en/">Blanket</a></h2>
    <nav>
      <ul>
        <li><a href="https://ryotaro.dev/en/about">About</a></li>
        <li><a href="https://ryotaro.dev/en/posts">Posts</a></li>
        <li><a href="https://ryotaro.dev/en/tags">Tags</a></li>
        
        <li><a href="https://ryotaro.dev/">ja</a></li>
        
      </ul>
      <ul>
        
        <li>
          <a href="https://github.com/ryotaro612">
            <i class="fab fa-github"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://www.linkedin.com/in/ryotaro612/">
            <i class="fab fa-linkedin-in"></i>
          </a>
        </li>
        
        
        <li>
          <a href="https://speakerdeck.com/ryotaro612/">
            <i class="fa-brands fa-speaker-deck"></i>
          </a>
        </li>
        
        <li>
          <a href="https://ryotaro.dev/en/%20index.xml">
            <i class="fas fa-rss"></i>
          </a>
        </li>
        
      </ul>
    </nav>
  </header>
  
<main>
  <h1>Posts</h1>
  
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/amazon.com-recommendations-item-to-item-collaborative-filtering/">Amazon.com Recommendations Item to Item Collaborative Filtering (2003)</a></h3>
    <div class="summary"><p>When the journal IEEE Internet Computing was celebrating its 20th anniversary in 2017, its editorial board selected <a href="https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf">Amazon.com Recommendations: Item-to-Item Collaborative Filtering</a>, published in 2003, as the paper that best stood the test of time.
The paper views traditional collaborative filtering as the approach of finding users similar to the target user and recommending items those users have selected but the user has not.
Let \(N\) be the number of the items. In the traditional approach, each user is represented as an \(N\)-dimensional vector to measure the similarity between users, the item to item collaborative filtering constructs an \(N\) x \(N\) matrix, where each component represents the similarity between two items.
By computing the item to item matrix offline, the proposed approach can recommend similar items in time independent of both \(N\) and the number of users \(M\).</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/collaborative-filtering/">
            #Collaborative Filtering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 16, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/outrageously-large-neural-networks-the-sparsely-gated-mixture-of-expert-layer/">OUTRAGEOUSLY LARGE NEURAL NETWORKS THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER (2017)</a></h3>
    <div class="summary"><p>Increasing a model’s number of parameters enhances its capacity to learn complex patterns, but it also raises computational costs.
<a href="https://arxiv.org/pdf/1701.06538">OUTRAGEOUSLY LARGE NEURAL NETWORKS: THE SPARSELY-GATED MIXTURE-OF-EXPERTS LAYER</a> (MoE)  introduces a method to scale model capacity efficiently by using a gating network that dynamically selects a sparse subset of feed-forward networks (called experts) for each input, while skipping computation for the others.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/mixture-of-experts/">
            #Mixture-of-Experts
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        August 1, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/training-language-models-to-follow-instructions-with-human-feedback/">Training Language Models to Follow Instructions With Human Feedback (2022)</a></h3>
    <div class="summary"><p>Increasing the number of parameters does not inherently improve a model’s ability to follow users&rsquo; intent. Large Language Models (LLMs) are typically trained to predict the next token in large-scale internet text corpora, but this objective does not explicitly encourage models to follow user instructions in a helpful and safe manner. [Training Language Models to Follow Instructions with Human Feedback](<a href="https://arxiv.org/pdf/2203.02155">https://arxiv.org/pdf/2203.02155</a>  introduces a method for aligning models with human intent using Reinforcement Learning from Human Feedback (RLHF).</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/reinforcement-learning-from-human-feedback/">
            #Reinforcement Learning From Human Feedback
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 24, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/react-synergizing-reasoning-and-acting-in-language-models/">REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS (2023)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2210.03629">ReAct (Synergizing <em>Re</em>asoning + <em>Act</em>ing)</a> is a prompting strategy that enables large language models (LLMs) to generate reasoning traces and actions in an interleaved manner, allowing them to more effectively combine thought and actions.
ReAct provides LLMs with reasoning traces that guide their actions.
Additionally, it allows models to incorporate external knowledge obtained through actions into their reasoning process.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/prompt-engineering/">
            #Prompt Engineering
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        July 11, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/denoising-diffusion-probabilistic-models/">Denoising Diffusion Probabilistic Models (2020)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/2006.11239">Denoising Diffusion Probabilistic Models</a> generate high-quality images by learning to reverse a gradual noising process.
The forward process is a fixed Markov chain that incrementally corrupts the data by adding Gaussian noise.
The reverse process is a parameterized Markov chain, trained to denoise the corrupted inputs and generate samples.
The authors demonstrate that training the model to predict the added noise minimizes a variational upper bound on the negative log-likelihood.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/diffusion-model/">
            #Diffusion Model
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 15, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/lora-low-rank-adaptation-of-large-language-models/">LoRA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS (2021)</a></h3>
    <div class="summary"><p>LoRA is motivated by the findings of <a href="https://arxiv.org/pdf/1804.08838.pdf">Li et al. (2018)</a> and <a href="https://arxiv.org/pdf/2012.13255.pdf">Aghajanyan et al. (2020)</a>, which show that overparameterized models tend to converge to solutions that lie within a low-dimensional intrinsic subspace.</p>
<p>The intrinsic dimension refers to the minimum number of trainable parameters needed to reach satisfactory performance on a given task.</p>
<p>LoRA introduces low-rank adaptation by decomposing the weight matrices in dense layers. Instead of fine-tuning all parameters of a pre-trained model, LoRA freezes the original weights and learns two low-rank matrices during training.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-model/">
            #Large Language Model
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/transformer/">
            #Transformer
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        June 7, 2025 (Originally posted on November 18, 2023)</p>
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/supervised-learning-of-universal-sentence-representations-from-natural-language-inference-data/">Supervised Learning of Universal Sentence Representations From Natural Language Inference Data (2017)</a></h3>
    <div class="summary"><p><a href="https://arxiv.org/pdf/1705.02364">Supervised Learning of Universal Sentence Representations From Natural Language Inference Data</a> proposes a supervised approach to train neural networks on the Stanford Natural Language Inference (SNLI) dataset to produce general-purpose sentence embeddings applicable to a wide range of downstream tasks.
The authors evaluated seven different encoder architectures across twelve NLP tasks and found that a bidirectional LSTM with max pooling achieved the best performance.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/sentence-embedding/">
            #Sentence Embedding
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        May 30, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/scaling-instruction-finetuned-language-models/">Scaling Instruction Finetuned Language Models (2022)</a></h3>
    <div class="summary"><p>Instruction finetuning is a technique for enhancing the zero-shot performance of large language models (LLMs). The seminal work, <a href="https://arxiv.org/pdf/2109.01652">Finetuned Language Models Are Zero-Shot Learners</a>, refers to this method as instruction tuning.
Building on this, <a href="https://arxiv.org/abs/2210.11416">Scaling Instruction-Finetuned Language Models</a> explored scaling the number of tasks, model sizes, and the incorporation of chain-of-thought (CoT) data. Their findings demonstrate that instruction finetuning can significantly improve LLM performance across a wide range of settings.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-models/">
            #Large Language Models
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/instruction-finetuning/">
            #Instruction Finetuning
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        May 7, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/reading-wikipedia-to-answer-open-domain-questions/">Reading Wikipedia to Answer Open Domain Questions (2017)</a></h3>
    <div class="summary"><p><a href="https://aclanthology.org/P17-1171/">Reading Wikipedia to Answer Open Domain Questions</a> proposes DrQA, a system for open-domain question answering.
DrQA consists of two components: Document Retriever and Document Reader.</p>
<p>Given a question, the Document Retriever uses bigram TF-IDF matching to search Wikipedia and retrieve the five most relevant articles.
These articles, along with the question, are then passed to the Document Reader, a neural network model that embeds the question and the paragraphs into vector representations.
The model then compares the paragraph embeddings with the question embedding to identify the most salient text span that likely contains the answer.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/open-domain-questions/">
            #Open Domain Questions
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/tf-idf/">
            #TF-IDF
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        April 26, 2025
        
      </span>
    </div>
  </article>
  
  <article>
    <h3><a href="https://ryotaro.dev/en/posts/language-models-are-few-shot-learners/">Language Models Are Few Shot Learners (2020)</a></h3>
    <div class="summary"><p>In <a href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a>, it is shown that increasing the number of parameters of <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">GPT-2</a> improves few-shot performance across various tasks.
The proposed model, GPT-3, is an autoregressive language model with 175 billion parameters.
Its architecture mirrors that of GPT-2, except that GPT-3 uses alternating dense and locally banded sparse attention patterns, similar to the <a href="https://arxiv.org/pdf/1904.10509">Sparse Transformer</a>.</p></div>
    <div class="article-footer">
      
      <ul class="tags">
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/few-shot-learning/">
            #Few-Shot Learning
          </a>
        </li>
        
        <li class="tag">
          <a href="https://ryotaro.dev/en/tags/large-language-model/">
            #Large Language Model
          </a>
        </li>
        
      </ul>
      
      <span class="date">
        
        April 12, 2025
        
      </span>
    </div>
  </article>
  
</main>

  

<ul class="pagination">
  
  
  <li>
    <a href="/en/page/2/">
      <i class="fa-solid fa-xl fa-angle-right"></i>
    </a>
  </li>
  <li>
    <a href="/en/page/6/">
      <i class="fa-solid fa-xl fa-angles-right"></i>
    </a>
  </li>
  
</ul>

  <footer>
    <small>© Ryotaro Nakamura. All Rights Reserved.</small>
  </footer>
</body>


</html>
